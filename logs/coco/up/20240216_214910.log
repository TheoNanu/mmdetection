2024/02/16 21:49:17 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.10.13 (main, Sep 11 2023, 13:44:35) [GCC 11.2.0]
    CUDA available: True
    MUSA available: False
    numpy_random_seed: 1368010620
    GPU 0,1,2,3,4,5,6,7: Tesla V100-SXM2-16GB
    CUDA_HOME: None
    GCC: n/a
    PyTorch: 1.11.0+cu113
    PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.12.0+cu113
    OpenCV: 4.9.0
    MMEngine: 0.10.3

Runtime environment:
    cudnn_benchmark: False
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 1368010620
    Distributed launcher: pytorch
    Distributed training: True
    GPU number: 8
------------------------------------------------------------

2024/02/16 21:49:18 - mmengine - INFO - Config:
auto_scale_lr = dict(base_batch_size=16, enable=False)
backend_args = None
data_root = 'data/coco/'
dataset_type = 'CocoDataset'
default_hooks = dict(
    checkpoint=dict(interval=1, type='CheckpointHook'),
    logger=dict(interval=50, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'),
    visualization=dict(type='DetVisualizationHook'))
default_scope = 'mmdet'
env_cfg = dict(
    cudnn_benchmark=False,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
launcher = 'pytorch'
load_from = '/results/epoch_34.pth'
log_level = 'INFO'
log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)
max_epochs = 36
model = dict(
    backbone=dict(
        attn_drop_rate=0.0,
        convert_weights=False,
        depths=[
            2,
            2,
            6,
            2,
        ],
        drop_path_rate=0.2,
        drop_rate=0.0,
        embed_dims=96,
        init_cfg=None,
        mlp_ratio=4,
        num_heads=[
            3,
            6,
            12,
            24,
        ],
        out_indices=(
            0,
            1,
            2,
            3,
        ),
        patch_norm=True,
        qk_scale=None,
        qkv_bias=True,
        schemes=(
            'up',
            'up',
            'up',
            'up',
        ),
        type='SwinTransformerMultipleSchemes',
        window_size=(
            7,
            7,
            7,
            7,
        ),
        with_cp=False),
    data_preprocessor=dict(
        bgr_to_rgb=True,
        mean=[
            123.675,
            116.28,
            103.53,
        ],
        pad_mask=True,
        pad_size_divisor=32,
        std=[
            58.395,
            57.12,
            57.375,
        ],
        type='DetDataPreprocessor'),
    neck=dict(
        in_channels=[
            96,
            192,
            384,
            768,
        ],
        num_outs=5,
        out_channels=256,
        type='FPN'),
    roi_head=dict(
        bbox_head=[
            dict(
                bbox_coder=dict(
                    target_means=[
                        0.0,
                        0.0,
                        0.0,
                        0.0,
                    ],
                    target_stds=[
                        0.1,
                        0.1,
                        0.2,
                        0.2,
                    ],
                    type='DeltaXYWHBBoxCoder'),
                conv_out_channels=256,
                fc_out_channels=1024,
                in_channels=256,
                loss_bbox=dict(loss_weight=10.0, type='GIoULoss'),
                loss_cls=dict(
                    loss_weight=1.0,
                    type='CrossEntropyLoss',
                    use_sigmoid=False),
                norm_cfg=dict(requires_grad=True, type='SyncBN'),
                num_classes=80,
                num_shared_convs=4,
                num_shared_fcs=1,
                reg_class_agnostic=False,
                reg_decoded_bbox=True,
                roi_feat_size=7,
                type='ConvFCBBoxHead'),
            dict(
                bbox_coder=dict(
                    target_means=[
                        0.0,
                        0.0,
                        0.0,
                        0.0,
                    ],
                    target_stds=[
                        0.05,
                        0.05,
                        0.1,
                        0.1,
                    ],
                    type='DeltaXYWHBBoxCoder'),
                conv_out_channels=256,
                fc_out_channels=1024,
                in_channels=256,
                loss_bbox=dict(loss_weight=10.0, type='GIoULoss'),
                loss_cls=dict(
                    loss_weight=1.0,
                    type='CrossEntropyLoss',
                    use_sigmoid=False),
                norm_cfg=dict(requires_grad=True, type='SyncBN'),
                num_classes=80,
                num_shared_convs=4,
                num_shared_fcs=1,
                reg_class_agnostic=False,
                reg_decoded_bbox=True,
                roi_feat_size=7,
                type='ConvFCBBoxHead'),
            dict(
                bbox_coder=dict(
                    target_means=[
                        0.0,
                        0.0,
                        0.0,
                        0.0,
                    ],
                    target_stds=[
                        0.033,
                        0.033,
                        0.067,
                        0.067,
                    ],
                    type='DeltaXYWHBBoxCoder'),
                conv_out_channels=256,
                fc_out_channels=1024,
                in_channels=256,
                loss_bbox=dict(loss_weight=10.0, type='GIoULoss'),
                loss_cls=dict(
                    loss_weight=1.0,
                    type='CrossEntropyLoss',
                    use_sigmoid=False),
                norm_cfg=dict(requires_grad=True, type='SyncBN'),
                num_classes=80,
                num_shared_convs=4,
                num_shared_fcs=1,
                reg_class_agnostic=False,
                reg_decoded_bbox=True,
                roi_feat_size=7,
                type='ConvFCBBoxHead'),
        ],
        bbox_roi_extractor=dict(
            featmap_strides=[
                4,
                8,
                16,
                32,
            ],
            out_channels=256,
            roi_layer=dict(output_size=7, sampling_ratio=0, type='RoIAlign'),
            type='SingleRoIExtractor'),
        mask_head=dict(
            conv_out_channels=256,
            in_channels=256,
            loss_mask=dict(
                loss_weight=1.0, type='CrossEntropyLoss', use_mask=True),
            num_classes=80,
            num_convs=4,
            type='FCNMaskHead'),
        mask_roi_extractor=dict(
            featmap_strides=[
                4,
                8,
                16,
                32,
            ],
            out_channels=256,
            roi_layer=dict(output_size=14, sampling_ratio=0, type='RoIAlign'),
            type='SingleRoIExtractor'),
        num_stages=3,
        stage_loss_weights=[
            1,
            0.5,
            0.25,
        ],
        type='CascadeRoIHead'),
    rpn_head=dict(
        anchor_generator=dict(
            ratios=[
                0.5,
                1.0,
                2.0,
            ],
            scales=[
                8,
            ],
            strides=[
                4,
                8,
                16,
                32,
                64,
            ],
            type='AnchorGenerator'),
        bbox_coder=dict(
            target_means=[
                0.0,
                0.0,
                0.0,
                0.0,
            ],
            target_stds=[
                1.0,
                1.0,
                1.0,
                1.0,
            ],
            type='DeltaXYWHBBoxCoder'),
        feat_channels=256,
        in_channels=256,
        loss_bbox=dict(
            beta=0.1111111111111111, loss_weight=1.0, type='SmoothL1Loss'),
        loss_cls=dict(
            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=True),
        type='RPNHead'),
    test_cfg=dict(
        rcnn=dict(
            mask_thr_binary=0.5,
            max_per_img=100,
            nms=dict(iou_threshold=0.5, type='nms'),
            score_thr=0.05),
        rpn=dict(
            max_per_img=1000,
            min_bbox_size=0,
            nms=dict(iou_threshold=0.7, type='nms'),
            nms_pre=1000)),
    train_cfg=dict(
        rcnn=[
            dict(
                assigner=dict(
                    ignore_iof_thr=-1,
                    match_low_quality=False,
                    min_pos_iou=0.5,
                    neg_iou_thr=0.5,
                    pos_iou_thr=0.5,
                    type='MaxIoUAssigner'),
                debug=False,
                mask_size=28,
                pos_weight=-1,
                sampler=dict(
                    add_gt_as_proposals=True,
                    neg_pos_ub=-1,
                    num=512,
                    pos_fraction=0.25,
                    type='RandomSampler')),
            dict(
                assigner=dict(
                    ignore_iof_thr=-1,
                    match_low_quality=False,
                    min_pos_iou=0.6,
                    neg_iou_thr=0.6,
                    pos_iou_thr=0.6,
                    type='MaxIoUAssigner'),
                debug=False,
                mask_size=28,
                pos_weight=-1,
                sampler=dict(
                    add_gt_as_proposals=True,
                    neg_pos_ub=-1,
                    num=512,
                    pos_fraction=0.25,
                    type='RandomSampler')),
            dict(
                assigner=dict(
                    ignore_iof_thr=-1,
                    match_low_quality=False,
                    min_pos_iou=0.7,
                    neg_iou_thr=0.7,
                    pos_iou_thr=0.7,
                    type='MaxIoUAssigner'),
                debug=False,
                mask_size=28,
                pos_weight=-1,
                sampler=dict(
                    add_gt_as_proposals=True,
                    neg_pos_ub=-1,
                    num=512,
                    pos_fraction=0.25,
                    type='RandomSampler')),
        ],
        rpn=dict(
            allowed_border=0,
            assigner=dict(
                ignore_iof_thr=-1,
                match_low_quality=True,
                min_pos_iou=0.3,
                neg_iou_thr=0.3,
                pos_iou_thr=0.7,
                type='MaxIoUAssigner'),
            debug=False,
            pos_weight=-1,
            sampler=dict(
                add_gt_as_proposals=False,
                neg_pos_ub=-1,
                num=256,
                pos_fraction=0.5,
                type='RandomSampler')),
        rpn_proposal=dict(
            max_per_img=2000,
            min_bbox_size=0,
            nms=dict(iou_threshold=0.7, type='nms'),
            nms_pre=2000)),
    type='CascadeRCNN')
optim_wrapper = dict(
    optimizer=dict(
        betas=(
            0.9,
            0.999,
        ), lr=0.0001, type='AdamW', weight_decay=0.05),
    paramwise_cfg=dict(
        custom_keys=dict(
            absolute_pos_embed=dict(decay_mult=0.0),
            norm=dict(decay_mult=0.0),
            relative_position_bias_table=dict(decay_mult=0.0))),
    type='OptimWrapper')
param_scheduler = [
    dict(
        begin=0, by_epoch=False, end=1000, start_factor=0.001,
        type='LinearLR'),
    dict(
        begin=0,
        by_epoch=True,
        end=36,
        gamma=0.1,
        milestones=[
            27,
            33,
        ],
        type='MultiStepLR'),
]
randomness = dict(seed=1368010620)
resume = True
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=1,
    dataset=dict(
        ann_file='annotations/instances_val2017.json',
        backend_args=None,
        data_prefix=dict(img='val2017/'),
        data_root='data/coco/',
        pipeline=[
            dict(backend_args=None, type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                1333,
                800,
            ), type='Resize'),
            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),
            dict(
                meta_keys=(
                    'img_id',
                    'img_path',
                    'ori_shape',
                    'img_shape',
                    'scale_factor',
                ),
                type='PackDetInputs'),
        ],
        test_mode=True,
        type='CocoDataset'),
    drop_last=False,
    num_workers=2,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(
    ann_file='data/coco/annotations/instances_val2017.json',
    backend_args=None,
    format_only=False,
    metric=[
        'bbox',
        'segm',
    ],
    type='CocoMetric')
test_pipeline = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(keep_ratio=True, scale=(
        1333,
        800,
    ), type='Resize'),
    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),
    dict(
        meta_keys=(
            'img_id',
            'img_path',
            'ori_shape',
            'img_shape',
            'scale_factor',
        ),
        type='PackDetInputs'),
]
train_cfg = dict(max_epochs=36, type='EpochBasedTrainLoop', val_interval=1)
train_dataloader = dict(
    batch_sampler=dict(type='AspectRatioBatchSampler'),
    batch_size=2,
    dataset=dict(
        ann_file='annotations/instances_train2017.json',
        backend_args=None,
        data_prefix=dict(img='train2017/'),
        data_root='data/coco/',
        filter_cfg=dict(filter_empty_gt=True, min_size=32),
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),
            dict(prob=0.5, type='RandomFlip'),
            dict(
                policies=[
                    [
                        dict(
                            keep_ratio=True,
                            scales=[
                                (
                                    480,
                                    1333,
                                ),
                                (
                                    512,
                                    1333,
                                ),
                                (
                                    544,
                                    1333,
                                ),
                                (
                                    576,
                                    1333,
                                ),
                                (
                                    608,
                                    1333,
                                ),
                                (
                                    640,
                                    1333,
                                ),
                                (
                                    672,
                                    1333,
                                ),
                                (
                                    704,
                                    1333,
                                ),
                                (
                                    736,
                                    1333,
                                ),
                                (
                                    768,
                                    1333,
                                ),
                                (
                                    800,
                                    1333,
                                ),
                            ],
                            type='RandomChoiceResize'),
                    ],
                    [
                        dict(
                            keep_ratio=True,
                            scales=[
                                (
                                    400,
                                    1333,
                                ),
                                (
                                    500,
                                    1333,
                                ),
                                (
                                    600,
                                    1333,
                                ),
                            ],
                            type='RandomChoiceResize'),
                        dict(
                            allow_negative_crop=True,
                            crop_size=(
                                384,
                                600,
                            ),
                            crop_type='absolute_range',
                            type='RandomCrop'),
                        dict(
                            keep_ratio=True,
                            scales=[
                                (
                                    480,
                                    1333,
                                ),
                                (
                                    512,
                                    1333,
                                ),
                                (
                                    544,
                                    1333,
                                ),
                                (
                                    576,
                                    1333,
                                ),
                                (
                                    608,
                                    1333,
                                ),
                                (
                                    640,
                                    1333,
                                ),
                                (
                                    672,
                                    1333,
                                ),
                                (
                                    704,
                                    1333,
                                ),
                                (
                                    736,
                                    1333,
                                ),
                                (
                                    768,
                                    1333,
                                ),
                                (
                                    800,
                                    1333,
                                ),
                            ],
                            type='RandomChoiceResize'),
                    ],
                ],
                type='AutoAugment'),
            dict(type='PackDetInputs'),
        ],
        type='CocoDataset'),
    num_workers=2,
    persistent_workers=True,
    sampler=dict(shuffle=True, type='DefaultSampler'))
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),
    dict(prob=0.5, type='RandomFlip'),
    dict(
        policies=[
            [
                dict(
                    keep_ratio=True,
                    scales=[
                        (
                            480,
                            1333,
                        ),
                        (
                            512,
                            1333,
                        ),
                        (
                            544,
                            1333,
                        ),
                        (
                            576,
                            1333,
                        ),
                        (
                            608,
                            1333,
                        ),
                        (
                            640,
                            1333,
                        ),
                        (
                            672,
                            1333,
                        ),
                        (
                            704,
                            1333,
                        ),
                        (
                            736,
                            1333,
                        ),
                        (
                            768,
                            1333,
                        ),
                        (
                            800,
                            1333,
                        ),
                    ],
                    type='RandomChoiceResize'),
            ],
            [
                dict(
                    keep_ratio=True,
                    scales=[
                        (
                            400,
                            1333,
                        ),
                        (
                            500,
                            1333,
                        ),
                        (
                            600,
                            1333,
                        ),
                    ],
                    type='RandomChoiceResize'),
                dict(
                    allow_negative_crop=True,
                    crop_size=(
                        384,
                        600,
                    ),
                    crop_type='absolute_range',
                    type='RandomCrop'),
                dict(
                    keep_ratio=True,
                    scales=[
                        (
                            480,
                            1333,
                        ),
                        (
                            512,
                            1333,
                        ),
                        (
                            544,
                            1333,
                        ),
                        (
                            576,
                            1333,
                        ),
                        (
                            608,
                            1333,
                        ),
                        (
                            640,
                            1333,
                        ),
                        (
                            672,
                            1333,
                        ),
                        (
                            704,
                            1333,
                        ),
                        (
                            736,
                            1333,
                        ),
                        (
                            768,
                            1333,
                        ),
                        (
                            800,
                            1333,
                        ),
                    ],
                    type='RandomChoiceResize'),
            ],
        ],
        type='AutoAugment'),
    dict(type='PackDetInputs'),
]
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=1,
    dataset=dict(
        ann_file='annotations/instances_val2017.json',
        backend_args=None,
        data_prefix=dict(img='val2017/'),
        data_root='data/coco/',
        pipeline=[
            dict(backend_args=None, type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                1333,
                800,
            ), type='Resize'),
            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),
            dict(
                meta_keys=(
                    'img_id',
                    'img_path',
                    'ori_shape',
                    'img_shape',
                    'scale_factor',
                ),
                type='PackDetInputs'),
        ],
        test_mode=True,
        type='CocoDataset'),
    drop_last=False,
    num_workers=2,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(
    ann_file='data/coco/annotations/instances_val2017.json',
    backend_args=None,
    format_only=False,
    metric=[
        'bbox',
        'segm',
    ],
    type='CocoMetric')
vis_backends = [
    dict(type='LocalVisBackend'),
]
visualizer = dict(
    name='visualizer',
    type='DetLocalVisualizer',
    vis_backends=[
        dict(type='LocalVisBackend'),
    ])
work_dir = '/results'

2024/02/16 21:49:21 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DetVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DetVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.weight:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.weight:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.weight:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.bias:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.bias:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.bias:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.weight:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.weight:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.weight:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.bias:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.bias:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.bias:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.weight:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.weight:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.weight:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.bias:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.bias:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.bias:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.weight:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.weight:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.weight:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.bias:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.bias:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.bias:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.weight:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.weight:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.weight:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.bias:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.bias:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.bias:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.weight:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.weight:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.weight:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.bias:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.bias:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.bias:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.weight:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.weight:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.weight:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.bias:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.bias:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.bias:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.weight:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.weight:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.weight:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.bias:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.bias:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.bias:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.weight:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.weight:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.weight:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.bias:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.bias:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.bias:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.weight:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.weight:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.weight:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.bias:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.bias:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.bias:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.weight:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.weight:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.weight:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.bias:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.bias:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.bias:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.weight:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.weight:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.weight:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.bias:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.bias:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.bias:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.weight:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.weight:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.weight:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.bias:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.bias:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.bias:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.weight:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.weight:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.weight:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.bias:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.bias:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.bias:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.weight:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.weight:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.weight:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.bias:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.bias:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.bias:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.weight:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.weight:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.weight:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.bias:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.bias:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.bias:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.weight:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.weight:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.weight:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.bias:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.bias:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.bias:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.weight:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.weight:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.weight:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.bias:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.bias:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.bias:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.weight:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.weight:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.weight:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.bias:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.bias:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.bias:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.weight:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.weight:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.weight:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.bias:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.bias:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.bias:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.weight:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.weight:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.weight:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.bias:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.bias:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.bias:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.weight:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.weight:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.weight:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.bias:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.bias:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.bias:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.weight:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.weight:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.weight:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.bias:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.bias:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.bias:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.weight:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.weight:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.weight:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.bias:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.bias:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.bias:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:decay_mult=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:lr=0.0001
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:weight_decay=0.0
2024/02/16 21:50:02 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:decay_mult=0.0
2024/02/16 21:50:06 - mmengine - WARNING - No pre-trained weights for SwinTransformerMultipleSchemes, training start from scratch
Name of parameter - Initialization information

backbone.patch_embed.projection.weight - torch.Size([96, 3, 4, 4]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.patch_embed.projection.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.patch_embed.norm.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.patch_embed.norm.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.0.blocks.0.norm1.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.0.blocks.0.norm1.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([169, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.0.blocks.0.attn.w_msa.qkv.weight - torch.Size([288, 96]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.0.blocks.0.attn.w_msa.qkv.bias - torch.Size([288]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.0.blocks.0.attn.w_msa.proj.weight - torch.Size([96, 96]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.0.blocks.0.attn.w_msa.proj.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.0.blocks.0.norm2.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.0.blocks.0.norm2.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.0.blocks.0.ffn.layers.0.0.weight - torch.Size([384, 96]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.0.blocks.0.ffn.layers.0.0.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.0.blocks.0.ffn.layers.1.weight - torch.Size([96, 384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.0.blocks.0.ffn.layers.1.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.0.blocks.1.norm1.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.0.blocks.1.norm1.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([169, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.0.blocks.1.attn.w_msa.qkv.weight - torch.Size([288, 96]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.0.blocks.1.attn.w_msa.qkv.bias - torch.Size([288]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.0.blocks.1.attn.w_msa.proj.weight - torch.Size([96, 96]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.0.blocks.1.attn.w_msa.proj.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.0.blocks.1.norm2.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.0.blocks.1.norm2.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.0.blocks.1.ffn.layers.0.0.weight - torch.Size([384, 96]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.0.blocks.1.ffn.layers.0.0.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.0.blocks.1.ffn.layers.1.weight - torch.Size([96, 384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.0.blocks.1.ffn.layers.1.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.0.downsample.norm.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.0.downsample.norm.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.0.downsample.reduction.weight - torch.Size([192, 384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.1.blocks.0.norm1.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.1.blocks.0.norm1.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([169, 6]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.1.blocks.0.attn.w_msa.qkv.weight - torch.Size([576, 192]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.1.blocks.0.attn.w_msa.qkv.bias - torch.Size([576]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.1.blocks.0.attn.w_msa.proj.weight - torch.Size([192, 192]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.1.blocks.0.attn.w_msa.proj.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.1.blocks.0.norm2.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.1.blocks.0.norm2.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.1.blocks.0.ffn.layers.0.0.weight - torch.Size([768, 192]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.1.blocks.0.ffn.layers.0.0.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.1.blocks.0.ffn.layers.1.weight - torch.Size([192, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.1.blocks.0.ffn.layers.1.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.1.blocks.1.norm1.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.1.blocks.1.norm1.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([169, 6]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.1.blocks.1.attn.w_msa.qkv.weight - torch.Size([576, 192]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.1.blocks.1.attn.w_msa.qkv.bias - torch.Size([576]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.1.blocks.1.attn.w_msa.proj.weight - torch.Size([192, 192]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.1.blocks.1.attn.w_msa.proj.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.1.blocks.1.norm2.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.1.blocks.1.norm2.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.1.blocks.1.ffn.layers.0.0.weight - torch.Size([768, 192]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.1.blocks.1.ffn.layers.0.0.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.1.blocks.1.ffn.layers.1.weight - torch.Size([192, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.1.blocks.1.ffn.layers.1.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.1.downsample.norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.1.downsample.norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.1.downsample.reduction.weight - torch.Size([384, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.0.norm1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.blocks.0.norm1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.blocks.0.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.0.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.0.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.0.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.0.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.blocks.0.norm2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.blocks.0.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.0.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.0.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.0.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.1.norm1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.blocks.1.norm1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.blocks.1.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.1.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.1.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.1.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.1.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.blocks.1.norm2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.blocks.1.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.1.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.1.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.1.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.2.norm1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.blocks.2.norm1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.blocks.2.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.2.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.2.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.2.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.2.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.blocks.2.norm2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.blocks.2.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.2.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.2.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.2.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.3.norm1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.blocks.3.norm1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.blocks.3.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.3.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.3.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.3.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.3.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.blocks.3.norm2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.blocks.3.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.3.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.3.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.3.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.4.norm1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.blocks.4.norm1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.blocks.4.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.4.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.4.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.4.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.4.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.blocks.4.norm2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.blocks.4.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.4.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.4.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.4.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.5.norm1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.blocks.5.norm1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.blocks.5.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.5.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.5.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.5.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.5.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.blocks.5.norm2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.blocks.5.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.5.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.5.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.5.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.downsample.norm.weight - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.downsample.norm.bias - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.downsample.reduction.weight - torch.Size([768, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.3.blocks.0.norm1.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.3.blocks.0.norm1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([169, 24]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.3.blocks.0.attn.w_msa.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.3.blocks.0.attn.w_msa.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.3.blocks.0.attn.w_msa.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.3.blocks.0.attn.w_msa.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.3.blocks.0.norm2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.3.blocks.0.norm2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.3.blocks.0.ffn.layers.0.0.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.3.blocks.0.ffn.layers.0.0.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.3.blocks.0.ffn.layers.1.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.3.blocks.0.ffn.layers.1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.3.blocks.1.norm1.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.3.blocks.1.norm1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([169, 24]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.3.blocks.1.attn.w_msa.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.3.blocks.1.attn.w_msa.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.3.blocks.1.attn.w_msa.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.3.blocks.1.attn.w_msa.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.3.blocks.1.norm2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.3.blocks.1.norm2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.3.blocks.1.ffn.layers.0.0.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.3.blocks.1.ffn.layers.0.0.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.3.blocks.1.ffn.layers.1.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.3.blocks.1.ffn.layers.1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.norm0.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.norm0.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.norm1.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.norm1.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.norm2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.norm3.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.norm3.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.lateral_convs.0.conv.weight - torch.Size([256, 96, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.lateral_convs.1.conv.weight - torch.Size([256, 192, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.lateral_convs.2.conv.weight - torch.Size([256, 384, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.lateral_convs.3.conv.weight - torch.Size([256, 768, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

rpn_head.rpn_conv.weight - torch.Size([256, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_conv.bias - torch.Size([256]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_cls.weight - torch.Size([3, 256, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_cls.bias - torch.Size([3]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_reg.weight - torch.Size([12, 256, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_reg.bias - torch.Size([12]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.0.fc_cls.weight - torch.Size([81, 1024]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.0.fc_cls.bias - torch.Size([81]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.0.fc_reg.weight - torch.Size([320, 1024]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.0.fc_reg.bias - torch.Size([320]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.0.shared_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.0.shared_convs.0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.0.shared_convs.0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.0.shared_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.0.shared_convs.1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.0.shared_convs.1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.0.shared_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.0.shared_convs.2.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.0.shared_convs.2.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.0.shared_convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.0.shared_convs.3.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.0.shared_convs.3.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.0.shared_fcs.0.weight - torch.Size([1024, 12544]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.0.shared_fcs.0.bias - torch.Size([1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.1.fc_cls.weight - torch.Size([81, 1024]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.1.fc_cls.bias - torch.Size([81]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.1.fc_reg.weight - torch.Size([320, 1024]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.1.fc_reg.bias - torch.Size([320]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.1.shared_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.1.shared_convs.0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.1.shared_convs.0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.1.shared_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.1.shared_convs.1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.1.shared_convs.1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.1.shared_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.1.shared_convs.2.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.1.shared_convs.2.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.1.shared_convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.1.shared_convs.3.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.1.shared_convs.3.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.1.shared_fcs.0.weight - torch.Size([1024, 12544]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.1.shared_fcs.0.bias - torch.Size([1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.2.fc_cls.weight - torch.Size([81, 1024]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.2.fc_cls.bias - torch.Size([81]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.2.fc_reg.weight - torch.Size([320, 1024]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.2.fc_reg.bias - torch.Size([320]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.2.shared_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.2.shared_convs.0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.2.shared_convs.0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.2.shared_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.2.shared_convs.1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.2.shared_convs.1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.2.shared_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.2.shared_convs.2.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.2.shared_convs.2.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.2.shared_convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.2.shared_convs.3.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.2.shared_convs.3.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.2.shared_fcs.0.weight - torch.Size([1024, 12544]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.2.shared_fcs.0.bias - torch.Size([1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.mask_head.0.convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.upsample.weight - torch.Size([256, 256, 2, 2]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.upsample.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.conv_logits.weight - torch.Size([80, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.conv_logits.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.upsample.weight - torch.Size([256, 256, 2, 2]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.upsample.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.conv_logits.weight - torch.Size([80, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.conv_logits.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.upsample.weight - torch.Size([256, 256, 2, 2]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.upsample.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.conv_logits.weight - torch.Size([80, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.conv_logits.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  
2024/02/16 21:50:09 - mmengine - INFO - Load checkpoint from /results/epoch_34.pth
2024/02/16 21:50:09 - mmengine - INFO - resumed epoch: 34, iter: 249220
2024/02/16 21:50:09 - mmengine - WARNING - "FileClient" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io
2024/02/16 21:50:09 - mmengine - WARNING - "HardDiskBackend" is the alias of "LocalBackend" and the former will be deprecated in future.
2024/02/16 21:50:09 - mmengine - INFO - Checkpoints will be saved to /results.
2024/02/16 21:50:45 - mmengine - INFO - Epoch(train) [35][  50/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:56:37  time: 0.7254  data_time: 0.0393  memory: 9570  loss: 1.1928  loss_rpn_cls: 0.0351  loss_rpn_bbox: 0.0318  s0.loss_cls: 0.1951  s0.acc: 92.8711  s0.loss_bbox: 0.2483  s0.loss_mask: 0.2318  s1.loss_cls: 0.0889  s1.acc: 93.5259  s1.loss_bbox: 0.1106  s1.loss_mask: 0.1136  s2.loss_cls: 0.0418  s2.acc: 94.9254  s2.loss_bbox: 0.0431  s2.loss_mask: 0.0528
2024/02/16 21:51:19 - mmengine - INFO - Epoch(train) [35][ 100/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:51:43  time: 0.6899  data_time: 0.0243  memory: 10658  loss: 1.0990  loss_rpn_cls: 0.0365  loss_rpn_bbox: 0.0281  s0.loss_cls: 0.1629  s0.acc: 95.1172  s0.loss_bbox: 0.2256  s0.loss_mask: 0.2336  s1.loss_cls: 0.0735  s1.acc: 96.2626  s1.loss_bbox: 0.1012  s1.loss_mask: 0.1122  s2.loss_cls: 0.0335  s2.acc: 93.8259  s2.loss_bbox: 0.0393  s2.loss_mask: 0.0528
2024/02/16 21:51:54 - mmengine - INFO - Epoch(train) [35][ 150/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:49:53  time: 0.6923  data_time: 0.0242  memory: 9331  loss: 1.1813  loss_rpn_cls: 0.0430  loss_rpn_bbox: 0.0284  s0.loss_cls: 0.1958  s0.acc: 83.1055  s0.loss_bbox: 0.2344  s0.loss_mask: 0.2437  s1.loss_cls: 0.0837  s1.acc: 83.5968  s1.loss_bbox: 0.1021  s1.loss_mask: 0.1158  s2.loss_cls: 0.0390  s2.acc: 81.8182  s2.loss_bbox: 0.0413  s2.loss_mask: 0.0541
2024/02/16 21:52:30 - mmengine - INFO - Epoch(train) [35][ 200/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:49:36  time: 0.7075  data_time: 0.0271  memory: 9436  loss: 1.1729  loss_rpn_cls: 0.0369  loss_rpn_bbox: 0.0252  s0.loss_cls: 0.1905  s0.acc: 98.9258  s0.loss_bbox: 0.2436  s0.loss_mask: 0.2390  s1.loss_cls: 0.0851  s1.acc: 96.5820  s1.loss_bbox: 0.1056  s1.loss_mask: 0.1149  s2.loss_cls: 0.0382  s2.acc: 96.7773  s2.loss_bbox: 0.0408  s2.loss_mask: 0.0532
2024/02/16 21:53:05 - mmengine - INFO - Epoch(train) [35][ 250/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:49:10  time: 0.7069  data_time: 0.0268  memory: 9550  loss: 1.1659  loss_rpn_cls: 0.0407  loss_rpn_bbox: 0.0291  s0.loss_cls: 0.1865  s0.acc: 92.2852  s0.loss_bbox: 0.2374  s0.loss_mask: 0.2383  s1.loss_cls: 0.0833  s1.acc: 91.3174  s1.loss_bbox: 0.1027  s1.loss_mask: 0.1166  s2.loss_cls: 0.0379  s2.acc: 92.1471  s2.loss_bbox: 0.0395  s2.loss_mask: 0.0540
2024/02/16 21:53:40 - mmengine - INFO - Epoch(train) [35][ 300/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:48:23  time: 0.6997  data_time: 0.0253  memory: 9109  loss: 1.0899  loss_rpn_cls: 0.0353  loss_rpn_bbox: 0.0242  s0.loss_cls: 0.1637  s0.acc: 93.5547  s0.loss_bbox: 0.2258  s0.loss_mask: 0.2321  s1.loss_cls: 0.0734  s1.acc: 92.9688  s1.loss_bbox: 0.0983  s1.loss_mask: 0.1120  s2.loss_cls: 0.0335  s2.acc: 95.2148  s2.loss_bbox: 0.0392  s2.loss_mask: 0.0523
2024/02/16 21:54:15 - mmengine - INFO - Epoch(train) [35][ 350/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:47:44  time: 0.7014  data_time: 0.0257  memory: 9087  loss: 1.1765  loss_rpn_cls: 0.0475  loss_rpn_bbox: 0.0267  s0.loss_cls: 0.1830  s0.acc: 98.4375  s0.loss_bbox: 0.2428  s0.loss_mask: 0.2292  s1.loss_cls: 0.0834  s1.acc: 98.6328  s1.loss_bbox: 0.1111  s1.loss_mask: 0.1126  s2.loss_cls: 0.0411  s2.acc: 98.0469  s2.loss_bbox: 0.0457  s2.loss_mask: 0.0532
2024/02/16 21:54:50 - mmengine - INFO - Epoch(train) [35][ 400/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:47:05  time: 0.7010  data_time: 0.0305  memory: 10191  loss: 1.2780  loss_rpn_cls: 0.0448  loss_rpn_bbox: 0.0342  s0.loss_cls: 0.2043  s0.acc: 93.5547  s0.loss_bbox: 0.2585  s0.loss_mask: 0.2566  s1.loss_cls: 0.0910  s1.acc: 92.9142  s1.loss_bbox: 0.1170  s1.loss_mask: 0.1251  s2.loss_cls: 0.0423  s2.acc: 94.4112  s2.loss_bbox: 0.0459  s2.loss_mask: 0.0583
2024/02/16 21:55:26 - mmengine - INFO - Epoch(train) [35][ 450/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:46:38  time: 0.7084  data_time: 0.0254  memory: 11383  loss: 1.1514  loss_rpn_cls: 0.0343  loss_rpn_bbox: 0.0238  s0.loss_cls: 0.1790  s0.acc: 94.6289  s0.loss_bbox: 0.2423  s0.loss_mask: 0.2402  s1.loss_cls: 0.0790  s1.acc: 96.5445  s1.loss_bbox: 0.1085  s1.loss_mask: 0.1134  s2.loss_cls: 0.0361  s2.acc: 96.8354  s2.loss_bbox: 0.0430  s2.loss_mask: 0.0517
2024/02/16 21:56:00 - mmengine - INFO - Epoch(train) [35][ 500/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:45:47  time: 0.6928  data_time: 0.0238  memory: 9491  loss: 1.2187  loss_rpn_cls: 0.0442  loss_rpn_bbox: 0.0280  s0.loss_cls: 0.1948  s0.acc: 93.3594  s0.loss_bbox: 0.2547  s0.loss_mask: 0.2484  s1.loss_cls: 0.0833  s1.acc: 93.7624  s1.loss_bbox: 0.1100  s1.loss_mask: 0.1185  s2.loss_cls: 0.0384  s2.acc: 91.7984  s2.loss_bbox: 0.0431  s2.loss_mask: 0.0551
2024/02/16 21:56:35 - mmengine - INFO - Epoch(train) [35][ 550/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:44:57  time: 0.6910  data_time: 0.0268  memory: 9368  loss: 1.1451  loss_rpn_cls: 0.0359  loss_rpn_bbox: 0.0271  s0.loss_cls: 0.1779  s0.acc: 97.5586  s0.loss_bbox: 0.2496  s0.loss_mask: 0.2229  s1.loss_cls: 0.0801  s1.acc: 98.2422  s1.loss_bbox: 0.1085  s1.loss_mask: 0.1095  s2.loss_cls: 0.0387  s2.acc: 96.8750  s2.loss_bbox: 0.0440  s2.loss_mask: 0.0508
2024/02/16 21:57:10 - mmengine - INFO - Epoch(train) [35][ 600/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:44:14  time: 0.6946  data_time: 0.0252  memory: 9454  loss: 1.1176  loss_rpn_cls: 0.0396  loss_rpn_bbox: 0.0252  s0.loss_cls: 0.1726  s0.acc: 96.5820  s0.loss_bbox: 0.2303  s0.loss_mask: 0.2272  s1.loss_cls: 0.0755  s1.acc: 97.4609  s1.loss_bbox: 0.1043  s1.loss_mask: 0.1116  s2.loss_cls: 0.0366  s2.acc: 95.5882  s2.loss_bbox: 0.0425  s2.loss_mask: 0.0521
2024/02/16 21:57:44 - mmengine - INFO - Epoch(train) [35][ 650/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:43:32  time: 0.6938  data_time: 0.0263  memory: 9737  loss: 1.1736  loss_rpn_cls: 0.0423  loss_rpn_bbox: 0.0307  s0.loss_cls: 0.1875  s0.acc: 97.1680  s0.loss_bbox: 0.2336  s0.loss_mask: 0.2398  s1.loss_cls: 0.0845  s1.acc: 97.9492  s1.loss_bbox: 0.1050  s1.loss_mask: 0.1167  s2.loss_cls: 0.0386  s2.acc: 97.2656  s2.loss_bbox: 0.0414  s2.loss_mask: 0.0536
2024/02/16 21:58:19 - mmengine - INFO - Epoch(train) [35][ 700/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:42:57  time: 0.7007  data_time: 0.0303  memory: 10977  loss: 1.1655  loss_rpn_cls: 0.0403  loss_rpn_bbox: 0.0289  s0.loss_cls: 0.1856  s0.acc: 93.7500  s0.loss_bbox: 0.2440  s0.loss_mask: 0.2343  s1.loss_cls: 0.0780  s1.acc: 94.3456  s1.loss_bbox: 0.1066  s1.loss_mask: 0.1145  s2.loss_cls: 0.0368  s2.acc: 94.6409  s2.loss_bbox: 0.0425  s2.loss_mask: 0.0539
2024/02/16 21:58:54 - mmengine - INFO - Epoch(train) [35][ 750/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:42:14  time: 0.6923  data_time: 0.0274  memory: 9684  loss: 1.2268  loss_rpn_cls: 0.0366  loss_rpn_bbox: 0.0296  s0.loss_cls: 0.1881  s0.acc: 95.0195  s0.loss_bbox: 0.2540  s0.loss_mask: 0.2540  s1.loss_cls: 0.0823  s1.acc: 96.6868  s1.loss_bbox: 0.1134  s1.loss_mask: 0.1245  s2.loss_cls: 0.0403  s2.acc: 96.0883  s2.loss_bbox: 0.0453  s2.loss_mask: 0.0587
2024/02/16 21:59:14 - mmengine - INFO - Exp name: cascade_mask_rcnn_swin_tiny_patch4_window7_mstrain_480-800_giou_4conv1f_adamw_3x_coco_20240216_214910
2024/02/16 21:59:28 - mmengine - INFO - Epoch(train) [35][ 800/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:41:20  time: 0.6773  data_time: 0.0261  memory: 9249  loss: 1.1589  loss_rpn_cls: 0.0385  loss_rpn_bbox: 0.0240  s0.loss_cls: 0.1773  s0.acc: 98.3398  s0.loss_bbox: 0.2353  s0.loss_mask: 0.2442  s1.loss_cls: 0.0811  s1.acc: 98.7305  s1.loss_bbox: 0.1049  s1.loss_mask: 0.1190  s2.loss_cls: 0.0367  s2.acc: 98.5352  s2.loss_bbox: 0.0418  s2.loss_mask: 0.0560
2024/02/16 22:00:02 - mmengine - INFO - Epoch(train) [35][ 850/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:40:33  time: 0.6839  data_time: 0.0259  memory: 10060  loss: 1.1736  loss_rpn_cls: 0.0420  loss_rpn_bbox: 0.0314  s0.loss_cls: 0.1891  s0.acc: 86.8164  s0.loss_bbox: 0.2456  s0.loss_mask: 0.2319  s1.loss_cls: 0.0811  s1.acc: 89.9177  s1.loss_bbox: 0.1075  s1.loss_mask: 0.1135  s2.loss_cls: 0.0374  s2.acc: 90.3392  s2.loss_bbox: 0.0418  s2.loss_mask: 0.0522
2024/02/16 22:00:37 - mmengine - INFO - Epoch(train) [35][ 900/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:39:53  time: 0.6904  data_time: 0.0244  memory: 9388  loss: 0.9767  loss_rpn_cls: 0.0306  loss_rpn_bbox: 0.0212  s0.loss_cls: 0.1367  s0.acc: 95.4102  s0.loss_bbox: 0.1975  s0.loss_mask: 0.2138  s1.loss_cls: 0.0625  s1.acc: 94.8242  s1.loss_bbox: 0.0911  s1.loss_mask: 0.1049  s2.loss_cls: 0.0297  s2.acc: 95.1172  s2.loss_bbox: 0.0387  s2.loss_mask: 0.0500
2024/02/16 22:01:11 - mmengine - INFO - Epoch(train) [35][ 950/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:39:14  time: 0.6921  data_time: 0.0289  memory: 9747  loss: 1.2957  loss_rpn_cls: 0.0444  loss_rpn_bbox: 0.0311  s0.loss_cls: 0.2103  s0.acc: 95.6055  s0.loss_bbox: 0.2777  s0.loss_mask: 0.2437  s1.loss_cls: 0.0930  s1.acc: 98.3398  s1.loss_bbox: 0.1246  s1.loss_mask: 0.1207  s2.loss_cls: 0.0438  s2.acc: 97.9492  s2.loss_bbox: 0.0494  s2.loss_mask: 0.0569
2024/02/16 22:01:46 - mmengine - INFO - Epoch(train) [35][1000/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:38:35  time: 0.6909  data_time: 0.0253  memory: 9513  loss: 1.2140  loss_rpn_cls: 0.0395  loss_rpn_bbox: 0.0282  s0.loss_cls: 0.1851  s0.acc: 98.4375  s0.loss_bbox: 0.2476  s0.loss_mask: 0.2543  s1.loss_cls: 0.0866  s1.acc: 98.2422  s1.loss_bbox: 0.1090  s1.loss_mask: 0.1230  s2.loss_cls: 0.0414  s2.acc: 98.7305  s2.loss_bbox: 0.0427  s2.loss_mask: 0.0565
2024/02/16 22:02:20 - mmengine - INFO - Epoch(train) [35][1050/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:37:55  time: 0.6888  data_time: 0.0229  memory: 10236  loss: 1.0778  loss_rpn_cls: 0.0411  loss_rpn_bbox: 0.0275  s0.loss_cls: 0.1581  s0.acc: 90.3320  s0.loss_bbox: 0.2137  s0.loss_mask: 0.2356  s1.loss_cls: 0.0669  s1.acc: 92.5234  s1.loss_bbox: 0.0969  s1.loss_mask: 0.1132  s2.loss_cls: 0.0315  s2.acc: 91.0031  s2.loss_bbox: 0.0406  s2.loss_mask: 0.0527
2024/02/16 22:02:55 - mmengine - INFO - Epoch(train) [35][1100/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:37:19  time: 0.6933  data_time: 0.0258  memory: 9781  loss: 1.1164  loss_rpn_cls: 0.0468  loss_rpn_bbox: 0.0280  s0.loss_cls: 0.1638  s0.acc: 97.4609  s0.loss_bbox: 0.2225  s0.loss_mask: 0.2389  s1.loss_cls: 0.0733  s1.acc: 96.7773  s1.loss_bbox: 0.0999  s1.loss_mask: 0.1154  s2.loss_cls: 0.0339  s2.acc: 96.9727  s2.loss_bbox: 0.0397  s2.loss_mask: 0.0542
2024/02/16 22:03:29 - mmengine - INFO - Epoch(train) [35][1150/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:36:34  time: 0.6796  data_time: 0.0274  memory: 10003  loss: 1.2562  loss_rpn_cls: 0.0492  loss_rpn_bbox: 0.0315  s0.loss_cls: 0.1962  s0.acc: 92.0898  s0.loss_bbox: 0.2578  s0.loss_mask: 0.2576  s1.loss_cls: 0.0870  s1.acc: 90.5906  s1.loss_bbox: 0.1116  s1.loss_mask: 0.1236  s2.loss_cls: 0.0416  s2.acc: 91.9000  s2.loss_bbox: 0.0425  s2.loss_mask: 0.0576
2024/02/16 22:04:04 - mmengine - INFO - Epoch(train) [35][1200/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:35:59  time: 0.6938  data_time: 0.0262  memory: 9477  loss: 1.1244  loss_rpn_cls: 0.0397  loss_rpn_bbox: 0.0261  s0.loss_cls: 0.1894  s0.acc: 99.0234  s0.loss_bbox: 0.2305  s0.loss_mask: 0.2219  s1.loss_cls: 0.0831  s1.acc: 98.7305  s1.loss_bbox: 0.1010  s1.loss_mask: 0.1048  s2.loss_cls: 0.0383  s2.acc: 99.7070  s2.loss_bbox: 0.0406  s2.loss_mask: 0.0490
2024/02/16 22:04:38 - mmengine - INFO - Epoch(train) [35][1250/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:35:21  time: 0.6905  data_time: 0.0261  memory: 9622  loss: 1.2392  loss_rpn_cls: 0.0458  loss_rpn_bbox: 0.0284  s0.loss_cls: 0.2103  s0.acc: 91.7969  s0.loss_bbox: 0.2518  s0.loss_mask: 0.2390  s1.loss_cls: 0.0932  s1.acc: 94.1406  s1.loss_bbox: 0.1119  s1.loss_mask: 0.1164  s2.loss_cls: 0.0426  s2.acc: 96.2891  s2.loss_bbox: 0.0452  s2.loss_mask: 0.0547
2024/02/16 22:05:13 - mmengine - INFO - Epoch(train) [35][1300/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:34:42  time: 0.6869  data_time: 0.0251  memory: 9636  loss: 1.1532  loss_rpn_cls: 0.0363  loss_rpn_bbox: 0.0245  s0.loss_cls: 0.1725  s0.acc: 94.6289  s0.loss_bbox: 0.2447  s0.loss_mask: 0.2354  s1.loss_cls: 0.0751  s1.acc: 94.0430  s1.loss_bbox: 0.1137  s1.loss_mask: 0.1156  s2.loss_cls: 0.0357  s2.acc: 96.0938  s2.loss_bbox: 0.0456  s2.loss_mask: 0.0542
2024/02/16 22:05:47 - mmengine - INFO - Epoch(train) [35][1350/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:34:07  time: 0.6934  data_time: 0.0316  memory: 9905  loss: 1.2195  loss_rpn_cls: 0.0494  loss_rpn_bbox: 0.0341  s0.loss_cls: 0.1907  s0.acc: 95.5078  s0.loss_bbox: 0.2578  s0.loss_mask: 0.2337  s1.loss_cls: 0.0851  s1.acc: 96.8496  s1.loss_bbox: 0.1147  s1.loss_mask: 0.1134  s2.loss_cls: 0.0412  s2.acc: 97.4671  s2.loss_bbox: 0.0459  s2.loss_mask: 0.0535
2024/02/16 22:06:22 - mmengine - INFO - Epoch(train) [35][1400/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:33:30  time: 0.6907  data_time: 0.0271  memory: 9752  loss: 1.2289  loss_rpn_cls: 0.0523  loss_rpn_bbox: 0.0288  s0.loss_cls: 0.1980  s0.acc: 92.5781  s0.loss_bbox: 0.2543  s0.loss_mask: 0.2392  s1.loss_cls: 0.0833  s1.acc: 93.1641  s1.loss_bbox: 0.1147  s1.loss_mask: 0.1175  s2.loss_cls: 0.0401  s2.acc: 95.1172  s2.loss_bbox: 0.0460  s2.loss_mask: 0.0548
2024/02/16 22:06:57 - mmengine - INFO - Epoch(train) [35][1450/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:32:54  time: 0.6917  data_time: 0.0296  memory: 9360  loss: 1.1489  loss_rpn_cls: 0.0456  loss_rpn_bbox: 0.0322  s0.loss_cls: 0.1740  s0.acc: 98.6328  s0.loss_bbox: 0.2411  s0.loss_mask: 0.2232  s1.loss_cls: 0.0774  s1.acc: 98.3398  s1.loss_bbox: 0.1098  s1.loss_mask: 0.1104  s2.loss_cls: 0.0374  s2.acc: 97.5586  s2.loss_bbox: 0.0451  s2.loss_mask: 0.0526
2024/02/16 22:07:31 - mmengine - INFO - Epoch(train) [35][1500/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:32:17  time: 0.6898  data_time: 0.0264  memory: 9712  loss: 1.2543  loss_rpn_cls: 0.0443  loss_rpn_bbox: 0.0306  s0.loss_cls: 0.1969  s0.acc: 94.1406  s0.loss_bbox: 0.2582  s0.loss_mask: 0.2575  s1.loss_cls: 0.0860  s1.acc: 95.4102  s1.loss_bbox: 0.1123  s1.loss_mask: 0.1251  s2.loss_cls: 0.0413  s2.acc: 96.1914  s2.loss_bbox: 0.0431  s2.loss_mask: 0.0590
2024/02/16 22:08:05 - mmengine - INFO - Epoch(train) [35][1550/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:31:36  time: 0.6796  data_time: 0.0238  memory: 9306  loss: 1.2115  loss_rpn_cls: 0.0401  loss_rpn_bbox: 0.0264  s0.loss_cls: 0.1963  s0.acc: 93.4570  s0.loss_bbox: 0.2584  s0.loss_mask: 0.2362  s1.loss_cls: 0.0859  s1.acc: 93.2485  s1.loss_bbox: 0.1137  s1.loss_mask: 0.1153  s2.loss_cls: 0.0411  s2.acc: 94.2346  s2.loss_bbox: 0.0438  s2.loss_mask: 0.0544
2024/02/16 22:08:39 - mmengine - INFO - Epoch(train) [35][1600/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:30:56  time: 0.6791  data_time: 0.0258  memory: 9258  loss: 1.1941  loss_rpn_cls: 0.0380  loss_rpn_bbox: 0.0275  s0.loss_cls: 0.1795  s0.acc: 99.2188  s0.loss_bbox: 0.2419  s0.loss_mask: 0.2601  s1.loss_cls: 0.0844  s1.acc: 99.3164  s1.loss_bbox: 0.1029  s1.loss_mask: 0.1251  s2.loss_cls: 0.0389  s2.acc: 99.4141  s2.loss_bbox: 0.0389  s2.loss_mask: 0.0570
2024/02/16 22:09:14 - mmengine - INFO - Epoch(train) [35][1650/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:30:19  time: 0.6890  data_time: 0.0250  memory: 9726  loss: 1.2002  loss_rpn_cls: 0.0451  loss_rpn_bbox: 0.0255  s0.loss_cls: 0.1859  s0.acc: 99.1211  s0.loss_bbox: 0.2435  s0.loss_mask: 0.2582  s1.loss_cls: 0.0803  s1.acc: 98.8281  s1.loss_bbox: 0.1040  s1.loss_mask: 0.1229  s2.loss_cls: 0.0373  s2.acc: 99.7070  s2.loss_bbox: 0.0405  s2.loss_mask: 0.0568
2024/02/16 22:09:49 - mmengine - INFO - Epoch(train) [35][1700/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:29:50  time: 0.7088  data_time: 0.0259  memory: 9163  loss: 1.2666  loss_rpn_cls: 0.0432  loss_rpn_bbox: 0.0333  s0.loss_cls: 0.1973  s0.acc: 91.5039  s0.loss_bbox: 0.2645  s0.loss_mask: 0.2599  s1.loss_cls: 0.0846  s1.acc: 90.0099  s1.loss_bbox: 0.1168  s1.loss_mask: 0.1253  s2.loss_cls: 0.0392  s2.acc: 91.8570  s2.loss_bbox: 0.0449  s2.loss_mask: 0.0575
2024/02/16 22:10:24 - mmengine - INFO - Epoch(train) [35][1750/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:29:14  time: 0.6896  data_time: 0.0259  memory: 9639  loss: 1.2631  loss_rpn_cls: 0.0468  loss_rpn_bbox: 0.0309  s0.loss_cls: 0.1985  s0.acc: 92.9688  s0.loss_bbox: 0.2691  s0.loss_mask: 0.2466  s1.loss_cls: 0.0872  s1.acc: 92.7919  s1.loss_bbox: 0.1190  s1.loss_mask: 0.1202  s2.loss_cls: 0.0416  s2.acc: 94.9083  s2.loss_bbox: 0.0470  s2.loss_mask: 0.0562
2024/02/16 22:10:44 - mmengine - INFO - Exp name: cascade_mask_rcnn_swin_tiny_patch4_window7_mstrain_480-800_giou_4conv1f_adamw_3x_coco_20240216_214910
2024/02/16 22:10:58 - mmengine - INFO - Epoch(train) [35][1800/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:28:38  time: 0.6897  data_time: 0.0249  memory: 9216  loss: 1.1538  loss_rpn_cls: 0.0300  loss_rpn_bbox: 0.0269  s0.loss_cls: 0.1859  s0.acc: 96.8750  s0.loss_bbox: 0.2487  s0.loss_mask: 0.2267  s1.loss_cls: 0.0821  s1.acc: 96.0938  s1.loss_bbox: 0.1107  s1.loss_mask: 0.1078  s2.loss_cls: 0.0387  s2.acc: 96.7773  s2.loss_bbox: 0.0451  s2.loss_mask: 0.0511
2024/02/16 22:11:33 - mmengine - INFO - Epoch(train) [35][1850/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:28:02  time: 0.6891  data_time: 0.0241  memory: 9505  loss: 1.1688  loss_rpn_cls: 0.0404  loss_rpn_bbox: 0.0298  s0.loss_cls: 0.1780  s0.acc: 91.2109  s0.loss_bbox: 0.2462  s0.loss_mask: 0.2388  s1.loss_cls: 0.0759  s1.acc: 92.5049  s1.loss_bbox: 0.1106  s1.loss_mask: 0.1160  s2.loss_cls: 0.0359  s2.acc: 94.3842  s2.loss_bbox: 0.0434  s2.loss_mask: 0.0538
2024/02/16 22:12:07 - mmengine - INFO - Epoch(train) [35][1900/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:27:24  time: 0.6831  data_time: 0.0241  memory: 10403  loss: 1.1448  loss_rpn_cls: 0.0371  loss_rpn_bbox: 0.0263  s0.loss_cls: 0.1821  s0.acc: 97.1680  s0.loss_bbox: 0.2385  s0.loss_mask: 0.2349  s1.loss_cls: 0.0781  s1.acc: 98.3398  s1.loss_bbox: 0.1028  s1.loss_mask: 0.1138  s2.loss_cls: 0.0371  s2.acc: 99.3164  s2.loss_bbox: 0.0412  s2.loss_mask: 0.0530
2024/02/16 22:12:41 - mmengine - INFO - Epoch(train) [35][1950/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:26:48  time: 0.6897  data_time: 0.0262  memory: 9386  loss: 1.1675  loss_rpn_cls: 0.0366  loss_rpn_bbox: 0.0256  s0.loss_cls: 0.1889  s0.acc: 86.6211  s0.loss_bbox: 0.2421  s0.loss_mask: 0.2336  s1.loss_cls: 0.0844  s1.acc: 88.0490  s1.loss_bbox: 0.1085  s1.loss_mask: 0.1140  s2.loss_cls: 0.0397  s2.acc: 88.2110  s2.loss_bbox: 0.0405  s2.loss_mask: 0.0536
2024/02/16 22:13:16 - mmengine - INFO - Epoch(train) [35][2000/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:26:12  time: 0.6889  data_time: 0.0267  memory: 9958  loss: 1.2503  loss_rpn_cls: 0.0486  loss_rpn_bbox: 0.0322  s0.loss_cls: 0.1967  s0.acc: 96.2891  s0.loss_bbox: 0.2685  s0.loss_mask: 0.2355  s1.loss_cls: 0.0885  s1.acc: 95.8984  s1.loss_bbox: 0.1202  s1.loss_mask: 0.1149  s2.loss_cls: 0.0425  s2.acc: 96.0938  s2.loss_bbox: 0.0483  s2.loss_mask: 0.0545
2024/02/16 22:13:50 - mmengine - INFO - Epoch(train) [35][2050/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:25:36  time: 0.6877  data_time: 0.0241  memory: 9069  loss: 1.1937  loss_rpn_cls: 0.0395  loss_rpn_bbox: 0.0281  s0.loss_cls: 0.1881  s0.acc: 97.5586  s0.loss_bbox: 0.2443  s0.loss_mask: 0.2496  s1.loss_cls: 0.0832  s1.acc: 98.2422  s1.loss_bbox: 0.1058  s1.loss_mask: 0.1185  s2.loss_cls: 0.0398  s2.acc: 98.0469  s2.loss_bbox: 0.0414  s2.loss_mask: 0.0555
2024/02/16 22:14:24 - mmengine - INFO - Epoch(train) [35][2100/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:24:59  time: 0.6856  data_time: 0.0272  memory: 10013  loss: 1.2942  loss_rpn_cls: 0.0420  loss_rpn_bbox: 0.0277  s0.loss_cls: 0.2084  s0.acc: 91.2109  s0.loss_bbox: 0.2785  s0.loss_mask: 0.2522  s1.loss_cls: 0.0925  s1.acc: 92.8210  s1.loss_bbox: 0.1217  s1.loss_mask: 0.1226  s2.loss_cls: 0.0421  s2.acc: 92.3387  s2.loss_bbox: 0.0482  s2.loss_mask: 0.0583
2024/02/16 22:14:59 - mmengine - INFO - Epoch(train) [35][2150/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:24:21  time: 0.6817  data_time: 0.0265  memory: 9899  loss: 1.2883  loss_rpn_cls: 0.0447  loss_rpn_bbox: 0.0296  s0.loss_cls: 0.2052  s0.acc: 93.3594  s0.loss_bbox: 0.2657  s0.loss_mask: 0.2645  s1.loss_cls: 0.0921  s1.acc: 91.9922  s1.loss_bbox: 0.1150  s1.loss_mask: 0.1262  s2.loss_cls: 0.0427  s2.acc: 94.0430  s2.loss_bbox: 0.0445  s2.loss_mask: 0.0581
2024/02/16 22:15:33 - mmengine - INFO - Epoch(train) [35][2200/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:23:46  time: 0.6888  data_time: 0.0266  memory: 9613  loss: 1.1702  loss_rpn_cls: 0.0339  loss_rpn_bbox: 0.0244  s0.loss_cls: 0.1842  s0.acc: 93.3594  s0.loss_bbox: 0.2348  s0.loss_mask: 0.2502  s1.loss_cls: 0.0828  s1.acc: 93.5547  s1.loss_bbox: 0.1026  s1.loss_mask: 0.1218  s2.loss_cls: 0.0384  s2.acc: 93.6523  s2.loss_bbox: 0.0411  s2.loss_mask: 0.0560
2024/02/16 22:16:07 - mmengine - INFO - Epoch(train) [35][2250/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:23:09  time: 0.6860  data_time: 0.0283  memory: 9230  loss: 1.2211  loss_rpn_cls: 0.0458  loss_rpn_bbox: 0.0280  s0.loss_cls: 0.1892  s0.acc: 91.3086  s0.loss_bbox: 0.2520  s0.loss_mask: 0.2521  s1.loss_cls: 0.0798  s1.acc: 91.5591  s1.loss_bbox: 0.1133  s1.loss_mask: 0.1203  s2.loss_cls: 0.0391  s2.acc: 91.2785  s2.loss_bbox: 0.0456  s2.loss_mask: 0.0557
2024/02/16 22:16:41 - mmengine - INFO - Epoch(train) [35][2300/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:22:31  time: 0.6802  data_time: 0.0265  memory: 9423  loss: 1.1514  loss_rpn_cls: 0.0394  loss_rpn_bbox: 0.0274  s0.loss_cls: 0.1732  s0.acc: 97.7539  s0.loss_bbox: 0.2270  s0.loss_mask: 0.2542  s1.loss_cls: 0.0770  s1.acc: 99.3164  s1.loss_bbox: 0.1012  s1.loss_mask: 0.1192  s2.loss_cls: 0.0364  s2.acc: 99.1211  s2.loss_bbox: 0.0411  s2.loss_mask: 0.0555
2024/02/16 22:17:16 - mmengine - INFO - Epoch(train) [35][2350/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:21:57  time: 0.6920  data_time: 0.0266  memory: 9779  loss: 1.2031  loss_rpn_cls: 0.0355  loss_rpn_bbox: 0.0288  s0.loss_cls: 0.1941  s0.acc: 98.1445  s0.loss_bbox: 0.2446  s0.loss_mask: 0.2477  s1.loss_cls: 0.0859  s1.acc: 98.9258  s1.loss_bbox: 0.1086  s1.loss_mask: 0.1191  s2.loss_cls: 0.0400  s2.acc: 99.1211  s2.loss_bbox: 0.0431  s2.loss_mask: 0.0557
2024/02/16 22:17:51 - mmengine - INFO - Epoch(train) [35][2400/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:21:23  time: 0.6944  data_time: 0.0255  memory: 9633  loss: 1.2607  loss_rpn_cls: 0.0400  loss_rpn_bbox: 0.0258  s0.loss_cls: 0.1935  s0.acc: 93.7500  s0.loss_bbox: 0.2688  s0.loss_mask: 0.2549  s1.loss_cls: 0.0883  s1.acc: 93.8053  s1.loss_bbox: 0.1198  s1.loss_mask: 0.1237  s2.loss_cls: 0.0408  s2.acc: 93.0255  s2.loss_bbox: 0.0470  s2.loss_mask: 0.0580
2024/02/16 22:18:25 - mmengine - INFO - Epoch(train) [35][2450/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:20:45  time: 0.6792  data_time: 0.0243  memory: 9374  loss: 1.1950  loss_rpn_cls: 0.0362  loss_rpn_bbox: 0.0261  s0.loss_cls: 0.1787  s0.acc: 92.1875  s0.loss_bbox: 0.2478  s0.loss_mask: 0.2572  s1.loss_cls: 0.0809  s1.acc: 94.3359  s1.loss_bbox: 0.1091  s1.loss_mask: 0.1228  s2.loss_cls: 0.0394  s2.acc: 96.4844  s2.loss_bbox: 0.0411  s2.loss_mask: 0.0558
2024/02/16 22:18:59 - mmengine - INFO - Epoch(train) [35][2500/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:20:10  time: 0.6894  data_time: 0.0266  memory: 10357  loss: 1.2232  loss_rpn_cls: 0.0518  loss_rpn_bbox: 0.0341  s0.loss_cls: 0.1884  s0.acc: 97.0703  s0.loss_bbox: 0.2486  s0.loss_mask: 0.2446  s1.loss_cls: 0.0832  s1.acc: 97.5586  s1.loss_bbox: 0.1094  s1.loss_mask: 0.1213  s2.loss_cls: 0.0401  s2.acc: 98.2422  s2.loss_bbox: 0.0445  s2.loss_mask: 0.0571
2024/02/16 22:19:33 - mmengine - INFO - Epoch(train) [35][2550/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:19:33  time: 0.6801  data_time: 0.0239  memory: 9383  loss: 1.1158  loss_rpn_cls: 0.0353  loss_rpn_bbox: 0.0248  s0.loss_cls: 0.1749  s0.acc: 93.6523  s0.loss_bbox: 0.2208  s0.loss_mask: 0.2381  s1.loss_cls: 0.0779  s1.acc: 94.8847  s1.loss_bbox: 0.0986  s1.loss_mask: 0.1148  s2.loss_cls: 0.0366  s2.acc: 94.0000  s2.loss_bbox: 0.0401  s2.loss_mask: 0.0539
2024/02/16 22:20:08 - mmengine - INFO - Epoch(train) [35][2600/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:18:59  time: 0.6942  data_time: 0.0260  memory: 9677  loss: 1.2660  loss_rpn_cls: 0.0471  loss_rpn_bbox: 0.0354  s0.loss_cls: 0.2177  s0.acc: 94.5312  s0.loss_bbox: 0.2662  s0.loss_mask: 0.2352  s1.loss_cls: 0.0941  s1.acc: 95.4102  s1.loss_bbox: 0.1156  s1.loss_mask: 0.1143  s2.loss_cls: 0.0429  s2.acc: 92.8711  s2.loss_bbox: 0.0442  s2.loss_mask: 0.0533
2024/02/16 22:20:43 - mmengine - INFO - Epoch(train) [35][2650/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:18:24  time: 0.6913  data_time: 0.0265  memory: 9367  loss: 1.2004  loss_rpn_cls: 0.0371  loss_rpn_bbox: 0.0259  s0.loss_cls: 0.1909  s0.acc: 92.8711  s0.loss_bbox: 0.2555  s0.loss_mask: 0.2380  s1.loss_cls: 0.0863  s1.acc: 94.1825  s1.loss_bbox: 0.1155  s1.loss_mask: 0.1147  s2.loss_cls: 0.0383  s2.acc: 94.8692  s2.loss_bbox: 0.0450  s2.loss_mask: 0.0531
2024/02/16 22:21:17 - mmengine - INFO - Epoch(train) [35][2700/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:17:49  time: 0.6910  data_time: 0.0265  memory: 9683  loss: 1.1369  loss_rpn_cls: 0.0416  loss_rpn_bbox: 0.0318  s0.loss_cls: 0.1732  s0.acc: 94.6289  s0.loss_bbox: 0.2300  s0.loss_mask: 0.2348  s1.loss_cls: 0.0759  s1.acc: 96.0938  s1.loss_bbox: 0.1037  s1.loss_mask: 0.1150  s2.loss_cls: 0.0368  s2.acc: 96.8750  s2.loss_bbox: 0.0402  s2.loss_mask: 0.0538
2024/02/16 22:21:51 - mmengine - INFO - Epoch(train) [35][2750/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:17:13  time: 0.6833  data_time: 0.0264  memory: 9692  loss: 1.1189  loss_rpn_cls: 0.0380  loss_rpn_bbox: 0.0246  s0.loss_cls: 0.1707  s0.acc: 92.3828  s0.loss_bbox: 0.2335  s0.loss_mask: 0.2247  s1.loss_cls: 0.0767  s1.acc: 93.9168  s1.loss_bbox: 0.1060  s1.loss_mask: 0.1111  s2.loss_cls: 0.0380  s2.acc: 93.0811  s2.loss_bbox: 0.0429  s2.loss_mask: 0.0526
2024/02/16 22:22:12 - mmengine - INFO - Exp name: cascade_mask_rcnn_swin_tiny_patch4_window7_mstrain_480-800_giou_4conv1f_adamw_3x_coco_20240216_214910
2024/02/16 22:22:26 - mmengine - INFO - Epoch(train) [35][2800/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:16:37  time: 0.6840  data_time: 0.0257  memory: 9747  loss: 1.0807  loss_rpn_cls: 0.0351  loss_rpn_bbox: 0.0228  s0.loss_cls: 0.1579  s0.acc: 92.7734  s0.loss_bbox: 0.2239  s0.loss_mask: 0.2317  s1.loss_cls: 0.0689  s1.acc: 95.3125  s1.loss_bbox: 0.1014  s1.loss_mask: 0.1133  s2.loss_cls: 0.0326  s2.acc: 94.2383  s2.loss_bbox: 0.0404  s2.loss_mask: 0.0527
2024/02/16 22:23:00 - mmengine - INFO - Epoch(train) [35][2850/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:16:03  time: 0.6932  data_time: 0.0267  memory: 9742  loss: 1.2186  loss_rpn_cls: 0.0359  loss_rpn_bbox: 0.0296  s0.loss_cls: 0.1969  s0.acc: 88.6719  s0.loss_bbox: 0.2523  s0.loss_mask: 0.2446  s1.loss_cls: 0.0895  s1.acc: 89.6951  s1.loss_bbox: 0.1131  s1.loss_mask: 0.1185  s2.loss_cls: 0.0398  s2.acc: 89.8747  s2.loss_bbox: 0.0434  s2.loss_mask: 0.0550
2024/02/16 22:23:35 - mmengine - INFO - Epoch(train) [35][2900/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:15:29  time: 0.6926  data_time: 0.0261  memory: 9386  loss: 1.1815  loss_rpn_cls: 0.0500  loss_rpn_bbox: 0.0300  s0.loss_cls: 0.1803  s0.acc: 95.7031  s0.loss_bbox: 0.2430  s0.loss_mask: 0.2350  s1.loss_cls: 0.0820  s1.acc: 97.4609  s1.loss_bbox: 0.1093  s1.loss_mask: 0.1166  s2.loss_cls: 0.0368  s2.acc: 97.9492  s2.loss_bbox: 0.0443  s2.loss_mask: 0.0543
2024/02/16 22:24:10 - mmengine - INFO - Epoch(train) [35][2950/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:14:54  time: 0.6936  data_time: 0.0245  memory: 8830  loss: 1.1877  loss_rpn_cls: 0.0487  loss_rpn_bbox: 0.0287  s0.loss_cls: 0.1842  s0.acc: 98.3398  s0.loss_bbox: 0.2363  s0.loss_mask: 0.2444  s1.loss_cls: 0.0845  s1.acc: 98.4375  s1.loss_bbox: 0.1069  s1.loss_mask: 0.1181  s2.loss_cls: 0.0395  s2.acc: 97.6562  s2.loss_bbox: 0.0422  s2.loss_mask: 0.0542
2024/02/16 22:24:45 - mmengine - INFO - Epoch(train) [35][3000/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:14:21  time: 0.6962  data_time: 0.0259  memory: 9576  loss: 1.1939  loss_rpn_cls: 0.0460  loss_rpn_bbox: 0.0253  s0.loss_cls: 0.1861  s0.acc: 99.1211  s0.loss_bbox: 0.2445  s0.loss_mask: 0.2486  s1.loss_cls: 0.0804  s1.acc: 97.9492  s1.loss_bbox: 0.1098  s1.loss_mask: 0.1195  s2.loss_cls: 0.0364  s2.acc: 99.5117  s2.loss_bbox: 0.0425  s2.loss_mask: 0.0548
2024/02/16 22:25:19 - mmengine - INFO - Epoch(train) [35][3050/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:13:46  time: 0.6901  data_time: 0.0287  memory: 9487  loss: 1.2267  loss_rpn_cls: 0.0458  loss_rpn_bbox: 0.0278  s0.loss_cls: 0.2022  s0.acc: 87.9883  s0.loss_bbox: 0.2597  s0.loss_mask: 0.2410  s1.loss_cls: 0.0876  s1.acc: 89.1602  s1.loss_bbox: 0.1118  s1.loss_mask: 0.1140  s2.loss_cls: 0.0397  s2.acc: 90.8203  s2.loss_bbox: 0.0441  s2.loss_mask: 0.0528
2024/02/16 22:25:53 - mmengine - INFO - Epoch(train) [35][3100/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:13:10  time: 0.6831  data_time: 0.0277  memory: 9520  loss: 1.2556  loss_rpn_cls: 0.0451  loss_rpn_bbox: 0.0266  s0.loss_cls: 0.2040  s0.acc: 91.1133  s0.loss_bbox: 0.2573  s0.loss_mask: 0.2493  s1.loss_cls: 0.0915  s1.acc: 91.8245  s1.loss_bbox: 0.1150  s1.loss_mask: 0.1229  s2.loss_cls: 0.0435  s2.acc: 91.8570  s2.loss_bbox: 0.0433  s2.loss_mask: 0.0572
2024/02/16 22:26:28 - mmengine - INFO - Epoch(train) [35][3150/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:12:35  time: 0.6866  data_time: 0.0250  memory: 8925  loss: 1.1236  loss_rpn_cls: 0.0304  loss_rpn_bbox: 0.0271  s0.loss_cls: 0.1615  s0.acc: 96.3867  s0.loss_bbox: 0.2337  s0.loss_mask: 0.2425  s1.loss_cls: 0.0711  s1.acc: 97.2973  s1.loss_bbox: 0.1059  s1.loss_mask: 0.1191  s2.loss_cls: 0.0339  s2.acc: 97.0588  s2.loss_bbox: 0.0426  s2.loss_mask: 0.0556
2024/02/16 22:27:01 - mmengine - INFO - Epoch(train) [35][3200/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:11:57  time: 0.6764  data_time: 0.0242  memory: 9479  loss: 1.1598  loss_rpn_cls: 0.0475  loss_rpn_bbox: 0.0309  s0.loss_cls: 0.1781  s0.acc: 96.8750  s0.loss_bbox: 0.2394  s0.loss_mask: 0.2395  s1.loss_cls: 0.0779  s1.acc: 96.9727  s1.loss_bbox: 0.1039  s1.loss_mask: 0.1133  s2.loss_cls: 0.0357  s2.acc: 97.2656  s2.loss_bbox: 0.0412  s2.loss_mask: 0.0523
2024/02/16 22:27:36 - mmengine - INFO - Epoch(train) [35][3250/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:11:22  time: 0.6839  data_time: 0.0242  memory: 11475  loss: 1.1672  loss_rpn_cls: 0.0422  loss_rpn_bbox: 0.0274  s0.loss_cls: 0.1740  s0.acc: 95.8008  s0.loss_bbox: 0.2397  s0.loss_mask: 0.2423  s1.loss_cls: 0.0769  s1.acc: 95.5135  s1.loss_bbox: 0.1104  s1.loss_mask: 0.1186  s2.loss_cls: 0.0353  s2.acc: 95.5224  s2.loss_bbox: 0.0442  s2.loss_mask: 0.0562
2024/02/16 22:28:10 - mmengine - INFO - Epoch(train) [35][3300/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:10:46  time: 0.6875  data_time: 0.0271  memory: 10636  loss: 1.1327  loss_rpn_cls: 0.0391  loss_rpn_bbox: 0.0276  s0.loss_cls: 0.1725  s0.acc: 91.5039  s0.loss_bbox: 0.2403  s0.loss_mask: 0.2289  s1.loss_cls: 0.0758  s1.acc: 93.0664  s1.loss_bbox: 0.1075  s1.loss_mask: 0.1102  s2.loss_cls: 0.0365  s2.acc: 93.1641  s2.loss_bbox: 0.0433  s2.loss_mask: 0.0511
2024/02/16 22:28:44 - mmengine - INFO - Epoch(train) [35][3350/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:10:11  time: 0.6835  data_time: 0.0237  memory: 9681  loss: 1.0831  loss_rpn_cls: 0.0284  loss_rpn_bbox: 0.0208  s0.loss_cls: 0.1656  s0.acc: 94.0430  s0.loss_bbox: 0.2228  s0.loss_mask: 0.2277  s1.loss_cls: 0.0725  s1.acc: 95.3094  s1.loss_bbox: 0.1010  s1.loss_mask: 0.1152  s2.loss_cls: 0.0348  s2.acc: 94.9153  s2.loss_bbox: 0.0402  s2.loss_mask: 0.0541
2024/02/16 22:29:19 - mmengine - INFO - Epoch(train) [35][3400/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:09:36  time: 0.6876  data_time: 0.0269  memory: 9594  loss: 1.2461  loss_rpn_cls: 0.0375  loss_rpn_bbox: 0.0317  s0.loss_cls: 0.1963  s0.acc: 95.7031  s0.loss_bbox: 0.2484  s0.loss_mask: 0.2682  s1.loss_cls: 0.0868  s1.acc: 97.0703  s1.loss_bbox: 0.1066  s1.loss_mask: 0.1280  s2.loss_cls: 0.0412  s2.acc: 95.6055  s2.loss_bbox: 0.0417  s2.loss_mask: 0.0596
2024/02/16 22:29:53 - mmengine - INFO - Epoch(train) [35][3450/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:09:02  time: 0.6934  data_time: 0.0276  memory: 9747  loss: 1.1725  loss_rpn_cls: 0.0471  loss_rpn_bbox: 0.0294  s0.loss_cls: 0.1904  s0.acc: 94.7266  s0.loss_bbox: 0.2470  s0.loss_mask: 0.2262  s1.loss_cls: 0.0814  s1.acc: 95.5078  s1.loss_bbox: 0.1076  s1.loss_mask: 0.1112  s2.loss_cls: 0.0375  s2.acc: 94.7266  s2.loss_bbox: 0.0424  s2.loss_mask: 0.0522
2024/02/16 22:30:28 - mmengine - INFO - Epoch(train) [35][3500/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:08:27  time: 0.6925  data_time: 0.0277  memory: 9313  loss: 1.1787  loss_rpn_cls: 0.0412  loss_rpn_bbox: 0.0290  s0.loss_cls: 0.1788  s0.acc: 96.6797  s0.loss_bbox: 0.2506  s0.loss_mask: 0.2379  s1.loss_cls: 0.0787  s1.acc: 98.3398  s1.loss_bbox: 0.1121  s1.loss_mask: 0.1159  s2.loss_cls: 0.0368  s2.acc: 96.4844  s2.loss_bbox: 0.0442  s2.loss_mask: 0.0535
2024/02/16 22:31:03 - mmengine - INFO - Epoch(train) [35][3550/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:07:53  time: 0.6922  data_time: 0.0261  memory: 9517  loss: 1.1643  loss_rpn_cls: 0.0504  loss_rpn_bbox: 0.0363  s0.loss_cls: 0.1895  s0.acc: 93.5547  s0.loss_bbox: 0.2353  s0.loss_mask: 0.2291  s1.loss_cls: 0.0812  s1.acc: 95.0195  s1.loss_bbox: 0.1032  s1.loss_mask: 0.1098  s2.loss_cls: 0.0388  s2.acc: 96.3867  s2.loss_bbox: 0.0405  s2.loss_mask: 0.0503
2024/02/16 22:31:37 - mmengine - INFO - Epoch(train) [35][3600/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:07:18  time: 0.6881  data_time: 0.0273  memory: 9707  loss: 1.1300  loss_rpn_cls: 0.0415  loss_rpn_bbox: 0.0285  s0.loss_cls: 0.1723  s0.acc: 98.9258  s0.loss_bbox: 0.2348  s0.loss_mask: 0.2287  s1.loss_cls: 0.0765  s1.acc: 99.5117  s1.loss_bbox: 0.1074  s1.loss_mask: 0.1109  s2.loss_cls: 0.0357  s2.acc: 99.7070  s2.loss_bbox: 0.0424  s2.loss_mask: 0.0513
2024/02/16 22:32:11 - mmengine - INFO - Epoch(train) [35][3650/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:06:42  time: 0.6809  data_time: 0.0260  memory: 9741  loss: 1.1982  loss_rpn_cls: 0.0472  loss_rpn_bbox: 0.0309  s0.loss_cls: 0.1827  s0.acc: 89.6484  s0.loss_bbox: 0.2589  s0.loss_mask: 0.2364  s1.loss_cls: 0.0821  s1.acc: 89.8438  s1.loss_bbox: 0.1136  s1.loss_mask: 0.1126  s2.loss_cls: 0.0380  s2.acc: 90.0391  s2.loss_bbox: 0.0437  s2.loss_mask: 0.0521
2024/02/16 22:32:45 - mmengine - INFO - Epoch(train) [35][3700/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:06:06  time: 0.6785  data_time: 0.0261  memory: 9863  loss: 1.1380  loss_rpn_cls: 0.0426  loss_rpn_bbox: 0.0244  s0.loss_cls: 0.1742  s0.acc: 87.5977  s0.loss_bbox: 0.2340  s0.loss_mask: 0.2358  s1.loss_cls: 0.0768  s1.acc: 88.3789  s1.loss_bbox: 0.1042  s1.loss_mask: 0.1151  s2.loss_cls: 0.0360  s2.acc: 87.1094  s2.loss_bbox: 0.0414  s2.loss_mask: 0.0535
2024/02/16 22:33:19 - mmengine - INFO - Epoch(train) [35][3750/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:05:30  time: 0.6840  data_time: 0.0284  memory: 9832  loss: 1.3389  loss_rpn_cls: 0.0506  loss_rpn_bbox: 0.0352  s0.loss_cls: 0.2182  s0.acc: 98.7305  s0.loss_bbox: 0.2838  s0.loss_mask: 0.2581  s1.loss_cls: 0.1011  s1.acc: 99.4141  s1.loss_bbox: 0.1206  s1.loss_mask: 0.1225  s2.loss_cls: 0.0466  s2.acc: 99.1211  s2.loss_bbox: 0.0459  s2.loss_mask: 0.0563
2024/02/16 22:33:40 - mmengine - INFO - Exp name: cascade_mask_rcnn_swin_tiny_patch4_window7_mstrain_480-800_giou_4conv1f_adamw_3x_coco_20240216_214910
2024/02/16 22:33:54 - mmengine - INFO - Epoch(train) [35][3800/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:04:55  time: 0.6848  data_time: 0.0253  memory: 9486  loss: 1.2341  loss_rpn_cls: 0.0372  loss_rpn_bbox: 0.0319  s0.loss_cls: 0.2028  s0.acc: 91.5039  s0.loss_bbox: 0.2562  s0.loss_mask: 0.2518  s1.loss_cls: 0.0867  s1.acc: 92.9577  s1.loss_bbox: 0.1098  s1.loss_mask: 0.1196  s2.loss_cls: 0.0405  s2.acc: 94.6894  s2.loss_bbox: 0.0420  s2.loss_mask: 0.0557
2024/02/16 22:34:28 - mmengine - INFO - Epoch(train) [35][3850/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:04:20  time: 0.6883  data_time: 0.0266  memory: 10269  loss: 1.2541  loss_rpn_cls: 0.0448  loss_rpn_bbox: 0.0351  s0.loss_cls: 0.2044  s0.acc: 93.7500  s0.loss_bbox: 0.2596  s0.loss_mask: 0.2387  s1.loss_cls: 0.0933  s1.acc: 94.4668  s1.loss_bbox: 0.1187  s1.loss_mask: 0.1162  s2.loss_cls: 0.0433  s2.acc: 94.5783  s2.loss_bbox: 0.0463  s2.loss_mask: 0.0538
2024/02/16 22:35:02 - mmengine - INFO - Epoch(train) [35][3900/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:03:44  time: 0.6776  data_time: 0.0253  memory: 9571  loss: 1.1606  loss_rpn_cls: 0.0434  loss_rpn_bbox: 0.0315  s0.loss_cls: 0.1780  s0.acc: 94.9219  s0.loss_bbox: 0.2418  s0.loss_mask: 0.2268  s1.loss_cls: 0.0800  s1.acc: 95.8008  s1.loss_bbox: 0.1105  s1.loss_mask: 0.1114  s2.loss_cls: 0.0388  s2.acc: 96.1914  s2.loss_bbox: 0.0450  s2.loss_mask: 0.0533
2024/02/16 22:35:37 - mmengine - INFO - Epoch(train) [35][3950/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:03:10  time: 0.6908  data_time: 0.0226  memory: 9564  loss: 1.1944  loss_rpn_cls: 0.0368  loss_rpn_bbox: 0.0265  s0.loss_cls: 0.1877  s0.acc: 90.0391  s0.loss_bbox: 0.2526  s0.loss_mask: 0.2450  s1.loss_cls: 0.0808  s1.acc: 92.7734  s1.loss_bbox: 0.1111  s1.loss_mask: 0.1172  s2.loss_cls: 0.0392  s2.acc: 92.2852  s2.loss_bbox: 0.0439  s2.loss_mask: 0.0536
2024/02/16 22:36:11 - mmengine - INFO - Epoch(train) [35][4000/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:02:35  time: 0.6852  data_time: 0.0219  memory: 10563  loss: 1.1430  loss_rpn_cls: 0.0368  loss_rpn_bbox: 0.0254  s0.loss_cls: 0.1783  s0.acc: 89.9414  s0.loss_bbox: 0.2267  s0.loss_mask: 0.2421  s1.loss_cls: 0.0803  s1.acc: 90.0695  s1.loss_bbox: 0.1025  s1.loss_mask: 0.1167  s2.loss_cls: 0.0385  s2.acc: 91.3776  s2.loss_bbox: 0.0409  s2.loss_mask: 0.0547
2024/02/16 22:36:45 - mmengine - INFO - Epoch(train) [35][4050/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:01:59  time: 0.6830  data_time: 0.0246  memory: 10109  loss: 1.1619  loss_rpn_cls: 0.0387  loss_rpn_bbox: 0.0301  s0.loss_cls: 0.1836  s0.acc: 90.9180  s0.loss_bbox: 0.2449  s0.loss_mask: 0.2315  s1.loss_cls: 0.0807  s1.acc: 93.5818  s1.loss_bbox: 0.1093  s1.loss_mask: 0.1094  s2.loss_cls: 0.0391  s2.acc: 92.4820  s2.loss_bbox: 0.0436  s2.loss_mask: 0.0510
2024/02/16 22:37:19 - mmengine - INFO - Epoch(train) [35][4100/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:01:23  time: 0.6762  data_time: 0.0246  memory: 10080  loss: 1.1054  loss_rpn_cls: 0.0363  loss_rpn_bbox: 0.0246  s0.loss_cls: 0.1701  s0.acc: 97.4609  s0.loss_bbox: 0.2210  s0.loss_mask: 0.2316  s1.loss_cls: 0.0777  s1.acc: 98.2422  s1.loss_bbox: 0.1029  s1.loss_mask: 0.1116  s2.loss_cls: 0.0375  s2.acc: 97.7539  s2.loss_bbox: 0.0404  s2.loss_mask: 0.0517
2024/02/16 22:37:53 - mmengine - INFO - Epoch(train) [35][4150/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:00:48  time: 0.6854  data_time: 0.0248  memory: 10022  loss: 1.2836  loss_rpn_cls: 0.0481  loss_rpn_bbox: 0.0300  s0.loss_cls: 0.2012  s0.acc: 93.7500  s0.loss_bbox: 0.2699  s0.loss_mask: 0.2619  s1.loss_cls: 0.0885  s1.acc: 95.4102  s1.loss_bbox: 0.1164  s1.loss_mask: 0.1247  s2.loss_cls: 0.0402  s2.acc: 93.9453  s2.loss_bbox: 0.0448  s2.loss_mask: 0.0578
2024/02/16 22:38:28 - mmengine - INFO - Epoch(train) [35][4200/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:00:13  time: 0.6906  data_time: 0.0244  memory: 9524  loss: 1.1709  loss_rpn_cls: 0.0409  loss_rpn_bbox: 0.0270  s0.loss_cls: 0.1793  s0.acc: 97.0703  s0.loss_bbox: 0.2528  s0.loss_mask: 0.2372  s1.loss_cls: 0.0759  s1.acc: 97.5586  s1.loss_bbox: 0.1117  s1.loss_mask: 0.1131  s2.loss_cls: 0.0364  s2.acc: 97.3633  s2.loss_bbox: 0.0443  s2.loss_mask: 0.0522
2024/02/16 22:39:02 - mmengine - INFO - Epoch(train) [35][4250/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:59:40  time: 0.6951  data_time: 0.0267  memory: 9526  loss: 1.2869  loss_rpn_cls: 0.0472  loss_rpn_bbox: 0.0295  s0.loss_cls: 0.2043  s0.acc: 96.9727  s0.loss_bbox: 0.2810  s0.loss_mask: 0.2490  s1.loss_cls: 0.0922  s1.acc: 96.9727  s1.loss_bbox: 0.1227  s1.loss_mask: 0.1178  s2.loss_cls: 0.0430  s2.acc: 95.7031  s2.loss_bbox: 0.0466  s2.loss_mask: 0.0536
2024/02/16 22:39:37 - mmengine - INFO - Epoch(train) [35][4300/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:59:05  time: 0.6917  data_time: 0.0265  memory: 9493  loss: 1.2366  loss_rpn_cls: 0.0503  loss_rpn_bbox: 0.0320  s0.loss_cls: 0.1992  s0.acc: 98.6328  s0.loss_bbox: 0.2539  s0.loss_mask: 0.2418  s1.loss_cls: 0.0894  s1.acc: 99.4141  s1.loss_bbox: 0.1112  s1.loss_mask: 0.1173  s2.loss_cls: 0.0423  s2.acc: 99.3164  s2.loss_bbox: 0.0441  s2.loss_mask: 0.0551
2024/02/16 22:40:12 - mmengine - INFO - Epoch(train) [35][4350/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:58:31  time: 0.6882  data_time: 0.0237  memory: 9270  loss: 1.1236  loss_rpn_cls: 0.0399  loss_rpn_bbox: 0.0236  s0.loss_cls: 0.1744  s0.acc: 93.2617  s0.loss_bbox: 0.2399  s0.loss_mask: 0.2234  s1.loss_cls: 0.0752  s1.acc: 94.2744  s1.loss_bbox: 0.1096  s1.loss_mask: 0.1086  s2.loss_cls: 0.0342  s2.acc: 95.2616  s2.loss_bbox: 0.0438  s2.loss_mask: 0.0511
2024/02/16 22:40:46 - mmengine - INFO - Epoch(train) [35][4400/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:57:57  time: 0.6925  data_time: 0.0237  memory: 8868  loss: 1.0931  loss_rpn_cls: 0.0306  loss_rpn_bbox: 0.0259  s0.loss_cls: 0.1745  s0.acc: 99.0234  s0.loss_bbox: 0.2135  s0.loss_mask: 0.2373  s1.loss_cls: 0.0762  s1.acc: 98.0469  s1.loss_bbox: 0.0948  s1.loss_mask: 0.1147  s2.loss_cls: 0.0354  s2.acc: 97.1680  s2.loss_bbox: 0.0371  s2.loss_mask: 0.0530
2024/02/16 22:41:20 - mmengine - INFO - Epoch(train) [35][4450/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:57:21  time: 0.6847  data_time: 0.0259  memory: 9540  loss: 1.1531  loss_rpn_cls: 0.0351  loss_rpn_bbox: 0.0263  s0.loss_cls: 0.1858  s0.acc: 83.6914  s0.loss_bbox: 0.2306  s0.loss_mask: 0.2400  s1.loss_cls: 0.0808  s1.acc: 83.0457  s1.loss_bbox: 0.1068  s1.loss_mask: 0.1135  s2.loss_cls: 0.0386  s2.acc: 86.3222  s2.loss_bbox: 0.0426  s2.loss_mask: 0.0530
2024/02/16 22:41:55 - mmengine - INFO - Epoch(train) [35][4500/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:56:46  time: 0.6852  data_time: 0.0252  memory: 9261  loss: 1.1558  loss_rpn_cls: 0.0348  loss_rpn_bbox: 0.0246  s0.loss_cls: 0.1741  s0.acc: 94.6289  s0.loss_bbox: 0.2377  s0.loss_mask: 0.2466  s1.loss_cls: 0.0783  s1.acc: 96.5820  s1.loss_bbox: 0.1060  s1.loss_mask: 0.1200  s2.loss_cls: 0.0384  s2.acc: 97.2656  s2.loss_bbox: 0.0403  s2.loss_mask: 0.0548
2024/02/16 22:42:29 - mmengine - INFO - Epoch(train) [35][4550/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:56:11  time: 0.6786  data_time: 0.0267  memory: 10079  loss: 1.2024  loss_rpn_cls: 0.0439  loss_rpn_bbox: 0.0263  s0.loss_cls: 0.1832  s0.acc: 89.7461  s0.loss_bbox: 0.2533  s0.loss_mask: 0.2433  s1.loss_cls: 0.0798  s1.acc: 89.9408  s1.loss_bbox: 0.1148  s1.loss_mask: 0.1188  s2.loss_cls: 0.0381  s2.acc: 90.4433  s2.loss_bbox: 0.0455  s2.loss_mask: 0.0552
2024/02/16 22:43:03 - mmengine - INFO - Epoch(train) [35][4600/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:55:36  time: 0.6847  data_time: 0.0261  memory: 9334  loss: 1.1881  loss_rpn_cls: 0.0482  loss_rpn_bbox: 0.0289  s0.loss_cls: 0.1844  s0.acc: 92.5781  s0.loss_bbox: 0.2495  s0.loss_mask: 0.2377  s1.loss_cls: 0.0793  s1.acc: 93.3532  s1.loss_bbox: 0.1115  s1.loss_mask: 0.1160  s2.loss_cls: 0.0371  s2.acc: 92.8713  s2.loss_bbox: 0.0426  s2.loss_mask: 0.0530
2024/02/16 22:43:37 - mmengine - INFO - Epoch(train) [35][4650/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:55:01  time: 0.6891  data_time: 0.0245  memory: 9641  loss: 1.1651  loss_rpn_cls: 0.0347  loss_rpn_bbox: 0.0243  s0.loss_cls: 0.1862  s0.acc: 92.0898  s0.loss_bbox: 0.2402  s0.loss_mask: 0.2460  s1.loss_cls: 0.0839  s1.acc: 90.1296  s1.loss_bbox: 0.1042  s1.loss_mask: 0.1147  s2.loss_cls: 0.0377  s2.acc: 92.3838  s2.loss_bbox: 0.0409  s2.loss_mask: 0.0522
2024/02/16 22:44:12 - mmengine - INFO - Epoch(train) [35][4700/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:54:27  time: 0.6958  data_time: 0.0316  memory: 9751  loss: 1.1873  loss_rpn_cls: 0.0447  loss_rpn_bbox: 0.0330  s0.loss_cls: 0.1794  s0.acc: 90.9180  s0.loss_bbox: 0.2553  s0.loss_mask: 0.2266  s1.loss_cls: 0.0806  s1.acc: 92.8215  s1.loss_bbox: 0.1153  s1.loss_mask: 0.1130  s2.loss_cls: 0.0392  s2.acc: 93.7376  s2.loss_bbox: 0.0464  s2.loss_mask: 0.0538
2024/02/16 22:44:47 - mmengine - INFO - Epoch(train) [35][4750/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:53:53  time: 0.6865  data_time: 0.0285  memory: 10507  loss: 1.1709  loss_rpn_cls: 0.0355  loss_rpn_bbox: 0.0262  s0.loss_cls: 0.1862  s0.acc: 92.7734  s0.loss_bbox: 0.2434  s0.loss_mask: 0.2419  s1.loss_cls: 0.0862  s1.acc: 92.9364  s1.loss_bbox: 0.1036  s1.loss_mask: 0.1146  s2.loss_cls: 0.0393  s2.acc: 91.1380  s2.loss_bbox: 0.0405  s2.loss_mask: 0.0533
2024/02/16 22:45:07 - mmengine - INFO - Exp name: cascade_mask_rcnn_swin_tiny_patch4_window7_mstrain_480-800_giou_4conv1f_adamw_3x_coco_20240216_214910
2024/02/16 22:45:21 - mmengine - INFO - Epoch(train) [35][4800/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:53:18  time: 0.6898  data_time: 0.0262  memory: 9753  loss: 1.2321  loss_rpn_cls: 0.0438  loss_rpn_bbox: 0.0332  s0.loss_cls: 0.1928  s0.acc: 89.9414  s0.loss_bbox: 0.2504  s0.loss_mask: 0.2551  s1.loss_cls: 0.0867  s1.acc: 92.3391  s1.loss_bbox: 0.1089  s1.loss_mask: 0.1224  s2.loss_cls: 0.0398  s2.acc: 94.4444  s2.loss_bbox: 0.0426  s2.loss_mask: 0.0565
2024/02/16 22:45:56 - mmengine - INFO - Epoch(train) [35][4850/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:52:43  time: 0.6869  data_time: 0.0277  memory: 9636  loss: 1.1486  loss_rpn_cls: 0.0406  loss_rpn_bbox: 0.0285  s0.loss_cls: 0.1765  s0.acc: 91.0156  s0.loss_bbox: 0.2348  s0.loss_mask: 0.2389  s1.loss_cls: 0.0792  s1.acc: 90.5273  s1.loss_bbox: 0.1034  s1.loss_mask: 0.1149  s2.loss_cls: 0.0358  s2.acc: 90.5273  s2.loss_bbox: 0.0411  s2.loss_mask: 0.0548
2024/02/16 22:46:29 - mmengine - INFO - Epoch(train) [35][4900/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:52:08  time: 0.6772  data_time: 0.0238  memory: 9436  loss: 1.0889  loss_rpn_cls: 0.0361  loss_rpn_bbox: 0.0257  s0.loss_cls: 0.1724  s0.acc: 93.1641  s0.loss_bbox: 0.2154  s0.loss_mask: 0.2253  s1.loss_cls: 0.0745  s1.acc: 93.6445  s1.loss_bbox: 0.0991  s1.loss_mask: 0.1119  s2.loss_cls: 0.0354  s2.acc: 91.6832  s2.loss_bbox: 0.0402  s2.loss_mask: 0.0530
2024/02/16 22:47:04 - mmengine - INFO - Epoch(train) [35][4950/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:51:34  time: 0.6943  data_time: 0.0243  memory: 9866  loss: 1.1648  loss_rpn_cls: 0.0364  loss_rpn_bbox: 0.0249  s0.loss_cls: 0.1876  s0.acc: 90.9180  s0.loss_bbox: 0.2382  s0.loss_mask: 0.2295  s1.loss_cls: 0.0858  s1.acc: 90.8555  s1.loss_bbox: 0.1099  s1.loss_mask: 0.1147  s2.loss_cls: 0.0392  s2.acc: 90.9627  s2.loss_bbox: 0.0446  s2.loss_mask: 0.0542
2024/02/16 22:47:39 - mmengine - INFO - Epoch(train) [35][5000/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:50:59  time: 0.6884  data_time: 0.0256  memory: 9726  loss: 1.1540  loss_rpn_cls: 0.0454  loss_rpn_bbox: 0.0268  s0.loss_cls: 0.1786  s0.acc: 96.5820  s0.loss_bbox: 0.2391  s0.loss_mask: 0.2290  s1.loss_cls: 0.0825  s1.acc: 97.1680  s1.loss_bbox: 0.1072  s1.loss_mask: 0.1129  s2.loss_cls: 0.0387  s2.acc: 97.6562  s2.loss_bbox: 0.0413  s2.loss_mask: 0.0525
2024/02/16 22:48:12 - mmengine - INFO - Epoch(train) [35][5050/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:50:24  time: 0.6769  data_time: 0.0234  memory: 9470  loss: 1.1731  loss_rpn_cls: 0.0449  loss_rpn_bbox: 0.0293  s0.loss_cls: 0.1803  s0.acc: 93.0664  s0.loss_bbox: 0.2376  s0.loss_mask: 0.2452  s1.loss_cls: 0.0788  s1.acc: 92.2686  s1.loss_bbox: 0.1054  s1.loss_mask: 0.1186  s2.loss_cls: 0.0359  s2.acc: 93.5910  s2.loss_bbox: 0.0422  s2.loss_mask: 0.0548
2024/02/16 22:48:47 - mmengine - INFO - Epoch(train) [35][5100/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:49:48  time: 0.6812  data_time: 0.0237  memory: 9662  loss: 1.2082  loss_rpn_cls: 0.0364  loss_rpn_bbox: 0.0247  s0.loss_cls: 0.1962  s0.acc: 87.8906  s0.loss_bbox: 0.2468  s0.loss_mask: 0.2522  s1.loss_cls: 0.0843  s1.acc: 88.8192  s1.loss_bbox: 0.1114  s1.loss_mask: 0.1191  s2.loss_cls: 0.0386  s2.acc: 90.3125  s2.loss_bbox: 0.0438  s2.loss_mask: 0.0546
2024/02/16 22:49:22 - mmengine - INFO - Epoch(train) [35][5150/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:49:15  time: 0.6992  data_time: 0.0264  memory: 10105  loss: 1.1917  loss_rpn_cls: 0.0336  loss_rpn_bbox: 0.0291  s0.loss_cls: 0.1833  s0.acc: 96.6797  s0.loss_bbox: 0.2522  s0.loss_mask: 0.2472  s1.loss_cls: 0.0812  s1.acc: 97.4609  s1.loss_bbox: 0.1109  s1.loss_mask: 0.1187  s2.loss_cls: 0.0383  s2.acc: 97.9492  s2.loss_bbox: 0.0419  s2.loss_mask: 0.0554
2024/02/16 22:49:56 - mmengine - INFO - Epoch(train) [35][5200/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:48:40  time: 0.6910  data_time: 0.0246  memory: 9409  loss: 1.0747  loss_rpn_cls: 0.0377  loss_rpn_bbox: 0.0286  s0.loss_cls: 0.1634  s0.acc: 89.8438  s0.loss_bbox: 0.2295  s0.loss_mask: 0.2159  s1.loss_cls: 0.0710  s1.acc: 88.0834  s1.loss_bbox: 0.1040  s1.loss_mask: 0.1023  s2.loss_cls: 0.0346  s2.acc: 86.8317  s2.loss_bbox: 0.0405  s2.loss_mask: 0.0472
2024/02/16 22:50:31 - mmengine - INFO - Epoch(train) [35][5250/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:48:06  time: 0.6895  data_time: 0.0281  memory: 10790  loss: 1.2420  loss_rpn_cls: 0.0437  loss_rpn_bbox: 0.0324  s0.loss_cls: 0.1971  s0.acc: 98.5352  s0.loss_bbox: 0.2687  s0.loss_mask: 0.2467  s1.loss_cls: 0.0833  s1.acc: 99.2188  s1.loss_bbox: 0.1137  s1.loss_mask: 0.1178  s2.loss_cls: 0.0391  s2.acc: 99.2188  s2.loss_bbox: 0.0440  s2.loss_mask: 0.0554
2024/02/16 22:51:05 - mmengine - INFO - Epoch(train) [35][5300/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:47:31  time: 0.6858  data_time: 0.0224  memory: 9530  loss: 1.0251  loss_rpn_cls: 0.0300  loss_rpn_bbox: 0.0270  s0.loss_cls: 0.1523  s0.acc: 98.8281  s0.loss_bbox: 0.2102  s0.loss_mask: 0.2217  s1.loss_cls: 0.0657  s1.acc: 98.5352  s1.loss_bbox: 0.0927  s1.loss_mask: 0.1070  s2.loss_cls: 0.0307  s2.acc: 98.6328  s2.loss_bbox: 0.0378  s2.loss_mask: 0.0500
2024/02/16 22:51:39 - mmengine - INFO - Epoch(train) [35][5350/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:46:56  time: 0.6819  data_time: 0.0238  memory: 9699  loss: 1.1109  loss_rpn_cls: 0.0382  loss_rpn_bbox: 0.0276  s0.loss_cls: 0.1636  s0.acc: 91.3086  s0.loss_bbox: 0.2297  s0.loss_mask: 0.2342  s1.loss_cls: 0.0707  s1.acc: 92.4528  s1.loss_bbox: 0.1042  s1.loss_mask: 0.1147  s2.loss_cls: 0.0338  s2.acc: 91.4513  s2.loss_bbox: 0.0408  s2.loss_mask: 0.0533
2024/02/16 22:52:13 - mmengine - INFO - Epoch(train) [35][5400/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:46:21  time: 0.6813  data_time: 0.0251  memory: 9605  loss: 1.0893  loss_rpn_cls: 0.0281  loss_rpn_bbox: 0.0246  s0.loss_cls: 0.1677  s0.acc: 97.3633  s0.loss_bbox: 0.2268  s0.loss_mask: 0.2270  s1.loss_cls: 0.0762  s1.acc: 97.0703  s1.loss_bbox: 0.1019  s1.loss_mask: 0.1099  s2.loss_cls: 0.0356  s2.acc: 96.5820  s2.loss_bbox: 0.0406  s2.loss_mask: 0.0509
2024/02/16 22:52:48 - mmengine - INFO - Epoch(train) [35][5450/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:45:47  time: 0.6932  data_time: 0.0258  memory: 9405  loss: 1.2795  loss_rpn_cls: 0.0486  loss_rpn_bbox: 0.0373  s0.loss_cls: 0.2026  s0.acc: 89.3555  s0.loss_bbox: 0.2709  s0.loss_mask: 0.2530  s1.loss_cls: 0.0887  s1.acc: 91.0643  s1.loss_bbox: 0.1157  s1.loss_mask: 0.1188  s2.loss_cls: 0.0428  s2.acc: 89.4106  s2.loss_bbox: 0.0457  s2.loss_mask: 0.0554
2024/02/16 22:53:23 - mmengine - INFO - Epoch(train) [35][5500/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:45:14  time: 0.7067  data_time: 0.0289  memory: 9410  loss: 1.2159  loss_rpn_cls: 0.0466  loss_rpn_bbox: 0.0321  s0.loss_cls: 0.1778  s0.acc: 86.9141  s0.loss_bbox: 0.2506  s0.loss_mask: 0.2570  s1.loss_cls: 0.0777  s1.acc: 88.7695  s1.loss_bbox: 0.1137  s1.loss_mask: 0.1220  s2.loss_cls: 0.0364  s2.acc: 85.6445  s2.loss_bbox: 0.0447  s2.loss_mask: 0.0573
2024/02/16 22:53:57 - mmengine - INFO - Epoch(train) [35][5550/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:44:39  time: 0.6846  data_time: 0.0296  memory: 9289  loss: 1.1731  loss_rpn_cls: 0.0432  loss_rpn_bbox: 0.0285  s0.loss_cls: 0.1798  s0.acc: 85.5469  s0.loss_bbox: 0.2430  s0.loss_mask: 0.2400  s1.loss_cls: 0.0804  s1.acc: 89.5112  s1.loss_bbox: 0.1092  s1.loss_mask: 0.1134  s2.loss_cls: 0.0374  s2.acc: 88.5279  s2.loss_bbox: 0.0443  s2.loss_mask: 0.0537
2024/02/16 22:54:32 - mmengine - INFO - Epoch(train) [35][5600/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:44:05  time: 0.6893  data_time: 0.0271  memory: 9284  loss: 1.1823  loss_rpn_cls: 0.0463  loss_rpn_bbox: 0.0308  s0.loss_cls: 0.1977  s0.acc: 91.6016  s0.loss_bbox: 0.2447  s0.loss_mask: 0.2218  s1.loss_cls: 0.0879  s1.acc: 91.8307  s1.loss_bbox: 0.1099  s1.loss_mask: 0.1083  s2.loss_cls: 0.0392  s2.acc: 91.7404  s2.loss_bbox: 0.0444  s2.loss_mask: 0.0512
2024/02/16 22:55:06 - mmengine - INFO - Epoch(train) [35][5650/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:43:30  time: 0.6892  data_time: 0.0277  memory: 9601  loss: 1.2234  loss_rpn_cls: 0.0534  loss_rpn_bbox: 0.0347  s0.loss_cls: 0.1842  s0.acc: 95.2148  s0.loss_bbox: 0.2505  s0.loss_mask: 0.2468  s1.loss_cls: 0.0817  s1.acc: 94.6289  s1.loss_bbox: 0.1115  s1.loss_mask: 0.1204  s2.loss_cls: 0.0398  s2.acc: 92.2852  s2.loss_bbox: 0.0440  s2.loss_mask: 0.0563
2024/02/16 22:55:41 - mmengine - INFO - Epoch(train) [35][5700/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:42:55  time: 0.6858  data_time: 0.0250  memory: 9736  loss: 1.1538  loss_rpn_cls: 0.0392  loss_rpn_bbox: 0.0258  s0.loss_cls: 0.1755  s0.acc: 92.7734  s0.loss_bbox: 0.2406  s0.loss_mask: 0.2376  s1.loss_cls: 0.0755  s1.acc: 90.3320  s1.loss_bbox: 0.1105  s1.loss_mask: 0.1145  s2.loss_cls: 0.0375  s2.acc: 91.6016  s2.loss_bbox: 0.0447  s2.loss_mask: 0.0526
2024/02/16 22:56:15 - mmengine - INFO - Epoch(train) [35][5750/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:42:20  time: 0.6839  data_time: 0.0257  memory: 9434  loss: 1.2386  loss_rpn_cls: 0.0461  loss_rpn_bbox: 0.0299  s0.loss_cls: 0.1887  s0.acc: 93.3594  s0.loss_bbox: 0.2637  s0.loss_mask: 0.2439  s1.loss_cls: 0.0870  s1.acc: 95.1676  s1.loss_bbox: 0.1190  s1.loss_mask: 0.1177  s2.loss_cls: 0.0409  s2.acc: 96.2598  s2.loss_bbox: 0.0470  s2.loss_mask: 0.0545
2024/02/16 22:56:36 - mmengine - INFO - Exp name: cascade_mask_rcnn_swin_tiny_patch4_window7_mstrain_480-800_giou_4conv1f_adamw_3x_coco_20240216_214910
2024/02/16 22:56:50 - mmengine - INFO - Epoch(train) [35][5800/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:41:46  time: 0.6913  data_time: 0.0266  memory: 9945  loss: 1.2113  loss_rpn_cls: 0.0405  loss_rpn_bbox: 0.0292  s0.loss_cls: 0.1966  s0.acc: 96.6797  s0.loss_bbox: 0.2531  s0.loss_mask: 0.2366  s1.loss_cls: 0.0836  s1.acc: 96.3867  s1.loss_bbox: 0.1156  s1.loss_mask: 0.1168  s2.loss_cls: 0.0395  s2.acc: 95.6055  s2.loss_bbox: 0.0461  s2.loss_mask: 0.0535
2024/02/16 22:57:24 - mmengine - INFO - Epoch(train) [35][5850/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:41:11  time: 0.6822  data_time: 0.0248  memory: 9723  loss: 1.1907  loss_rpn_cls: 0.0368  loss_rpn_bbox: 0.0252  s0.loss_cls: 0.1944  s0.acc: 90.9180  s0.loss_bbox: 0.2474  s0.loss_mask: 0.2400  s1.loss_cls: 0.0866  s1.acc: 92.1569  s1.loss_bbox: 0.1085  s1.loss_mask: 0.1151  s2.loss_cls: 0.0409  s2.acc: 94.1176  s2.loss_bbox: 0.0425  s2.loss_mask: 0.0531
2024/02/16 22:57:58 - mmengine - INFO - Epoch(train) [35][5900/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:40:36  time: 0.6783  data_time: 0.0268  memory: 9741  loss: 1.2259  loss_rpn_cls: 0.0406  loss_rpn_bbox: 0.0265  s0.loss_cls: 0.1965  s0.acc: 90.1367  s0.loss_bbox: 0.2682  s0.loss_mask: 0.2411  s1.loss_cls: 0.0838  s1.acc: 92.4805  s1.loss_bbox: 0.1176  s1.loss_mask: 0.1147  s2.loss_cls: 0.0384  s2.acc: 95.0195  s2.loss_bbox: 0.0458  s2.loss_mask: 0.0527
2024/02/16 22:58:32 - mmengine - INFO - Epoch(train) [35][5950/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:40:01  time: 0.6838  data_time: 0.0278  memory: 9573  loss: 1.2177  loss_rpn_cls: 0.0469  loss_rpn_bbox: 0.0311  s0.loss_cls: 0.1931  s0.acc: 94.5312  s0.loss_bbox: 0.2631  s0.loss_mask: 0.2365  s1.loss_cls: 0.0800  s1.acc: 94.2383  s1.loss_bbox: 0.1163  s1.loss_mask: 0.1129  s2.loss_cls: 0.0384  s2.acc: 93.3594  s2.loss_bbox: 0.0465  s2.loss_mask: 0.0531
2024/02/16 22:59:06 - mmengine - INFO - Epoch(train) [35][6000/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:39:27  time: 0.6909  data_time: 0.0284  memory: 9709  loss: 1.1105  loss_rpn_cls: 0.0320  loss_rpn_bbox: 0.0281  s0.loss_cls: 0.1838  s0.acc: 97.2656  s0.loss_bbox: 0.2309  s0.loss_mask: 0.2169  s1.loss_cls: 0.0790  s1.acc: 97.1680  s1.loss_bbox: 0.1066  s1.loss_mask: 0.1034  s2.loss_cls: 0.0376  s2.acc: 97.7539  s2.loss_bbox: 0.0433  s2.loss_mask: 0.0489
2024/02/16 22:59:41 - mmengine - INFO - Epoch(train) [35][6050/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:38:52  time: 0.6831  data_time: 0.0284  memory: 9511  loss: 1.2707  loss_rpn_cls: 0.0499  loss_rpn_bbox: 0.0320  s0.loss_cls: 0.2000  s0.acc: 90.8203  s0.loss_bbox: 0.2669  s0.loss_mask: 0.2570  s1.loss_cls: 0.0878  s1.acc: 89.4790  s1.loss_bbox: 0.1154  s1.loss_mask: 0.1218  s2.loss_cls: 0.0403  s2.acc: 91.2210  s2.loss_bbox: 0.0435  s2.loss_mask: 0.0561
2024/02/16 23:00:15 - mmengine - INFO - Epoch(train) [35][6100/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:38:18  time: 0.6945  data_time: 0.0260  memory: 10247  loss: 1.2308  loss_rpn_cls: 0.0392  loss_rpn_bbox: 0.0302  s0.loss_cls: 0.2019  s0.acc: 89.3555  s0.loss_bbox: 0.2582  s0.loss_mask: 0.2401  s1.loss_cls: 0.0883  s1.acc: 90.4995  s1.loss_bbox: 0.1154  s1.loss_mask: 0.1178  s2.loss_cls: 0.0426  s2.acc: 92.1645  s2.loss_bbox: 0.0441  s2.loss_mask: 0.0530
2024/02/16 23:00:50 - mmengine - INFO - Epoch(train) [35][6150/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:37:43  time: 0.6821  data_time: 0.0254  memory: 9620  loss: 1.2629  loss_rpn_cls: 0.0501  loss_rpn_bbox: 0.0346  s0.loss_cls: 0.2022  s0.acc: 87.1094  s0.loss_bbox: 0.2620  s0.loss_mask: 0.2479  s1.loss_cls: 0.0887  s1.acc: 87.7228  s1.loss_bbox: 0.1147  s1.loss_mask: 0.1204  s2.loss_cls: 0.0425  s2.acc: 86.7458  s2.loss_bbox: 0.0444  s2.loss_mask: 0.0554
2024/02/16 23:01:24 - mmengine - INFO - Epoch(train) [35][6200/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:37:08  time: 0.6792  data_time: 0.0259  memory: 9655  loss: 1.1721  loss_rpn_cls: 0.0405  loss_rpn_bbox: 0.0266  s0.loss_cls: 0.1788  s0.acc: 95.4102  s0.loss_bbox: 0.2471  s0.loss_mask: 0.2391  s1.loss_cls: 0.0807  s1.acc: 95.9606  s1.loss_bbox: 0.1088  s1.loss_mask: 0.1159  s2.loss_cls: 0.0388  s2.acc: 94.5866  s2.loss_bbox: 0.0419  s2.loss_mask: 0.0538
2024/02/16 23:01:58 - mmengine - INFO - Epoch(train) [35][6250/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:36:34  time: 0.6954  data_time: 0.0314  memory: 9687  loss: 1.2395  loss_rpn_cls: 0.0505  loss_rpn_bbox: 0.0312  s0.loss_cls: 0.2059  s0.acc: 92.2852  s0.loss_bbox: 0.2558  s0.loss_mask: 0.2405  s1.loss_cls: 0.0876  s1.acc: 93.2866  s1.loss_bbox: 0.1125  s1.loss_mask: 0.1157  s2.loss_cls: 0.0424  s2.acc: 93.0583  s2.loss_bbox: 0.0438  s2.loss_mask: 0.0535
2024/02/16 23:02:33 - mmengine - INFO - Epoch(train) [35][6300/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:35:59  time: 0.6888  data_time: 0.0287  memory: 9412  loss: 1.2068  loss_rpn_cls: 0.0402  loss_rpn_bbox: 0.0264  s0.loss_cls: 0.1896  s0.acc: 93.8477  s0.loss_bbox: 0.2579  s0.loss_mask: 0.2435  s1.loss_cls: 0.0843  s1.acc: 96.1914  s1.loss_bbox: 0.1105  s1.loss_mask: 0.1160  s2.loss_cls: 0.0394  s2.acc: 94.9219  s2.loss_bbox: 0.0439  s2.loss_mask: 0.0550
2024/02/16 23:03:07 - mmengine - INFO - Epoch(train) [35][6350/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:35:24  time: 0.6805  data_time: 0.0265  memory: 10955  loss: 1.1843  loss_rpn_cls: 0.0394  loss_rpn_bbox: 0.0301  s0.loss_cls: 0.1812  s0.acc: 97.4609  s0.loss_bbox: 0.2554  s0.loss_mask: 0.2353  s1.loss_cls: 0.0826  s1.acc: 96.8750  s1.loss_bbox: 0.1132  s1.loss_mask: 0.1123  s2.loss_cls: 0.0377  s2.acc: 96.9727  s2.loss_bbox: 0.0442  s2.loss_mask: 0.0530
2024/02/16 23:03:41 - mmengine - INFO - Epoch(train) [35][6400/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:34:49  time: 0.6820  data_time: 0.0262  memory: 9152  loss: 1.2656  loss_rpn_cls: 0.0508  loss_rpn_bbox: 0.0271  s0.loss_cls: 0.1990  s0.acc: 96.1914  s0.loss_bbox: 0.2571  s0.loss_mask: 0.2550  s1.loss_cls: 0.0917  s1.acc: 95.3125  s1.loss_bbox: 0.1158  s1.loss_mask: 0.1239  s2.loss_cls: 0.0443  s2.acc: 96.2891  s2.loss_bbox: 0.0433  s2.loss_mask: 0.0576
2024/02/16 23:04:15 - mmengine - INFO - Epoch(train) [35][6450/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:34:14  time: 0.6791  data_time: 0.0246  memory: 9269  loss: 1.1231  loss_rpn_cls: 0.0394  loss_rpn_bbox: 0.0254  s0.loss_cls: 0.1756  s0.acc: 91.2109  s0.loss_bbox: 0.2393  s0.loss_mask: 0.2267  s1.loss_cls: 0.0743  s1.acc: 92.0118  s1.loss_bbox: 0.1057  s1.loss_mask: 0.1096  s2.loss_cls: 0.0350  s2.acc: 92.4138  s2.loss_bbox: 0.0413  s2.loss_mask: 0.0508
2024/02/16 23:04:49 - mmengine - INFO - Epoch(train) [35][6500/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:33:40  time: 0.6859  data_time: 0.0261  memory: 9738  loss: 1.2447  loss_rpn_cls: 0.0509  loss_rpn_bbox: 0.0307  s0.loss_cls: 0.1977  s0.acc: 87.8906  s0.loss_bbox: 0.2613  s0.loss_mask: 0.2498  s1.loss_cls: 0.0856  s1.acc: 85.2539  s1.loss_bbox: 0.1114  s1.loss_mask: 0.1193  s2.loss_cls: 0.0396  s2.acc: 87.8906  s2.loss_bbox: 0.0433  s2.loss_mask: 0.0552
2024/02/16 23:05:23 - mmengine - INFO - Epoch(train) [35][6550/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:33:05  time: 0.6821  data_time: 0.0268  memory: 9427  loss: 1.1257  loss_rpn_cls: 0.0322  loss_rpn_bbox: 0.0249  s0.loss_cls: 0.1786  s0.acc: 95.8984  s0.loss_bbox: 0.2338  s0.loss_mask: 0.2272  s1.loss_cls: 0.0811  s1.acc: 96.8750  s1.loss_bbox: 0.1045  s1.loss_mask: 0.1110  s2.loss_cls: 0.0387  s2.acc: 97.4609  s2.loss_bbox: 0.0415  s2.loss_mask: 0.0521
2024/02/16 23:05:58 - mmengine - INFO - Epoch(train) [35][6600/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:32:30  time: 0.6832  data_time: 0.0247  memory: 9108  loss: 1.1111  loss_rpn_cls: 0.0416  loss_rpn_bbox: 0.0292  s0.loss_cls: 0.1697  s0.acc: 98.9258  s0.loss_bbox: 0.2288  s0.loss_mask: 0.2261  s1.loss_cls: 0.0739  s1.acc: 99.0234  s1.loss_bbox: 0.1027  s1.loss_mask: 0.1105  s2.loss_cls: 0.0360  s2.acc: 98.8281  s2.loss_bbox: 0.0406  s2.loss_mask: 0.0521
2024/02/16 23:06:32 - mmengine - INFO - Epoch(train) [35][6650/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:31:55  time: 0.6809  data_time: 0.0219  memory: 9544  loss: 1.1281  loss_rpn_cls: 0.0360  loss_rpn_bbox: 0.0274  s0.loss_cls: 0.1609  s0.acc: 95.1172  s0.loss_bbox: 0.2264  s0.loss_mask: 0.2447  s1.loss_cls: 0.0738  s1.acc: 96.7936  s1.loss_bbox: 0.1063  s1.loss_mask: 0.1191  s2.loss_cls: 0.0345  s2.acc: 95.7661  s2.loss_bbox: 0.0427  s2.loss_mask: 0.0563
2024/02/16 23:07:06 - mmengine - INFO - Epoch(train) [35][6700/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:31:21  time: 0.6908  data_time: 0.0255  memory: 9795  loss: 1.1968  loss_rpn_cls: 0.0355  loss_rpn_bbox: 0.0281  s0.loss_cls: 0.1911  s0.acc: 94.7266  s0.loss_bbox: 0.2491  s0.loss_mask: 0.2412  s1.loss_cls: 0.0850  s1.acc: 95.1000  s1.loss_bbox: 0.1109  s1.loss_mask: 0.1163  s2.loss_cls: 0.0400  s2.acc: 95.7704  s2.loss_bbox: 0.0445  s2.loss_mask: 0.0551
2024/02/16 23:07:41 - mmengine - INFO - Epoch(train) [35][6750/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:30:46  time: 0.6875  data_time: 0.0238  memory: 9431  loss: 1.0781  loss_rpn_cls: 0.0358  loss_rpn_bbox: 0.0292  s0.loss_cls: 0.1679  s0.acc: 84.9609  s0.loss_bbox: 0.2133  s0.loss_mask: 0.2296  s1.loss_cls: 0.0719  s1.acc: 87.4104  s1.loss_bbox: 0.0950  s1.loss_mask: 0.1119  s2.loss_cls: 0.0343  s2.acc: 85.9040  s2.loss_bbox: 0.0371  s2.loss_mask: 0.0521
2024/02/16 23:08:01 - mmengine - INFO - Exp name: cascade_mask_rcnn_swin_tiny_patch4_window7_mstrain_480-800_giou_4conv1f_adamw_3x_coco_20240216_214910
2024/02/16 23:08:15 - mmengine - INFO - Epoch(train) [35][6800/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:30:12  time: 0.6818  data_time: 0.0253  memory: 9727  loss: 1.2216  loss_rpn_cls: 0.0505  loss_rpn_bbox: 0.0315  s0.loss_cls: 0.1970  s0.acc: 97.3633  s0.loss_bbox: 0.2577  s0.loss_mask: 0.2339  s1.loss_cls: 0.0869  s1.acc: 94.5312  s1.loss_bbox: 0.1136  s1.loss_mask: 0.1146  s2.loss_cls: 0.0395  s2.acc: 91.9922  s2.loss_bbox: 0.0436  s2.loss_mask: 0.0529
2024/02/16 23:08:49 - mmengine - INFO - Epoch(train) [35][6850/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:29:37  time: 0.6788  data_time: 0.0253  memory: 9363  loss: 1.1747  loss_rpn_cls: 0.0447  loss_rpn_bbox: 0.0274  s0.loss_cls: 0.1794  s0.acc: 94.8242  s0.loss_bbox: 0.2441  s0.loss_mask: 0.2432  s1.loss_cls: 0.0748  s1.acc: 94.4336  s1.loss_bbox: 0.1113  s1.loss_mask: 0.1155  s2.loss_cls: 0.0358  s2.acc: 95.9961  s2.loss_bbox: 0.0449  s2.loss_mask: 0.0536
2024/02/16 23:09:23 - mmengine - INFO - Epoch(train) [35][6900/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:29:02  time: 0.6879  data_time: 0.0262  memory: 9963  loss: 1.2233  loss_rpn_cls: 0.0460  loss_rpn_bbox: 0.0291  s0.loss_cls: 0.1980  s0.acc: 92.3828  s0.loss_bbox: 0.2620  s0.loss_mask: 0.2334  s1.loss_cls: 0.0859  s1.acc: 91.2698  s1.loss_bbox: 0.1169  s1.loss_mask: 0.1121  s2.loss_cls: 0.0407  s2.acc: 91.8570  s2.loss_bbox: 0.0467  s2.loss_mask: 0.0526
2024/02/16 23:09:57 - mmengine - INFO - Epoch(train) [35][6950/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:28:27  time: 0.6797  data_time: 0.0251  memory: 9657  loss: 1.1999  loss_rpn_cls: 0.0396  loss_rpn_bbox: 0.0269  s0.loss_cls: 0.1889  s0.acc: 89.9414  s0.loss_bbox: 0.2546  s0.loss_mask: 0.2396  s1.loss_cls: 0.0851  s1.acc: 92.2696  s1.loss_bbox: 0.1141  s1.loss_mask: 0.1149  s2.loss_cls: 0.0401  s2.acc: 91.1619  s2.loss_bbox: 0.0440  s2.loss_mask: 0.0522
2024/02/16 23:10:31 - mmengine - INFO - Epoch(train) [35][7000/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:27:52  time: 0.6780  data_time: 0.0263  memory: 9171  loss: 1.2156  loss_rpn_cls: 0.0445  loss_rpn_bbox: 0.0266  s0.loss_cls: 0.2058  s0.acc: 91.4062  s0.loss_bbox: 0.2561  s0.loss_mask: 0.2308  s1.loss_cls: 0.0919  s1.acc: 90.1367  s1.loss_bbox: 0.1121  s1.loss_mask: 0.1120  s2.loss_cls: 0.0423  s2.acc: 90.6250  s2.loss_bbox: 0.0418  s2.loss_mask: 0.0516
2024/02/16 23:11:05 - mmengine - INFO - Epoch(train) [35][7050/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:27:18  time: 0.6849  data_time: 0.0244  memory: 9360  loss: 1.2069  loss_rpn_cls: 0.0420  loss_rpn_bbox: 0.0240  s0.loss_cls: 0.1894  s0.acc: 95.6055  s0.loss_bbox: 0.2615  s0.loss_mask: 0.2347  s1.loss_cls: 0.0831  s1.acc: 96.4844  s1.loss_bbox: 0.1156  s1.loss_mask: 0.1168  s2.loss_cls: 0.0391  s2.acc: 100.0000  s2.loss_bbox: 0.0456  s2.loss_mask: 0.0551
2024/02/16 23:11:39 - mmengine - INFO - Epoch(train) [35][7100/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:26:43  time: 0.6799  data_time: 0.0272  memory: 9885  loss: 1.1966  loss_rpn_cls: 0.0392  loss_rpn_bbox: 0.0293  s0.loss_cls: 0.1914  s0.acc: 86.0352  s0.loss_bbox: 0.2374  s0.loss_mask: 0.2500  s1.loss_cls: 0.0825  s1.acc: 89.9371  s1.loss_bbox: 0.1069  s1.loss_mask: 0.1226  s2.loss_cls: 0.0376  s2.acc: 89.1213  s2.loss_bbox: 0.0426  s2.loss_mask: 0.0571
2024/02/16 23:12:14 - mmengine - INFO - Epoch(train) [35][7150/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:26:08  time: 0.6835  data_time: 0.0262  memory: 9679  loss: 1.0605  loss_rpn_cls: 0.0400  loss_rpn_bbox: 0.0231  s0.loss_cls: 0.1653  s0.acc: 96.5820  s0.loss_bbox: 0.2023  s0.loss_mask: 0.2238  s1.loss_cls: 0.0719  s1.acc: 95.8984  s1.loss_bbox: 0.0955  s1.loss_mask: 0.1129  s2.loss_cls: 0.0344  s2.acc: 94.2383  s2.loss_bbox: 0.0385  s2.loss_mask: 0.0528
2024/02/16 23:12:48 - mmengine - INFO - Epoch(train) [35][7200/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:25:34  time: 0.6918  data_time: 0.0261  memory: 9298  loss: 1.1474  loss_rpn_cls: 0.0377  loss_rpn_bbox: 0.0245  s0.loss_cls: 0.1638  s0.acc: 96.7773  s0.loss_bbox: 0.2459  s0.loss_mask: 0.2427  s1.loss_cls: 0.0769  s1.acc: 97.0499  s1.loss_bbox: 0.1075  s1.loss_mask: 0.1159  s2.loss_cls: 0.0365  s2.acc: 97.7413  s2.loss_bbox: 0.0414  s2.loss_mask: 0.0544
2024/02/16 23:13:23 - mmengine - INFO - Epoch(train) [35][7250/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:25:00  time: 0.6956  data_time: 0.0288  memory: 9886  loss: 1.2249  loss_rpn_cls: 0.0470  loss_rpn_bbox: 0.0298  s0.loss_cls: 0.1999  s0.acc: 97.9492  s0.loss_bbox: 0.2532  s0.loss_mask: 0.2398  s1.loss_cls: 0.0882  s1.acc: 98.4375  s1.loss_bbox: 0.1115  s1.loss_mask: 0.1151  s2.loss_cls: 0.0412  s2.acc: 97.6562  s2.loss_bbox: 0.0447  s2.loss_mask: 0.0545
2024/02/16 23:13:58 - mmengine - INFO - Epoch(train) [35][7300/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:24:25  time: 0.6890  data_time: 0.0274  memory: 9638  loss: 1.1543  loss_rpn_cls: 0.0403  loss_rpn_bbox: 0.0315  s0.loss_cls: 0.1739  s0.acc: 88.9648  s0.loss_bbox: 0.2395  s0.loss_mask: 0.2350  s1.loss_cls: 0.0772  s1.acc: 93.4055  s1.loss_bbox: 0.1067  s1.loss_mask: 0.1160  s2.loss_cls: 0.0377  s2.acc: 90.7480  s2.loss_bbox: 0.0424  s2.loss_mask: 0.0542
2024/02/16 23:14:18 - mmengine - INFO - Exp name: cascade_mask_rcnn_swin_tiny_patch4_window7_mstrain_480-800_giou_4conv1f_adamw_3x_coco_20240216_214910
2024/02/16 23:14:18 - mmengine - INFO - Saving checkpoint at 35 epochs
2024/02/16 23:14:33 - mmengine - INFO - Epoch(val) [35][ 50/625]    eta: 0:02:00  time: 0.2088  data_time: 0.0334  memory: 9788  
2024/02/16 23:14:43 - mmengine - INFO - Epoch(val) [35][100/625]    eta: 0:01:47  time: 0.2010  data_time: 0.0291  memory: 2665  
2024/02/16 23:14:53 - mmengine - INFO - Epoch(val) [35][150/625]    eta: 0:01:36  time: 0.1971  data_time: 0.0250  memory: 2661  
2024/02/16 23:15:03 - mmengine - INFO - Epoch(val) [35][200/625]    eta: 0:01:24  time: 0.1932  data_time: 0.0210  memory: 2661  
2024/02/16 23:15:13 - mmengine - INFO - Epoch(val) [35][250/625]    eta: 0:01:15  time: 0.2011  data_time: 0.0264  memory: 2665  
2024/02/16 23:15:23 - mmengine - INFO - Epoch(val) [35][300/625]    eta: 0:01:04  time: 0.1963  data_time: 0.0242  memory: 2661  
2024/02/16 23:15:33 - mmengine - INFO - Epoch(val) [35][350/625]    eta: 0:00:54  time: 0.2009  data_time: 0.0258  memory: 2662  
2024/02/16 23:15:43 - mmengine - INFO - Epoch(val) [35][400/625]    eta: 0:00:44  time: 0.1995  data_time: 0.0253  memory: 2665  
2024/02/16 23:15:53 - mmengine - INFO - Epoch(val) [35][450/625]    eta: 0:00:34  time: 0.1971  data_time: 0.0226  memory: 2665  
2024/02/16 23:16:03 - mmengine - INFO - Epoch(val) [35][500/625]    eta: 0:00:24  time: 0.1975  data_time: 0.0256  memory: 2662  
2024/02/16 23:16:13 - mmengine - INFO - Epoch(val) [35][550/625]    eta: 0:00:14  time: 0.2045  data_time: 0.0275  memory: 2665  
2024/02/16 23:16:23 - mmengine - INFO - Epoch(val) [35][600/625]    eta: 0:00:04  time: 0.1985  data_time: 0.0239  memory: 2661  
2024/02/16 23:16:40 - mmengine - INFO - Evaluating bbox...
2024/02/16 23:17:31 - mmengine - INFO - bbox_mAP_copypaste: 0.439 0.623 0.478 0.290 0.466 0.576
2024/02/16 23:17:31 - mmengine - INFO - Evaluating segm...
2024/02/16 23:18:31 - mmengine - INFO - segm_mAP_copypaste: 0.383 0.597 0.411 0.206 0.407 0.561
2024/02/16 23:18:32 - mmengine - INFO - Epoch(val) [35][625/625]    coco/bbox_mAP: 0.4390  coco/bbox_mAP_50: 0.6230  coco/bbox_mAP_75: 0.4780  coco/bbox_mAP_s: 0.2900  coco/bbox_mAP_m: 0.4660  coco/bbox_mAP_l: 0.5760  coco/segm_mAP: 0.3830  coco/segm_mAP_50: 0.5970  coco/segm_mAP_75: 0.4110  coco/segm_mAP_s: 0.2060  coco/segm_mAP_m: 0.4070  coco/segm_mAP_l: 0.5610  data_time: 0.0255  time: 0.1992
2024/02/16 23:19:08 - mmengine - INFO - Epoch(train) [36][  50/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:23:31  time: 0.7151  data_time: 0.0278  memory: 9134  loss: 1.1919  loss_rpn_cls: 0.0459  loss_rpn_bbox: 0.0262  s0.loss_cls: 0.1903  s0.acc: 96.7773  s0.loss_bbox: 0.2371  s0.loss_mask: 0.2417  s1.loss_cls: 0.0876  s1.acc: 95.9961  s1.loss_bbox: 0.1068  s1.loss_mask: 0.1186  s2.loss_cls: 0.0406  s2.acc: 97.7539  s2.loss_bbox: 0.0416  s2.loss_mask: 0.0556
2024/02/16 23:19:43 - mmengine - INFO - Epoch(train) [36][ 100/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:22:57  time: 0.6995  data_time: 0.0258  memory: 10908  loss: 1.2476  loss_rpn_cls: 0.0504  loss_rpn_bbox: 0.0292  s0.loss_cls: 0.2051  s0.acc: 84.5703  s0.loss_bbox: 0.2511  s0.loss_mask: 0.2466  s1.loss_cls: 0.0934  s1.acc: 83.9844  s1.loss_bbox: 0.1124  s1.loss_mask: 0.1181  s2.loss_cls: 0.0436  s2.acc: 84.7656  s2.loss_bbox: 0.0428  s2.loss_mask: 0.0547
2024/02/16 23:20:18 - mmengine - INFO - Epoch(train) [36][ 150/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:22:24  time: 0.7021  data_time: 0.0265  memory: 9649  loss: 1.1933  loss_rpn_cls: 0.0410  loss_rpn_bbox: 0.0290  s0.loss_cls: 0.1786  s0.acc: 90.3320  s0.loss_bbox: 0.2399  s0.loss_mask: 0.2576  s1.loss_cls: 0.0803  s1.acc: 91.9162  s1.loss_bbox: 0.1062  s1.loss_mask: 0.1240  s2.loss_cls: 0.0375  s2.acc: 92.2311  s2.loss_bbox: 0.0422  s2.loss_mask: 0.0572
2024/02/16 23:20:52 - mmengine - INFO - Epoch(train) [36][ 200/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:21:49  time: 0.6816  data_time: 0.0283  memory: 9622  loss: 1.2840  loss_rpn_cls: 0.0426  loss_rpn_bbox: 0.0311  s0.loss_cls: 0.2218  s0.acc: 89.8438  s0.loss_bbox: 0.2693  s0.loss_mask: 0.2410  s1.loss_cls: 0.0992  s1.acc: 91.8429  s1.loss_bbox: 0.1171  s1.loss_mask: 0.1167  s2.loss_cls: 0.0461  s2.acc: 93.4761  s2.loss_bbox: 0.0451  s2.loss_mask: 0.0539
2024/02/16 23:21:26 - mmengine - INFO - Epoch(train) [36][ 250/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:21:15  time: 0.6895  data_time: 0.0263  memory: 9500  loss: 1.1381  loss_rpn_cls: 0.0339  loss_rpn_bbox: 0.0276  s0.loss_cls: 0.1737  s0.acc: 97.2656  s0.loss_bbox: 0.2438  s0.loss_mask: 0.2377  s1.loss_cls: 0.0757  s1.acc: 96.7773  s1.loss_bbox: 0.1041  s1.loss_mask: 0.1111  s2.loss_cls: 0.0369  s2.acc: 96.9727  s2.loss_bbox: 0.0422  s2.loss_mask: 0.0514
2024/02/16 23:22:01 - mmengine - INFO - Epoch(train) [36][ 300/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:20:40  time: 0.6834  data_time: 0.0278  memory: 9777  loss: 1.1325  loss_rpn_cls: 0.0365  loss_rpn_bbox: 0.0275  s0.loss_cls: 0.1804  s0.acc: 87.2070  s0.loss_bbox: 0.2386  s0.loss_mask: 0.2287  s1.loss_cls: 0.0755  s1.acc: 87.3000  s1.loss_bbox: 0.1057  s1.loss_mask: 0.1107  s2.loss_cls: 0.0352  s2.acc: 88.2236  s2.loss_bbox: 0.0414  s2.loss_mask: 0.0523
2024/02/16 23:22:35 - mmengine - INFO - Epoch(train) [36][ 350/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:20:05  time: 0.6868  data_time: 0.0287  memory: 9978  loss: 1.2500  loss_rpn_cls: 0.0547  loss_rpn_bbox: 0.0322  s0.loss_cls: 0.1980  s0.acc: 95.3125  s0.loss_bbox: 0.2597  s0.loss_mask: 0.2496  s1.loss_cls: 0.0822  s1.acc: 94.7266  s1.loss_bbox: 0.1143  s1.loss_mask: 0.1199  s2.loss_cls: 0.0387  s2.acc: 94.8242  s2.loss_bbox: 0.0449  s2.loss_mask: 0.0557
2024/02/16 23:23:10 - mmengine - INFO - Epoch(train) [36][ 400/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:19:31  time: 0.6934  data_time: 0.0267  memory: 9860  loss: 1.2379  loss_rpn_cls: 0.0413  loss_rpn_bbox: 0.0332  s0.loss_cls: 0.1890  s0.acc: 82.6172  s0.loss_bbox: 0.2594  s0.loss_mask: 0.2546  s1.loss_cls: 0.0852  s1.acc: 85.1562  s1.loss_bbox: 0.1110  s1.loss_mask: 0.1248  s2.loss_cls: 0.0398  s2.acc: 87.1094  s2.loss_bbox: 0.0415  s2.loss_mask: 0.0582
2024/02/16 23:23:44 - mmengine - INFO - Exp name: cascade_mask_rcnn_swin_tiny_patch4_window7_mstrain_480-800_giou_4conv1f_adamw_3x_coco_20240216_214910
2024/02/16 23:23:44 - mmengine - INFO - Epoch(train) [36][ 450/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:18:57  time: 0.6931  data_time: 0.0274  memory: 9683  loss: 1.1479  loss_rpn_cls: 0.0368  loss_rpn_bbox: 0.0296  s0.loss_cls: 0.1742  s0.acc: 93.7500  s0.loss_bbox: 0.2401  s0.loss_mask: 0.2352  s1.loss_cls: 0.0752  s1.acc: 95.1269  s1.loss_bbox: 0.1083  s1.loss_mask: 0.1153  s2.loss_cls: 0.0360  s2.acc: 96.3377  s2.loss_bbox: 0.0428  s2.loss_mask: 0.0543
2024/02/16 23:24:19 - mmengine - INFO - Epoch(train) [36][ 500/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:18:22  time: 0.6828  data_time: 0.0273  memory: 9638  loss: 1.2775  loss_rpn_cls: 0.0422  loss_rpn_bbox: 0.0333  s0.loss_cls: 0.1935  s0.acc: 95.7031  s0.loss_bbox: 0.2738  s0.loss_mask: 0.2663  s1.loss_cls: 0.0863  s1.acc: 94.7680  s1.loss_bbox: 0.1191  s1.loss_mask: 0.1219  s2.loss_cls: 0.0407  s2.acc: 94.8667  s2.loss_bbox: 0.0452  s2.loss_mask: 0.0552
2024/02/16 23:24:53 - mmengine - INFO - Epoch(train) [36][ 550/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:17:47  time: 0.6808  data_time: 0.0270  memory: 9518  loss: 1.1873  loss_rpn_cls: 0.0381  loss_rpn_bbox: 0.0303  s0.loss_cls: 0.1841  s0.acc: 91.4062  s0.loss_bbox: 0.2513  s0.loss_mask: 0.2399  s1.loss_cls: 0.0813  s1.acc: 91.5438  s1.loss_bbox: 0.1110  s1.loss_mask: 0.1167  s2.loss_cls: 0.0372  s2.acc: 90.2655  s2.loss_bbox: 0.0436  s2.loss_mask: 0.0538
2024/02/16 23:25:27 - mmengine - INFO - Epoch(train) [36][ 600/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:17:13  time: 0.6896  data_time: 0.0287  memory: 8895  loss: 1.2582  loss_rpn_cls: 0.0456  loss_rpn_bbox: 0.0306  s0.loss_cls: 0.2023  s0.acc: 93.0664  s0.loss_bbox: 0.2721  s0.loss_mask: 0.2409  s1.loss_cls: 0.0898  s1.acc: 96.3673  s1.loss_bbox: 0.1189  s1.loss_mask: 0.1159  s2.loss_cls: 0.0422  s2.acc: 96.5829  s2.loss_bbox: 0.0458  s2.loss_mask: 0.0541
2024/02/16 23:26:02 - mmengine - INFO - Epoch(train) [36][ 650/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:16:39  time: 0.6889  data_time: 0.0272  memory: 10103  loss: 1.2360  loss_rpn_cls: 0.0415  loss_rpn_bbox: 0.0297  s0.loss_cls: 0.1815  s0.acc: 87.4023  s0.loss_bbox: 0.2616  s0.loss_mask: 0.2639  s1.loss_cls: 0.0795  s1.acc: 89.3253  s1.loss_bbox: 0.1148  s1.loss_mask: 0.1223  s2.loss_cls: 0.0376  s2.acc: 92.6337  s2.loss_bbox: 0.0462  s2.loss_mask: 0.0574
2024/02/16 23:26:36 - mmengine - INFO - Epoch(train) [36][ 700/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:16:04  time: 0.6816  data_time: 0.0284  memory: 9631  loss: 1.1297  loss_rpn_cls: 0.0367  loss_rpn_bbox: 0.0275  s0.loss_cls: 0.1706  s0.acc: 98.4375  s0.loss_bbox: 0.2393  s0.loss_mask: 0.2353  s1.loss_cls: 0.0730  s1.acc: 98.9258  s1.loss_bbox: 0.1070  s1.loss_mask: 0.1128  s2.loss_cls: 0.0334  s2.acc: 99.2188  s2.loss_bbox: 0.0422  s2.loss_mask: 0.0519
2024/02/16 23:27:10 - mmengine - INFO - Epoch(train) [36][ 750/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:15:30  time: 0.6891  data_time: 0.0247  memory: 9609  loss: 1.1696  loss_rpn_cls: 0.0340  loss_rpn_bbox: 0.0283  s0.loss_cls: 0.1790  s0.acc: 96.6797  s0.loss_bbox: 0.2518  s0.loss_mask: 0.2323  s1.loss_cls: 0.0796  s1.acc: 95.2239  s1.loss_bbox: 0.1141  s1.loss_mask: 0.1128  s2.loss_cls: 0.0391  s2.acc: 96.3855  s2.loss_bbox: 0.0458  s2.loss_mask: 0.0528
2024/02/16 23:27:45 - mmengine - INFO - Epoch(train) [36][ 800/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:14:56  time: 0.6975  data_time: 0.0232  memory: 9174  loss: 1.0817  loss_rpn_cls: 0.0349  loss_rpn_bbox: 0.0227  s0.loss_cls: 0.1717  s0.acc: 95.1172  s0.loss_bbox: 0.2201  s0.loss_mask: 0.2205  s1.loss_cls: 0.0749  s1.acc: 95.4102  s1.loss_bbox: 0.1027  s1.loss_mask: 0.1056  s2.loss_cls: 0.0357  s2.acc: 96.6797  s2.loss_bbox: 0.0428  s2.loss_mask: 0.0500
2024/02/16 23:28:20 - mmengine - INFO - Epoch(train) [36][ 850/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:14:21  time: 0.6956  data_time: 0.0282  memory: 10192  loss: 1.1940  loss_rpn_cls: 0.0416  loss_rpn_bbox: 0.0285  s0.loss_cls: 0.1857  s0.acc: 95.1172  s0.loss_bbox: 0.2412  s0.loss_mask: 0.2555  s1.loss_cls: 0.0820  s1.acc: 96.0938  s1.loss_bbox: 0.1051  s1.loss_mask: 0.1208  s2.loss_cls: 0.0374  s2.acc: 96.4844  s2.loss_bbox: 0.0408  s2.loss_mask: 0.0554
2024/02/16 23:28:54 - mmengine - INFO - Epoch(train) [36][ 900/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:13:47  time: 0.6895  data_time: 0.0287  memory: 9393  loss: 1.2322  loss_rpn_cls: 0.0419  loss_rpn_bbox: 0.0318  s0.loss_cls: 0.1983  s0.acc: 93.6523  s0.loss_bbox: 0.2647  s0.loss_mask: 0.2428  s1.loss_cls: 0.0882  s1.acc: 93.4570  s1.loss_bbox: 0.1142  s1.loss_mask: 0.1144  s2.loss_cls: 0.0410  s2.acc: 94.5312  s2.loss_bbox: 0.0444  s2.loss_mask: 0.0506
2024/02/16 23:29:29 - mmengine - INFO - Epoch(train) [36][ 950/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:13:13  time: 0.6873  data_time: 0.0270  memory: 9662  loss: 1.2524  loss_rpn_cls: 0.0437  loss_rpn_bbox: 0.0317  s0.loss_cls: 0.2028  s0.acc: 90.7227  s0.loss_bbox: 0.2638  s0.loss_mask: 0.2397  s1.loss_cls: 0.0909  s1.acc: 91.7577  s1.loss_bbox: 0.1178  s1.loss_mask: 0.1182  s2.loss_cls: 0.0425  s2.acc: 92.7507  s2.loss_bbox: 0.0467  s2.loss_mask: 0.0547
2024/02/16 23:30:03 - mmengine - INFO - Epoch(train) [36][1000/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:12:38  time: 0.6926  data_time: 0.0280  memory: 10371  loss: 1.2517  loss_rpn_cls: 0.0497  loss_rpn_bbox: 0.0333  s0.loss_cls: 0.2052  s0.acc: 99.0234  s0.loss_bbox: 0.2572  s0.loss_mask: 0.2395  s1.loss_cls: 0.0911  s1.acc: 98.9258  s1.loss_bbox: 0.1150  s1.loss_mask: 0.1185  s2.loss_cls: 0.0427  s2.acc: 99.0234  s2.loss_bbox: 0.0449  s2.loss_mask: 0.0544
2024/02/16 23:30:38 - mmengine - INFO - Epoch(train) [36][1050/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:12:04  time: 0.6848  data_time: 0.0298  memory: 9186  loss: 1.1435  loss_rpn_cls: 0.0482  loss_rpn_bbox: 0.0293  s0.loss_cls: 0.1764  s0.acc: 94.3359  s0.loss_bbox: 0.2293  s0.loss_mask: 0.2373  s1.loss_cls: 0.0756  s1.acc: 94.1406  s1.loss_bbox: 0.1036  s1.loss_mask: 0.1134  s2.loss_cls: 0.0359  s2.acc: 94.2383  s2.loss_bbox: 0.0417  s2.loss_mask: 0.0529
2024/02/16 23:31:12 - mmengine - INFO - Epoch(train) [36][1100/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:11:29  time: 0.6893  data_time: 0.0298  memory: 9780  loss: 1.2367  loss_rpn_cls: 0.0423  loss_rpn_bbox: 0.0341  s0.loss_cls: 0.1823  s0.acc: 93.0664  s0.loss_bbox: 0.2603  s0.loss_mask: 0.2613  s1.loss_cls: 0.0841  s1.acc: 92.9688  s1.loss_bbox: 0.1119  s1.loss_mask: 0.1236  s2.loss_cls: 0.0381  s2.acc: 97.0703  s2.loss_bbox: 0.0430  s2.loss_mask: 0.0556
2024/02/16 23:31:47 - mmengine - INFO - Epoch(train) [36][1150/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:10:55  time: 0.6863  data_time: 0.0286  memory: 9031  loss: 1.2079  loss_rpn_cls: 0.0446  loss_rpn_bbox: 0.0328  s0.loss_cls: 0.1951  s0.acc: 92.3828  s0.loss_bbox: 0.2504  s0.loss_mask: 0.2361  s1.loss_cls: 0.0855  s1.acc: 93.4570  s1.loss_bbox: 0.1111  s1.loss_mask: 0.1151  s2.loss_cls: 0.0402  s2.acc: 95.7031  s2.loss_bbox: 0.0440  s2.loss_mask: 0.0528
2024/02/16 23:32:21 - mmengine - INFO - Epoch(train) [36][1200/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:10:20  time: 0.6882  data_time: 0.0309  memory: 9834  loss: 1.0289  loss_rpn_cls: 0.0398  loss_rpn_bbox: 0.0278  s0.loss_cls: 0.1575  s0.acc: 92.2852  s0.loss_bbox: 0.2005  s0.loss_mask: 0.2179  s1.loss_cls: 0.0697  s1.acc: 93.3401  s1.loss_bbox: 0.0907  s1.loss_mask: 0.1051  s2.loss_cls: 0.0338  s2.acc: 92.0040  s2.loss_bbox: 0.0369  s2.loss_mask: 0.0493
2024/02/16 23:32:55 - mmengine - INFO - Epoch(train) [36][1250/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:09:46  time: 0.6865  data_time: 0.0256  memory: 9253  loss: 1.1772  loss_rpn_cls: 0.0424  loss_rpn_bbox: 0.0283  s0.loss_cls: 0.1894  s0.acc: 91.5039  s0.loss_bbox: 0.2405  s0.loss_mask: 0.2368  s1.loss_cls: 0.0830  s1.acc: 94.2540  s1.loss_bbox: 0.1077  s1.loss_mask: 0.1130  s2.loss_cls: 0.0396  s2.acc: 94.2132  s2.loss_bbox: 0.0432  s2.loss_mask: 0.0532
2024/02/16 23:33:30 - mmengine - INFO - Epoch(train) [36][1300/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:09:12  time: 0.6931  data_time: 0.0247  memory: 9560  loss: 1.1985  loss_rpn_cls: 0.0351  loss_rpn_bbox: 0.0253  s0.loss_cls: 0.1993  s0.acc: 95.0195  s0.loss_bbox: 0.2401  s0.loss_mask: 0.2430  s1.loss_cls: 0.0900  s1.acc: 98.2422  s1.loss_bbox: 0.1085  s1.loss_mask: 0.1168  s2.loss_cls: 0.0424  s2.acc: 96.3867  s2.loss_bbox: 0.0431  s2.loss_mask: 0.0549
2024/02/16 23:34:05 - mmengine - INFO - Epoch(train) [36][1350/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:08:37  time: 0.6991  data_time: 0.0283  memory: 9739  loss: 1.2540  loss_rpn_cls: 0.0493  loss_rpn_bbox: 0.0318  s0.loss_cls: 0.1925  s0.acc: 95.5078  s0.loss_bbox: 0.2589  s0.loss_mask: 0.2555  s1.loss_cls: 0.0847  s1.acc: 95.0195  s1.loss_bbox: 0.1145  s1.loss_mask: 0.1238  s2.loss_cls: 0.0398  s2.acc: 94.7266  s2.loss_bbox: 0.0459  s2.loss_mask: 0.0573
2024/02/16 23:34:40 - mmengine - INFO - Epoch(train) [36][1400/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:08:03  time: 0.6926  data_time: 0.0259  memory: 9335  loss: 1.1822  loss_rpn_cls: 0.0429  loss_rpn_bbox: 0.0299  s0.loss_cls: 0.1791  s0.acc: 99.6094  s0.loss_bbox: 0.2434  s0.loss_mask: 0.2378  s1.loss_cls: 0.0817  s1.acc: 99.7070  s1.loss_bbox: 0.1111  s1.loss_mask: 0.1176  s2.loss_cls: 0.0391  s2.acc: 99.7070  s2.loss_bbox: 0.0447  s2.loss_mask: 0.0549
2024/02/16 23:35:14 - mmengine - INFO - Exp name: cascade_mask_rcnn_swin_tiny_patch4_window7_mstrain_480-800_giou_4conv1f_adamw_3x_coco_20240216_214910
2024/02/16 23:35:14 - mmengine - INFO - Epoch(train) [36][1450/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:07:29  time: 0.6906  data_time: 0.0260  memory: 9710  loss: 1.2025  loss_rpn_cls: 0.0415  loss_rpn_bbox: 0.0249  s0.loss_cls: 0.1927  s0.acc: 94.5312  s0.loss_bbox: 0.2530  s0.loss_mask: 0.2404  s1.loss_cls: 0.0855  s1.acc: 95.2008  s1.loss_bbox: 0.1111  s1.loss_mask: 0.1155  s2.loss_cls: 0.0401  s2.acc: 95.1028  s2.loss_bbox: 0.0442  s2.loss_mask: 0.0535
2024/02/16 23:35:48 - mmengine - INFO - Epoch(train) [36][1500/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:06:54  time: 0.6829  data_time: 0.0270  memory: 9885  loss: 1.1416  loss_rpn_cls: 0.0389  loss_rpn_bbox: 0.0247  s0.loss_cls: 0.1868  s0.acc: 96.0938  s0.loss_bbox: 0.2327  s0.loss_mask: 0.2268  s1.loss_cls: 0.0783  s1.acc: 98.9216  s1.loss_bbox: 0.1068  s1.loss_mask: 0.1124  s2.loss_cls: 0.0370  s2.acc: 98.6234  s2.loss_bbox: 0.0449  s2.loss_mask: 0.0524
2024/02/16 23:36:23 - mmengine - INFO - Epoch(train) [36][1550/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:06:20  time: 0.6868  data_time: 0.0290  memory: 9298  loss: 1.3083  loss_rpn_cls: 0.0495  loss_rpn_bbox: 0.0366  s0.loss_cls: 0.2051  s0.acc: 91.8945  s0.loss_bbox: 0.2754  s0.loss_mask: 0.2527  s1.loss_cls: 0.0913  s1.acc: 94.9505  s1.loss_bbox: 0.1233  s1.loss_mask: 0.1250  s2.loss_cls: 0.0422  s2.acc: 95.4365  s2.loss_bbox: 0.0490  s2.loss_mask: 0.0582
2024/02/16 23:36:57 - mmengine - INFO - Epoch(train) [36][1600/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:05:45  time: 0.6872  data_time: 0.0269  memory: 8851  loss: 1.1696  loss_rpn_cls: 0.0463  loss_rpn_bbox: 0.0269  s0.loss_cls: 0.1815  s0.acc: 91.7969  s0.loss_bbox: 0.2443  s0.loss_mask: 0.2335  s1.loss_cls: 0.0807  s1.acc: 93.7931  s1.loss_bbox: 0.1079  s1.loss_mask: 0.1151  s2.loss_cls: 0.0395  s2.acc: 95.2709  s2.loss_bbox: 0.0405  s2.loss_mask: 0.0534
2024/02/16 23:37:31 - mmengine - INFO - Epoch(train) [36][1650/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:05:11  time: 0.6795  data_time: 0.0242  memory: 9468  loss: 1.1293  loss_rpn_cls: 0.0368  loss_rpn_bbox: 0.0224  s0.loss_cls: 0.1761  s0.acc: 93.1641  s0.loss_bbox: 0.2235  s0.loss_mask: 0.2459  s1.loss_cls: 0.0770  s1.acc: 91.6992  s1.loss_bbox: 0.1003  s1.loss_mask: 0.1174  s2.loss_cls: 0.0363  s2.acc: 92.5781  s2.loss_bbox: 0.0395  s2.loss_mask: 0.0542
2024/02/16 23:38:05 - mmengine - INFO - Epoch(train) [36][1700/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:04:36  time: 0.6832  data_time: 0.0274  memory: 9806  loss: 1.0616  loss_rpn_cls: 0.0404  loss_rpn_bbox: 0.0288  s0.loss_cls: 0.1591  s0.acc: 95.4102  s0.loss_bbox: 0.2104  s0.loss_mask: 0.2257  s1.loss_cls: 0.0691  s1.acc: 96.1962  s1.loss_bbox: 0.0950  s1.loss_mask: 0.1108  s2.loss_cls: 0.0316  s2.acc: 96.7644  s2.loss_bbox: 0.0395  s2.loss_mask: 0.0512
2024/02/16 23:38:39 - mmengine - INFO - Epoch(train) [36][1750/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:04:01  time: 0.6769  data_time: 0.0271  memory: 9250  loss: 1.2206  loss_rpn_cls: 0.0379  loss_rpn_bbox: 0.0279  s0.loss_cls: 0.1888  s0.acc: 94.7266  s0.loss_bbox: 0.2623  s0.loss_mask: 0.2499  s1.loss_cls: 0.0835  s1.acc: 96.0938  s1.loss_bbox: 0.1125  s1.loss_mask: 0.1190  s2.loss_cls: 0.0401  s2.acc: 96.8750  s2.loss_bbox: 0.0436  s2.loss_mask: 0.0551
2024/02/16 23:39:14 - mmengine - INFO - Epoch(train) [36][1800/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:03:27  time: 0.6930  data_time: 0.0271  memory: 9352  loss: 1.0841  loss_rpn_cls: 0.0354  loss_rpn_bbox: 0.0241  s0.loss_cls: 0.1726  s0.acc: 97.0703  s0.loss_bbox: 0.2295  s0.loss_mask: 0.2160  s1.loss_cls: 0.0746  s1.acc: 97.8175  s1.loss_bbox: 0.1032  s1.loss_mask: 0.1039  s2.loss_cls: 0.0348  s2.acc: 97.1230  s2.loss_bbox: 0.0417  s2.loss_mask: 0.0485
2024/02/16 23:39:48 - mmengine - INFO - Epoch(train) [36][1850/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:02:52  time: 0.6879  data_time: 0.0287  memory: 9559  loss: 1.1150  loss_rpn_cls: 0.0348  loss_rpn_bbox: 0.0245  s0.loss_cls: 0.1726  s0.acc: 94.0430  s0.loss_bbox: 0.2305  s0.loss_mask: 0.2285  s1.loss_cls: 0.0755  s1.acc: 95.7031  s1.loss_bbox: 0.1051  s1.loss_mask: 0.1125  s2.loss_cls: 0.0356  s2.acc: 95.8008  s2.loss_bbox: 0.0428  s2.loss_mask: 0.0526
2024/02/16 23:40:23 - mmengine - INFO - Epoch(train) [36][1900/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:02:18  time: 0.6844  data_time: 0.0282  memory: 9673  loss: 1.2380  loss_rpn_cls: 0.0440  loss_rpn_bbox: 0.0308  s0.loss_cls: 0.1891  s0.acc: 92.3828  s0.loss_bbox: 0.2617  s0.loss_mask: 0.2492  s1.loss_cls: 0.0852  s1.acc: 93.0328  s1.loss_bbox: 0.1174  s1.loss_mask: 0.1196  s2.loss_cls: 0.0395  s2.acc: 95.2978  s2.loss_bbox: 0.0459  s2.loss_mask: 0.0556
2024/02/16 23:40:57 - mmengine - INFO - Epoch(train) [36][1950/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:01:43  time: 0.6896  data_time: 0.0254  memory: 8693  loss: 1.2269  loss_rpn_cls: 0.0429  loss_rpn_bbox: 0.0262  s0.loss_cls: 0.1905  s0.acc: 97.0703  s0.loss_bbox: 0.2627  s0.loss_mask: 0.2529  s1.loss_cls: 0.0813  s1.acc: 98.7305  s1.loss_bbox: 0.1147  s1.loss_mask: 0.1188  s2.loss_cls: 0.0371  s2.acc: 98.9258  s2.loss_bbox: 0.0447  s2.loss_mask: 0.0551
2024/02/16 23:41:31 - mmengine - INFO - Epoch(train) [36][2000/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:01:09  time: 0.6824  data_time: 0.0307  memory: 10141  loss: 1.2181  loss_rpn_cls: 0.0471  loss_rpn_bbox: 0.0298  s0.loss_cls: 0.1938  s0.acc: 84.4727  s0.loss_bbox: 0.2574  s0.loss_mask: 0.2393  s1.loss_cls: 0.0839  s1.acc: 85.4564  s1.loss_bbox: 0.1145  s1.loss_mask: 0.1142  s2.loss_cls: 0.0406  s2.acc: 88.4000  s2.loss_bbox: 0.0454  s2.loss_mask: 0.0522
2024/02/16 23:42:06 - mmengine - INFO - Epoch(train) [36][2050/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:00:35  time: 0.6918  data_time: 0.0297  memory: 9443  loss: 1.3034  loss_rpn_cls: 0.0429  loss_rpn_bbox: 0.0328  s0.loss_cls: 0.2122  s0.acc: 91.1133  s0.loss_bbox: 0.2819  s0.loss_mask: 0.2454  s1.loss_cls: 0.0927  s1.acc: 91.0156  s1.loss_bbox: 0.1260  s1.loss_mask: 0.1200  s2.loss_cls: 0.0438  s2.acc: 91.5039  s2.loss_bbox: 0.0496  s2.loss_mask: 0.0560
2024/02/16 23:42:40 - mmengine - INFO - Epoch(train) [36][2100/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:00:00  time: 0.6885  data_time: 0.0250  memory: 9376  loss: 1.1475  loss_rpn_cls: 0.0394  loss_rpn_bbox: 0.0252  s0.loss_cls: 0.1691  s0.acc: 95.6055  s0.loss_bbox: 0.2408  s0.loss_mask: 0.2378  s1.loss_cls: 0.0791  s1.acc: 94.1406  s1.loss_bbox: 0.1081  s1.loss_mask: 0.1163  s2.loss_cls: 0.0375  s2.acc: 95.6055  s2.loss_bbox: 0.0418  s2.loss_mask: 0.0523
2024/02/16 23:43:15 - mmengine - INFO - Epoch(train) [36][2150/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:59:26  time: 0.6882  data_time: 0.0264  memory: 9140  loss: 1.0596  loss_rpn_cls: 0.0345  loss_rpn_bbox: 0.0243  s0.loss_cls: 0.1692  s0.acc: 97.1680  s0.loss_bbox: 0.2118  s0.loss_mask: 0.2176  s1.loss_cls: 0.0726  s1.acc: 98.4647  s1.loss_bbox: 0.0975  s1.loss_mask: 0.1080  s2.loss_cls: 0.0340  s2.acc: 97.4200  s2.loss_bbox: 0.0397  s2.loss_mask: 0.0505
2024/02/16 23:43:49 - mmengine - INFO - Epoch(train) [36][2200/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:58:51  time: 0.6817  data_time: 0.0252  memory: 9684  loss: 1.0627  loss_rpn_cls: 0.0389  loss_rpn_bbox: 0.0256  s0.loss_cls: 0.1566  s0.acc: 88.4766  s0.loss_bbox: 0.2208  s0.loss_mask: 0.2161  s1.loss_cls: 0.0677  s1.acc: 90.2263  s1.loss_bbox: 0.1050  s1.loss_mask: 0.1074  s2.loss_cls: 0.0310  s2.acc: 91.1614  s2.loss_bbox: 0.0431  s2.loss_mask: 0.0505
2024/02/16 23:44:24 - mmengine - INFO - Epoch(train) [36][2250/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:58:17  time: 0.6909  data_time: 0.0252  memory: 9922  loss: 1.2112  loss_rpn_cls: 0.0361  loss_rpn_bbox: 0.0271  s0.loss_cls: 0.1832  s0.acc: 91.0156  s0.loss_bbox: 0.2552  s0.loss_mask: 0.2613  s1.loss_cls: 0.0776  s1.acc: 94.6392  s1.loss_bbox: 0.1142  s1.loss_mask: 0.1197  s2.loss_cls: 0.0379  s2.acc: 92.6955  s2.loss_bbox: 0.0437  s2.loss_mask: 0.0552
2024/02/16 23:44:58 - mmengine - INFO - Epoch(train) [36][2300/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:57:42  time: 0.6904  data_time: 0.0261  memory: 10219  loss: 1.2476  loss_rpn_cls: 0.0379  loss_rpn_bbox: 0.0278  s0.loss_cls: 0.1924  s0.acc: 95.5078  s0.loss_bbox: 0.2762  s0.loss_mask: 0.2471  s1.loss_cls: 0.0846  s1.acc: 95.4102  s1.loss_bbox: 0.1201  s1.loss_mask: 0.1188  s2.loss_cls: 0.0397  s2.acc: 94.1176  s2.loss_bbox: 0.0476  s2.loss_mask: 0.0554
2024/02/16 23:45:32 - mmengine - INFO - Epoch(train) [36][2350/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:57:08  time: 0.6867  data_time: 0.0290  memory: 10129  loss: 1.2501  loss_rpn_cls: 0.0459  loss_rpn_bbox: 0.0244  s0.loss_cls: 0.1972  s0.acc: 92.6758  s0.loss_bbox: 0.2623  s0.loss_mask: 0.2497  s1.loss_cls: 0.0861  s1.acc: 92.4116  s1.loss_bbox: 0.1158  s1.loss_mask: 0.1246  s2.loss_cls: 0.0411  s2.acc: 95.0000  s2.loss_bbox: 0.0452  s2.loss_mask: 0.0578
2024/02/16 23:46:07 - mmengine - INFO - Epoch(train) [36][2400/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:56:34  time: 0.6948  data_time: 0.0319  memory: 9398  loss: 1.3259  loss_rpn_cls: 0.0429  loss_rpn_bbox: 0.0336  s0.loss_cls: 0.2095  s0.acc: 90.8203  s0.loss_bbox: 0.2928  s0.loss_mask: 0.2565  s1.loss_cls: 0.0957  s1.acc: 92.3383  s1.loss_bbox: 0.1235  s1.loss_mask: 0.1219  s2.loss_cls: 0.0451  s2.acc: 92.1471  s2.loss_bbox: 0.0476  s2.loss_mask: 0.0567
2024/02/16 23:46:41 - mmengine - INFO - Exp name: cascade_mask_rcnn_swin_tiny_patch4_window7_mstrain_480-800_giou_4conv1f_adamw_3x_coco_20240216_214910
2024/02/16 23:46:41 - mmengine - INFO - Epoch(train) [36][2450/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:55:59  time: 0.6828  data_time: 0.0244  memory: 9335  loss: 1.1306  loss_rpn_cls: 0.0425  loss_rpn_bbox: 0.0250  s0.loss_cls: 0.1753  s0.acc: 88.5742  s0.loss_bbox: 0.2283  s0.loss_mask: 0.2301  s1.loss_cls: 0.0797  s1.acc: 90.2390  s1.loss_bbox: 0.1046  s1.loss_mask: 0.1125  s2.loss_cls: 0.0373  s2.acc: 89.8608  s2.loss_bbox: 0.0424  s2.loss_mask: 0.0527
2024/02/16 23:47:16 - mmengine - INFO - Epoch(train) [36][2500/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:55:25  time: 0.6875  data_time: 0.0249  memory: 9554  loss: 1.1888  loss_rpn_cls: 0.0420  loss_rpn_bbox: 0.0260  s0.loss_cls: 0.1952  s0.acc: 89.4531  s0.loss_bbox: 0.2503  s0.loss_mask: 0.2284  s1.loss_cls: 0.0847  s1.acc: 91.8945  s1.loss_bbox: 0.1136  s1.loss_mask: 0.1109  s2.loss_cls: 0.0389  s2.acc: 93.4570  s2.loss_bbox: 0.0462  s2.loss_mask: 0.0526
2024/02/16 23:47:50 - mmengine - INFO - Epoch(train) [36][2550/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:54:50  time: 0.6929  data_time: 0.0269  memory: 9271  loss: 1.1294  loss_rpn_cls: 0.0381  loss_rpn_bbox: 0.0278  s0.loss_cls: 0.1696  s0.acc: 98.0469  s0.loss_bbox: 0.2416  s0.loss_mask: 0.2246  s1.loss_cls: 0.0761  s1.acc: 97.9492  s1.loss_bbox: 0.1117  s1.loss_mask: 0.1087  s2.loss_cls: 0.0359  s2.acc: 98.6328  s2.loss_bbox: 0.0442  s2.loss_mask: 0.0511
2024/02/16 23:48:25 - mmengine - INFO - Epoch(train) [36][2600/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:54:16  time: 0.6974  data_time: 0.0285  memory: 9345  loss: 1.2171  loss_rpn_cls: 0.0432  loss_rpn_bbox: 0.0277  s0.loss_cls: 0.1916  s0.acc: 97.8516  s0.loss_bbox: 0.2590  s0.loss_mask: 0.2389  s1.loss_cls: 0.0877  s1.acc: 99.1211  s1.loss_bbox: 0.1155  s1.loss_mask: 0.1145  s2.loss_cls: 0.0409  s2.acc: 98.5352  s2.loss_bbox: 0.0456  s2.loss_mask: 0.0524
2024/02/16 23:49:00 - mmengine - INFO - Epoch(train) [36][2650/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:53:42  time: 0.6919  data_time: 0.0264  memory: 9930  loss: 1.0705  loss_rpn_cls: 0.0381  loss_rpn_bbox: 0.0296  s0.loss_cls: 0.1612  s0.acc: 90.4297  s0.loss_bbox: 0.2133  s0.loss_mask: 0.2293  s1.loss_cls: 0.0710  s1.acc: 91.5725  s1.loss_bbox: 0.0959  s1.loss_mask: 0.1094  s2.loss_cls: 0.0347  s2.acc: 92.2440  s2.loss_bbox: 0.0370  s2.loss_mask: 0.0509
2024/02/16 23:49:34 - mmengine - INFO - Epoch(train) [36][2700/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:53:07  time: 0.6803  data_time: 0.0259  memory: 9625  loss: 1.2567  loss_rpn_cls: 0.0472  loss_rpn_bbox: 0.0337  s0.loss_cls: 0.1972  s0.acc: 95.5078  s0.loss_bbox: 0.2733  s0.loss_mask: 0.2405  s1.loss_cls: 0.0860  s1.acc: 94.4336  s1.loss_bbox: 0.1214  s1.loss_mask: 0.1160  s2.loss_cls: 0.0403  s2.acc: 94.5312  s2.loss_bbox: 0.0476  s2.loss_mask: 0.0536
2024/02/16 23:50:08 - mmengine - INFO - Epoch(train) [36][2750/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:52:33  time: 0.6793  data_time: 0.0254  memory: 9362  loss: 1.1442  loss_rpn_cls: 0.0340  loss_rpn_bbox: 0.0279  s0.loss_cls: 0.1691  s0.acc: 97.0703  s0.loss_bbox: 0.2252  s0.loss_mask: 0.2486  s1.loss_cls: 0.0758  s1.acc: 98.8281  s1.loss_bbox: 0.1040  s1.loss_mask: 0.1218  s2.loss_cls: 0.0386  s2.acc: 97.3633  s2.loss_bbox: 0.0404  s2.loss_mask: 0.0586
2024/02/16 23:50:42 - mmengine - INFO - Epoch(train) [36][2800/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:51:58  time: 0.6737  data_time: 0.0253  memory: 9469  loss: 1.1245  loss_rpn_cls: 0.0344  loss_rpn_bbox: 0.0267  s0.loss_cls: 0.1726  s0.acc: 96.5820  s0.loss_bbox: 0.2377  s0.loss_mask: 0.2251  s1.loss_cls: 0.0746  s1.acc: 95.9961  s1.loss_bbox: 0.1111  s1.loss_mask: 0.1107  s2.loss_cls: 0.0363  s2.acc: 92.6758  s2.loss_bbox: 0.0443  s2.loss_mask: 0.0509
2024/02/16 23:51:16 - mmengine - INFO - Epoch(train) [36][2850/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:51:23  time: 0.6917  data_time: 0.0268  memory: 10214  loss: 1.2778  loss_rpn_cls: 0.0434  loss_rpn_bbox: 0.0317  s0.loss_cls: 0.2086  s0.acc: 92.6758  s0.loss_bbox: 0.2574  s0.loss_mask: 0.2579  s1.loss_cls: 0.0901  s1.acc: 95.5239  s1.loss_bbox: 0.1141  s1.loss_mask: 0.1270  s2.loss_cls: 0.0421  s2.acc: 96.2437  s2.loss_bbox: 0.0452  s2.loss_mask: 0.0604
2024/02/16 23:51:51 - mmengine - INFO - Epoch(train) [36][2900/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:50:49  time: 0.6953  data_time: 0.0270  memory: 9466  loss: 1.0924  loss_rpn_cls: 0.0377  loss_rpn_bbox: 0.0266  s0.loss_cls: 0.1722  s0.acc: 95.9961  s0.loss_bbox: 0.2226  s0.loss_mask: 0.2170  s1.loss_cls: 0.0743  s1.acc: 96.7773  s1.loss_bbox: 0.1030  s1.loss_mask: 0.1080  s2.loss_cls: 0.0376  s2.acc: 93.8477  s2.loss_bbox: 0.0427  s2.loss_mask: 0.0506
2024/02/16 23:52:25 - mmengine - INFO - Epoch(train) [36][2950/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:50:15  time: 0.6861  data_time: 0.0252  memory: 9384  loss: 1.2056  loss_rpn_cls: 0.0383  loss_rpn_bbox: 0.0276  s0.loss_cls: 0.1827  s0.acc: 94.2383  s0.loss_bbox: 0.2528  s0.loss_mask: 0.2479  s1.loss_cls: 0.0821  s1.acc: 96.2891  s1.loss_bbox: 0.1154  s1.loss_mask: 0.1188  s2.loss_cls: 0.0387  s2.acc: 97.0703  s2.loss_bbox: 0.0458  s2.loss_mask: 0.0555
2024/02/16 23:53:00 - mmengine - INFO - Epoch(train) [36][3000/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:49:40  time: 0.6869  data_time: 0.0274  memory: 9883  loss: 1.2416  loss_rpn_cls: 0.0391  loss_rpn_bbox: 0.0314  s0.loss_cls: 0.1878  s0.acc: 96.0938  s0.loss_bbox: 0.2575  s0.loss_mask: 0.2565  s1.loss_cls: 0.0854  s1.acc: 98.7305  s1.loss_bbox: 0.1180  s1.loss_mask: 0.1231  s2.loss_cls: 0.0412  s2.acc: 98.2422  s2.loss_bbox: 0.0452  s2.loss_mask: 0.0562
2024/02/16 23:53:34 - mmengine - INFO - Epoch(train) [36][3050/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:49:06  time: 0.6782  data_time: 0.0261  memory: 9551  loss: 1.1374  loss_rpn_cls: 0.0366  loss_rpn_bbox: 0.0212  s0.loss_cls: 0.1810  s0.acc: 89.0625  s0.loss_bbox: 0.2425  s0.loss_mask: 0.2281  s1.loss_cls: 0.0783  s1.acc: 91.9162  s1.loss_bbox: 0.1079  s1.loss_mask: 0.1102  s2.loss_cls: 0.0358  s2.acc: 91.8245  s2.loss_bbox: 0.0438  s2.loss_mask: 0.0520
2024/02/16 23:54:08 - mmengine - INFO - Epoch(train) [36][3100/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:48:31  time: 0.6903  data_time: 0.0258  memory: 9743  loss: 1.2004  loss_rpn_cls: 0.0388  loss_rpn_bbox: 0.0251  s0.loss_cls: 0.1804  s0.acc: 93.2617  s0.loss_bbox: 0.2568  s0.loss_mask: 0.2523  s1.loss_cls: 0.0824  s1.acc: 93.6318  s1.loss_bbox: 0.1082  s1.loss_mask: 0.1206  s2.loss_cls: 0.0390  s2.acc: 94.9203  s2.loss_bbox: 0.0410  s2.loss_mask: 0.0557
2024/02/16 23:54:43 - mmengine - INFO - Epoch(train) [36][3150/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:47:57  time: 0.6902  data_time: 0.0303  memory: 9179  loss: 1.1289  loss_rpn_cls: 0.0362  loss_rpn_bbox: 0.0303  s0.loss_cls: 0.1838  s0.acc: 94.2383  s0.loss_bbox: 0.2298  s0.loss_mask: 0.2247  s1.loss_cls: 0.0799  s1.acc: 94.5066  s1.loss_bbox: 0.1029  s1.loss_mask: 0.1106  s2.loss_cls: 0.0372  s2.acc: 94.4615  s2.loss_bbox: 0.0420  s2.loss_mask: 0.0515
2024/02/16 23:55:18 - mmengine - INFO - Epoch(train) [36][3200/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:47:23  time: 0.6943  data_time: 0.0252  memory: 9540  loss: 1.2811  loss_rpn_cls: 0.0493  loss_rpn_bbox: 0.0327  s0.loss_cls: 0.2153  s0.acc: 92.1875  s0.loss_bbox: 0.2731  s0.loss_mask: 0.2363  s1.loss_cls: 0.0978  s1.acc: 95.1172  s1.loss_bbox: 0.1207  s1.loss_mask: 0.1126  s2.loss_cls: 0.0457  s2.acc: 96.0938  s2.loss_bbox: 0.0469  s2.loss_mask: 0.0508
2024/02/16 23:55:52 - mmengine - INFO - Epoch(train) [36][3250/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:46:48  time: 0.6866  data_time: 0.0262  memory: 9539  loss: 1.1801  loss_rpn_cls: 0.0430  loss_rpn_bbox: 0.0310  s0.loss_cls: 0.1875  s0.acc: 87.8906  s0.loss_bbox: 0.2553  s0.loss_mask: 0.2239  s1.loss_cls: 0.0811  s1.acc: 86.9694  s1.loss_bbox: 0.1146  s1.loss_mask: 0.1087  s2.loss_cls: 0.0390  s2.acc: 87.5000  s2.loss_bbox: 0.0456  s2.loss_mask: 0.0505
2024/02/16 23:56:27 - mmengine - INFO - Epoch(train) [36][3300/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:46:14  time: 0.6913  data_time: 0.0311  memory: 9722  loss: 1.3049  loss_rpn_cls: 0.0467  loss_rpn_bbox: 0.0325  s0.loss_cls: 0.2139  s0.acc: 94.7266  s0.loss_bbox: 0.2787  s0.loss_mask: 0.2457  s1.loss_cls: 0.0947  s1.acc: 93.2798  s1.loss_bbox: 0.1217  s1.loss_mask: 0.1204  s2.loss_cls: 0.0457  s2.acc: 95.2953  s2.loss_bbox: 0.0483  s2.loss_mask: 0.0566
2024/02/16 23:57:01 - mmengine - INFO - Epoch(train) [36][3350/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:45:39  time: 0.6873  data_time: 0.0263  memory: 10801  loss: 1.1831  loss_rpn_cls: 0.0378  loss_rpn_bbox: 0.0237  s0.loss_cls: 0.1778  s0.acc: 91.8945  s0.loss_bbox: 0.2330  s0.loss_mask: 0.2596  s1.loss_cls: 0.0788  s1.acc: 93.9723  s1.loss_bbox: 0.1068  s1.loss_mask: 0.1270  s2.loss_cls: 0.0381  s2.acc: 92.7866  s2.loss_bbox: 0.0416  s2.loss_mask: 0.0589
2024/02/16 23:57:35 - mmengine - INFO - Epoch(train) [36][3400/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:45:05  time: 0.6880  data_time: 0.0272  memory: 10224  loss: 1.1887  loss_rpn_cls: 0.0404  loss_rpn_bbox: 0.0269  s0.loss_cls: 0.1901  s0.acc: 91.8945  s0.loss_bbox: 0.2506  s0.loss_mask: 0.2346  s1.loss_cls: 0.0833  s1.acc: 93.5157  s1.loss_bbox: 0.1132  s1.loss_mask: 0.1137  s2.loss_cls: 0.0385  s2.acc: 93.8900  s2.loss_bbox: 0.0454  s2.loss_mask: 0.0520
2024/02/16 23:58:10 - mmengine - INFO - Exp name: cascade_mask_rcnn_swin_tiny_patch4_window7_mstrain_480-800_giou_4conv1f_adamw_3x_coco_20240216_214910
2024/02/16 23:58:10 - mmengine - INFO - Epoch(train) [36][3450/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:44:30  time: 0.6870  data_time: 0.0242  memory: 9609  loss: 1.1151  loss_rpn_cls: 0.0417  loss_rpn_bbox: 0.0248  s0.loss_cls: 0.1727  s0.acc: 97.7539  s0.loss_bbox: 0.2199  s0.loss_mask: 0.2335  s1.loss_cls: 0.0770  s1.acc: 97.2656  s1.loss_bbox: 0.0997  s1.loss_mask: 0.1159  s2.loss_cls: 0.0342  s2.acc: 97.3633  s2.loss_bbox: 0.0411  s2.loss_mask: 0.0545
2024/02/16 23:58:44 - mmengine - INFO - Epoch(train) [36][3500/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:43:56  time: 0.6923  data_time: 0.0281  memory: 9594  loss: 1.1813  loss_rpn_cls: 0.0428  loss_rpn_bbox: 0.0342  s0.loss_cls: 0.1832  s0.acc: 90.5273  s0.loss_bbox: 0.2491  s0.loss_mask: 0.2274  s1.loss_cls: 0.0825  s1.acc: 92.7638  s1.loss_bbox: 0.1139  s1.loss_mask: 0.1114  s2.loss_cls: 0.0394  s2.acc: 91.9598  s2.loss_bbox: 0.0454  s2.loss_mask: 0.0521
2024/02/16 23:59:19 - mmengine - INFO - Epoch(train) [36][3550/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:43:22  time: 0.6845  data_time: 0.0276  memory: 10954  loss: 1.1785  loss_rpn_cls: 0.0398  loss_rpn_bbox: 0.0296  s0.loss_cls: 0.1910  s0.acc: 96.1914  s0.loss_bbox: 0.2394  s0.loss_mask: 0.2354  s1.loss_cls: 0.0838  s1.acc: 94.6289  s1.loss_bbox: 0.1068  s1.loss_mask: 0.1154  s2.loss_cls: 0.0401  s2.acc: 94.8242  s2.loss_bbox: 0.0428  s2.loss_mask: 0.0543
2024/02/16 23:59:54 - mmengine - INFO - Epoch(train) [36][3600/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:42:47  time: 0.6971  data_time: 0.0277  memory: 9516  loss: 1.2451  loss_rpn_cls: 0.0505  loss_rpn_bbox: 0.0320  s0.loss_cls: 0.1903  s0.acc: 91.6992  s0.loss_bbox: 0.2691  s0.loss_mask: 0.2409  s1.loss_cls: 0.0828  s1.acc: 95.0199  s1.loss_bbox: 0.1192  s1.loss_mask: 0.1178  s2.loss_cls: 0.0398  s2.acc: 93.6299  s2.loss_bbox: 0.0473  s2.loss_mask: 0.0555
2024/02/17 00:00:28 - mmengine - INFO - Epoch(train) [36][3650/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:42:13  time: 0.6896  data_time: 0.0269  memory: 9320  loss: 1.1395  loss_rpn_cls: 0.0379  loss_rpn_bbox: 0.0262  s0.loss_cls: 0.1742  s0.acc: 96.4844  s0.loss_bbox: 0.2387  s0.loss_mask: 0.2382  s1.loss_cls: 0.0769  s1.acc: 96.6797  s1.loss_bbox: 0.1034  s1.loss_mask: 0.1141  s2.loss_cls: 0.0351  s2.acc: 96.3867  s2.loss_bbox: 0.0420  s2.loss_mask: 0.0530
2024/02/17 00:01:02 - mmengine - INFO - Epoch(train) [36][3700/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:41:38  time: 0.6874  data_time: 0.0307  memory: 9432  loss: 1.2452  loss_rpn_cls: 0.0449  loss_rpn_bbox: 0.0313  s0.loss_cls: 0.1985  s0.acc: 92.6758  s0.loss_bbox: 0.2625  s0.loss_mask: 0.2434  s1.loss_cls: 0.0862  s1.acc: 93.0303  s1.loss_bbox: 0.1175  s1.loss_mask: 0.1189  s2.loss_cls: 0.0406  s2.acc: 92.5553  s2.loss_bbox: 0.0460  s2.loss_mask: 0.0554
2024/02/17 00:01:37 - mmengine - INFO - Epoch(train) [36][3750/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:41:04  time: 0.6964  data_time: 0.0251  memory: 9615  loss: 1.1451  loss_rpn_cls: 0.0383  loss_rpn_bbox: 0.0263  s0.loss_cls: 0.1782  s0.acc: 83.8867  s0.loss_bbox: 0.2311  s0.loss_mask: 0.2433  s1.loss_cls: 0.0766  s1.acc: 83.5294  s1.loss_bbox: 0.1024  s1.loss_mask: 0.1184  s2.loss_cls: 0.0349  s2.acc: 82.4682  s2.loss_bbox: 0.0408  s2.loss_mask: 0.0547
2024/02/17 00:02:11 - mmengine - INFO - Epoch(train) [36][3800/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:40:30  time: 0.6788  data_time: 0.0252  memory: 9218  loss: 1.2105  loss_rpn_cls: 0.0361  loss_rpn_bbox: 0.0257  s0.loss_cls: 0.1817  s0.acc: 92.5781  s0.loss_bbox: 0.2574  s0.loss_mask: 0.2555  s1.loss_cls: 0.0752  s1.acc: 92.3828  s1.loss_bbox: 0.1146  s1.loss_mask: 0.1238  s2.loss_cls: 0.0361  s2.acc: 92.6758  s2.loss_bbox: 0.0460  s2.loss_mask: 0.0584
2024/02/17 00:02:47 - mmengine - INFO - Epoch(train) [36][3850/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:39:55  time: 0.7082  data_time: 0.0282  memory: 9963  loss: 1.0876  loss_rpn_cls: 0.0344  loss_rpn_bbox: 0.0251  s0.loss_cls: 0.1727  s0.acc: 93.2617  s0.loss_bbox: 0.2195  s0.loss_mask: 0.2291  s1.loss_cls: 0.0755  s1.acc: 94.8869  s1.loss_bbox: 0.0977  s1.loss_mask: 0.1107  s2.loss_cls: 0.0341  s2.acc: 92.4287  s2.loss_bbox: 0.0380  s2.loss_mask: 0.0507
2024/02/17 00:03:22 - mmengine - INFO - Epoch(train) [36][3900/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:39:21  time: 0.6971  data_time: 0.0264  memory: 9716  loss: 1.1877  loss_rpn_cls: 0.0413  loss_rpn_bbox: 0.0322  s0.loss_cls: 0.1921  s0.acc: 98.3398  s0.loss_bbox: 0.2409  s0.loss_mask: 0.2404  s1.loss_cls: 0.0828  s1.acc: 99.5117  s1.loss_bbox: 0.1070  s1.loss_mask: 0.1166  s2.loss_cls: 0.0393  s2.acc: 99.3164  s2.loss_bbox: 0.0411  s2.loss_mask: 0.0540
2024/02/17 00:03:56 - mmengine - INFO - Epoch(train) [36][3950/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:38:47  time: 0.6854  data_time: 0.0274  memory: 9735  loss: 1.1733  loss_rpn_cls: 0.0422  loss_rpn_bbox: 0.0262  s0.loss_cls: 0.1894  s0.acc: 96.0938  s0.loss_bbox: 0.2407  s0.loss_mask: 0.2320  s1.loss_cls: 0.0833  s1.acc: 96.8750  s1.loss_bbox: 0.1077  s1.loss_mask: 0.1141  s2.loss_cls: 0.0398  s2.acc: 98.2422  s2.loss_bbox: 0.0446  s2.loss_mask: 0.0533
2024/02/17 00:04:30 - mmengine - INFO - Epoch(train) [36][4000/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:38:12  time: 0.6845  data_time: 0.0277  memory: 11041  loss: 1.1974  loss_rpn_cls: 0.0382  loss_rpn_bbox: 0.0276  s0.loss_cls: 0.1889  s0.acc: 86.9141  s0.loss_bbox: 0.2401  s0.loss_mask: 0.2473  s1.loss_cls: 0.0807  s1.acc: 88.7586  s1.loss_bbox: 0.1123  s1.loss_mask: 0.1212  s2.loss_cls: 0.0382  s2.acc: 89.4428  s2.loss_bbox: 0.0455  s2.loss_mask: 0.0576
2024/02/17 00:05:05 - mmengine - INFO - Epoch(train) [36][4050/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:37:38  time: 0.6937  data_time: 0.0271  memory: 9598  loss: 1.1551  loss_rpn_cls: 0.0353  loss_rpn_bbox: 0.0233  s0.loss_cls: 0.1811  s0.acc: 91.5039  s0.loss_bbox: 0.2441  s0.loss_mask: 0.2359  s1.loss_cls: 0.0772  s1.acc: 92.4623  s1.loss_bbox: 0.1072  s1.loss_mask: 0.1144  s2.loss_cls: 0.0385  s2.acc: 91.3828  s2.loss_bbox: 0.0436  s2.loss_mask: 0.0545
2024/02/17 00:05:40 - mmengine - INFO - Epoch(train) [36][4100/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:37:04  time: 0.6962  data_time: 0.0267  memory: 9761  loss: 1.1716  loss_rpn_cls: 0.0432  loss_rpn_bbox: 0.0334  s0.loss_cls: 0.1791  s0.acc: 94.2383  s0.loss_bbox: 0.2409  s0.loss_mask: 0.2386  s1.loss_cls: 0.0816  s1.acc: 92.1875  s1.loss_bbox: 0.1072  s1.loss_mask: 0.1153  s2.loss_cls: 0.0387  s2.acc: 93.8477  s2.loss_bbox: 0.0408  s2.loss_mask: 0.0526
2024/02/17 00:06:14 - mmengine - INFO - Epoch(train) [36][4150/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:36:29  time: 0.6916  data_time: 0.0283  memory: 9977  loss: 1.1648  loss_rpn_cls: 0.0345  loss_rpn_bbox: 0.0291  s0.loss_cls: 0.1767  s0.acc: 96.5820  s0.loss_bbox: 0.2522  s0.loss_mask: 0.2419  s1.loss_cls: 0.0802  s1.acc: 97.8346  s1.loss_bbox: 0.1057  s1.loss_mask: 0.1135  s2.loss_cls: 0.0371  s2.acc: 97.5223  s2.loss_bbox: 0.0418  s2.loss_mask: 0.0523
2024/02/17 00:06:48 - mmengine - INFO - Epoch(train) [36][4200/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:35:55  time: 0.6814  data_time: 0.0257  memory: 9708  loss: 1.1333  loss_rpn_cls: 0.0293  loss_rpn_bbox: 0.0227  s0.loss_cls: 0.1746  s0.acc: 95.8008  s0.loss_bbox: 0.2385  s0.loss_mask: 0.2367  s1.loss_cls: 0.0741  s1.acc: 98.3398  s1.loss_bbox: 0.1066  s1.loss_mask: 0.1171  s2.loss_cls: 0.0360  s2.acc: 99.0234  s2.loss_bbox: 0.0434  s2.loss_mask: 0.0545
2024/02/17 00:07:23 - mmengine - INFO - Epoch(train) [36][4250/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:35:20  time: 0.6893  data_time: 0.0252  memory: 9659  loss: 1.1494  loss_rpn_cls: 0.0455  loss_rpn_bbox: 0.0274  s0.loss_cls: 0.1760  s0.acc: 89.4531  s0.loss_bbox: 0.2368  s0.loss_mask: 0.2335  s1.loss_cls: 0.0769  s1.acc: 91.6008  s1.loss_bbox: 0.1060  s1.loss_mask: 0.1145  s2.loss_cls: 0.0375  s2.acc: 93.1102  s2.loss_bbox: 0.0425  s2.loss_mask: 0.0528
2024/02/17 00:07:57 - mmengine - INFO - Epoch(train) [36][4300/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:34:46  time: 0.6897  data_time: 0.0317  memory: 9989  loss: 1.2470  loss_rpn_cls: 0.0416  loss_rpn_bbox: 0.0257  s0.loss_cls: 0.1943  s0.acc: 91.6016  s0.loss_bbox: 0.2636  s0.loss_mask: 0.2502  s1.loss_cls: 0.0894  s1.acc: 92.2542  s1.loss_bbox: 0.1171  s1.loss_mask: 0.1207  s2.loss_cls: 0.0433  s2.acc: 92.4678  s2.loss_bbox: 0.0456  s2.loss_mask: 0.0555
2024/02/17 00:08:32 - mmengine - INFO - Epoch(train) [36][4350/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:34:11  time: 0.6823  data_time: 0.0245  memory: 9714  loss: 1.0538  loss_rpn_cls: 0.0339  loss_rpn_bbox: 0.0219  s0.loss_cls: 0.1594  s0.acc: 91.6992  s0.loss_bbox: 0.2119  s0.loss_mask: 0.2211  s1.loss_cls: 0.0755  s1.acc: 88.9552  s1.loss_bbox: 0.0992  s1.loss_mask: 0.1069  s2.loss_cls: 0.0353  s2.acc: 89.7796  s2.loss_bbox: 0.0394  s2.loss_mask: 0.0493
2024/02/17 00:09:06 - mmengine - INFO - Epoch(train) [36][4400/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:33:37  time: 0.6792  data_time: 0.0249  memory: 10145  loss: 1.1135  loss_rpn_cls: 0.0386  loss_rpn_bbox: 0.0262  s0.loss_cls: 0.1730  s0.acc: 97.1680  s0.loss_bbox: 0.2273  s0.loss_mask: 0.2356  s1.loss_cls: 0.0770  s1.acc: 97.4609  s1.loss_bbox: 0.1002  s1.loss_mask: 0.1100  s2.loss_cls: 0.0348  s2.acc: 98.6328  s2.loss_bbox: 0.0397  s2.loss_mask: 0.0512
2024/02/17 00:09:40 - mmengine - INFO - Exp name: cascade_mask_rcnn_swin_tiny_patch4_window7_mstrain_480-800_giou_4conv1f_adamw_3x_coco_20240216_214910
2024/02/17 00:09:40 - mmengine - INFO - Epoch(train) [36][4450/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:33:02  time: 0.6931  data_time: 0.0255  memory: 9681  loss: 1.1842  loss_rpn_cls: 0.0378  loss_rpn_bbox: 0.0228  s0.loss_cls: 0.1926  s0.acc: 92.9688  s0.loss_bbox: 0.2478  s0.loss_mask: 0.2362  s1.loss_cls: 0.0838  s1.acc: 93.3594  s1.loss_bbox: 0.1114  s1.loss_mask: 0.1135  s2.loss_cls: 0.0407  s2.acc: 94.1406  s2.loss_bbox: 0.0445  s2.loss_mask: 0.0531
2024/02/17 00:10:14 - mmengine - INFO - Epoch(train) [36][4500/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:32:28  time: 0.6815  data_time: 0.0266  memory: 9728  loss: 1.2753  loss_rpn_cls: 0.0416  loss_rpn_bbox: 0.0340  s0.loss_cls: 0.1976  s0.acc: 94.9219  s0.loss_bbox: 0.2722  s0.loss_mask: 0.2531  s1.loss_cls: 0.0885  s1.acc: 96.0938  s1.loss_bbox: 0.1196  s1.loss_mask: 0.1220  s2.loss_cls: 0.0427  s2.acc: 95.8008  s2.loss_bbox: 0.0466  s2.loss_mask: 0.0574
2024/02/17 00:10:48 - mmengine - INFO - Epoch(train) [36][4550/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:31:53  time: 0.6791  data_time: 0.0247  memory: 9303  loss: 1.0542  loss_rpn_cls: 0.0318  loss_rpn_bbox: 0.0269  s0.loss_cls: 0.1524  s0.acc: 89.6484  s0.loss_bbox: 0.2150  s0.loss_mask: 0.2257  s1.loss_cls: 0.0670  s1.acc: 91.9081  s1.loss_bbox: 0.0982  s1.loss_mask: 0.1104  s2.loss_cls: 0.0342  s2.acc: 88.6228  s2.loss_bbox: 0.0403  s2.loss_mask: 0.0523
2024/02/17 00:11:23 - mmengine - INFO - Epoch(train) [36][4600/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:31:19  time: 0.6977  data_time: 0.0307  memory: 9431  loss: 1.2072  loss_rpn_cls: 0.0505  loss_rpn_bbox: 0.0340  s0.loss_cls: 0.1852  s0.acc: 89.2578  s0.loss_bbox: 0.2572  s0.loss_mask: 0.2357  s1.loss_cls: 0.0814  s1.acc: 92.0782  s1.loss_bbox: 0.1145  s1.loss_mask: 0.1135  s2.loss_cls: 0.0381  s2.acc: 91.0973  s2.loss_bbox: 0.0447  s2.loss_mask: 0.0522
2024/02/17 00:11:58 - mmengine - INFO - Epoch(train) [36][4650/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:30:45  time: 0.6907  data_time: 0.0278  memory: 9930  loss: 1.1305  loss_rpn_cls: 0.0390  loss_rpn_bbox: 0.0299  s0.loss_cls: 0.1771  s0.acc: 88.3789  s0.loss_bbox: 0.2305  s0.loss_mask: 0.2297  s1.loss_cls: 0.0792  s1.acc: 89.9414  s1.loss_bbox: 0.1032  s1.loss_mask: 0.1125  s2.loss_cls: 0.0381  s2.acc: 90.8203  s2.loss_bbox: 0.0389  s2.loss_mask: 0.0524
2024/02/17 00:12:32 - mmengine - INFO - Epoch(train) [36][4700/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:30:10  time: 0.6796  data_time: 0.0248  memory: 9081  loss: 1.1151  loss_rpn_cls: 0.0469  loss_rpn_bbox: 0.0315  s0.loss_cls: 0.1791  s0.acc: 96.0938  s0.loss_bbox: 0.2221  s0.loss_mask: 0.2201  s1.loss_cls: 0.0792  s1.acc: 95.6905  s1.loss_bbox: 0.1009  s1.loss_mask: 0.1076  s2.loss_cls: 0.0369  s2.acc: 95.9922  s2.loss_bbox: 0.0404  s2.loss_mask: 0.0506
2024/02/17 00:13:06 - mmengine - INFO - Epoch(train) [36][4750/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:29:36  time: 0.6893  data_time: 0.0263  memory: 10621  loss: 1.2277  loss_rpn_cls: 0.0413  loss_rpn_bbox: 0.0295  s0.loss_cls: 0.1890  s0.acc: 95.8008  s0.loss_bbox: 0.2548  s0.loss_mask: 0.2554  s1.loss_cls: 0.0851  s1.acc: 96.6797  s1.loss_bbox: 0.1126  s1.loss_mask: 0.1221  s2.loss_cls: 0.0394  s2.acc: 97.8516  s2.loss_bbox: 0.0436  s2.loss_mask: 0.0548
2024/02/17 00:13:40 - mmengine - INFO - Epoch(train) [36][4800/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:29:01  time: 0.6798  data_time: 0.0229  memory: 9142  loss: 1.0974  loss_rpn_cls: 0.0399  loss_rpn_bbox: 0.0248  s0.loss_cls: 0.1606  s0.acc: 93.7500  s0.loss_bbox: 0.2203  s0.loss_mask: 0.2459  s1.loss_cls: 0.0683  s1.acc: 96.0922  s1.loss_bbox: 0.0979  s1.loss_mask: 0.1155  s2.loss_cls: 0.0312  s2.acc: 96.8750  s2.loss_bbox: 0.0395  s2.loss_mask: 0.0536
2024/02/17 00:14:15 - mmengine - INFO - Epoch(train) [36][4850/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:28:27  time: 0.6846  data_time: 0.0240  memory: 9642  loss: 1.1505  loss_rpn_cls: 0.0425  loss_rpn_bbox: 0.0269  s0.loss_cls: 0.1755  s0.acc: 93.6523  s0.loss_bbox: 0.2323  s0.loss_mask: 0.2399  s1.loss_cls: 0.0762  s1.acc: 93.6523  s1.loss_bbox: 0.1048  s1.loss_mask: 0.1186  s2.loss_cls: 0.0365  s2.acc: 95.0195  s2.loss_bbox: 0.0426  s2.loss_mask: 0.0546
2024/02/17 00:14:49 - mmengine - INFO - Epoch(train) [36][4900/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:27:52  time: 0.6802  data_time: 0.0270  memory: 9785  loss: 1.1256  loss_rpn_cls: 0.0320  loss_rpn_bbox: 0.0243  s0.loss_cls: 0.1663  s0.acc: 96.6797  s0.loss_bbox: 0.2267  s0.loss_mask: 0.2488  s1.loss_cls: 0.0729  s1.acc: 96.8750  s1.loss_bbox: 0.1041  s1.loss_mask: 0.1195  s2.loss_cls: 0.0339  s2.acc: 96.7773  s2.loss_bbox: 0.0421  s2.loss_mask: 0.0551
2024/02/17 00:15:23 - mmengine - INFO - Epoch(train) [36][4950/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:27:18  time: 0.6839  data_time: 0.0309  memory: 9985  loss: 1.1429  loss_rpn_cls: 0.0425  loss_rpn_bbox: 0.0262  s0.loss_cls: 0.1799  s0.acc: 99.0234  s0.loss_bbox: 0.2308  s0.loss_mask: 0.2322  s1.loss_cls: 0.0802  s1.acc: 98.8281  s1.loss_bbox: 0.1042  s1.loss_mask: 0.1135  s2.loss_cls: 0.0372  s2.acc: 98.5352  s2.loss_bbox: 0.0421  s2.loss_mask: 0.0540
2024/02/17 00:15:57 - mmengine - INFO - Epoch(train) [36][5000/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:26:43  time: 0.6904  data_time: 0.0253  memory: 9441  loss: 1.2716  loss_rpn_cls: 0.0518  loss_rpn_bbox: 0.0340  s0.loss_cls: 0.2035  s0.acc: 95.8984  s0.loss_bbox: 0.2793  s0.loss_mask: 0.2379  s1.loss_cls: 0.0882  s1.acc: 94.5312  s1.loss_bbox: 0.1222  s1.loss_mask: 0.1133  s2.loss_cls: 0.0423  s2.acc: 94.3359  s2.loss_bbox: 0.0463  s2.loss_mask: 0.0528
2024/02/17 00:16:32 - mmengine - INFO - Epoch(train) [36][5050/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:26:09  time: 0.6930  data_time: 0.0239  memory: 9962  loss: 1.1282  loss_rpn_cls: 0.0413  loss_rpn_bbox: 0.0273  s0.loss_cls: 0.1755  s0.acc: 92.3828  s0.loss_bbox: 0.2260  s0.loss_mask: 0.2369  s1.loss_cls: 0.0792  s1.acc: 93.6523  s1.loss_bbox: 0.0998  s1.loss_mask: 0.1129  s2.loss_cls: 0.0361  s2.acc: 95.6055  s2.loss_bbox: 0.0404  s2.loss_mask: 0.0527
2024/02/17 00:17:07 - mmengine - INFO - Epoch(train) [36][5100/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:25:35  time: 0.6955  data_time: 0.0268  memory: 9317  loss: 1.1531  loss_rpn_cls: 0.0347  loss_rpn_bbox: 0.0287  s0.loss_cls: 0.1685  s0.acc: 92.0898  s0.loss_bbox: 0.2386  s0.loss_mask: 0.2520  s1.loss_cls: 0.0751  s1.acc: 92.8793  s1.loss_bbox: 0.1056  s1.loss_mask: 0.1202  s2.loss_cls: 0.0345  s2.acc: 93.0890  s2.loss_bbox: 0.0411  s2.loss_mask: 0.0540
2024/02/17 00:17:42 - mmengine - INFO - Epoch(train) [36][5150/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:25:00  time: 0.6931  data_time: 0.0284  memory: 9767  loss: 1.2326  loss_rpn_cls: 0.0455  loss_rpn_bbox: 0.0294  s0.loss_cls: 0.1871  s0.acc: 90.6250  s0.loss_bbox: 0.2686  s0.loss_mask: 0.2420  s1.loss_cls: 0.0836  s1.acc: 91.9922  s1.loss_bbox: 0.1179  s1.loss_mask: 0.1162  s2.loss_cls: 0.0394  s2.acc: 93.2617  s2.loss_bbox: 0.0480  s2.loss_mask: 0.0549
2024/02/17 00:18:16 - mmengine - INFO - Epoch(train) [36][5200/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:24:26  time: 0.6872  data_time: 0.0291  memory: 9682  loss: 1.2258  loss_rpn_cls: 0.0493  loss_rpn_bbox: 0.0356  s0.loss_cls: 0.2014  s0.acc: 83.4961  s0.loss_bbox: 0.2511  s0.loss_mask: 0.2342  s1.loss_cls: 0.0891  s1.acc: 83.8867  s1.loss_bbox: 0.1125  s1.loss_mask: 0.1125  s2.loss_cls: 0.0417  s2.acc: 85.8398  s2.loss_bbox: 0.0453  s2.loss_mask: 0.0529
2024/02/17 00:18:50 - mmengine - INFO - Epoch(train) [36][5250/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:23:51  time: 0.6821  data_time: 0.0303  memory: 9616  loss: 1.1999  loss_rpn_cls: 0.0363  loss_rpn_bbox: 0.0322  s0.loss_cls: 0.1848  s0.acc: 89.8438  s0.loss_bbox: 0.2578  s0.loss_mask: 0.2384  s1.loss_cls: 0.0817  s1.acc: 88.4956  s1.loss_bbox: 0.1132  s1.loss_mask: 0.1176  s2.loss_cls: 0.0394  s2.acc: 90.1367  s2.loss_bbox: 0.0445  s2.loss_mask: 0.0539
2024/02/17 00:19:24 - mmengine - INFO - Epoch(train) [36][5300/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:23:17  time: 0.6851  data_time: 0.0277  memory: 9402  loss: 1.1926  loss_rpn_cls: 0.0447  loss_rpn_bbox: 0.0313  s0.loss_cls: 0.1935  s0.acc: 88.9648  s0.loss_bbox: 0.2420  s0.loss_mask: 0.2361  s1.loss_cls: 0.0888  s1.acc: 89.4094  s1.loss_bbox: 0.1072  s1.loss_mask: 0.1139  s2.loss_cls: 0.0408  s2.acc: 87.4872  s2.loss_bbox: 0.0418  s2.loss_mask: 0.0525
2024/02/17 00:19:59 - mmengine - INFO - Epoch(train) [36][5350/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:22:43  time: 0.6910  data_time: 0.0286  memory: 10589  loss: 1.2551  loss_rpn_cls: 0.0449  loss_rpn_bbox: 0.0290  s0.loss_cls: 0.2005  s0.acc: 98.2422  s0.loss_bbox: 0.2662  s0.loss_mask: 0.2379  s1.loss_cls: 0.0893  s1.acc: 98.7305  s1.loss_bbox: 0.1222  s1.loss_mask: 0.1197  s2.loss_cls: 0.0428  s2.acc: 98.6328  s2.loss_bbox: 0.0476  s2.loss_mask: 0.0548
2024/02/17 00:20:33 - mmengine - INFO - Epoch(train) [36][5400/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:22:08  time: 0.6815  data_time: 0.0286  memory: 10090  loss: 1.3915  loss_rpn_cls: 0.0662  loss_rpn_bbox: 0.0355  s0.loss_cls: 0.2351  s0.acc: 95.8008  s0.loss_bbox: 0.2810  s0.loss_mask: 0.2712  s1.loss_cls: 0.1066  s1.acc: 97.2656  s1.loss_bbox: 0.1180  s1.loss_mask: 0.1265  s2.loss_cls: 0.0483  s2.acc: 96.3867  s2.loss_bbox: 0.0447  s2.loss_mask: 0.0587
2024/02/17 00:21:07 - mmengine - INFO - Exp name: cascade_mask_rcnn_swin_tiny_patch4_window7_mstrain_480-800_giou_4conv1f_adamw_3x_coco_20240216_214910
2024/02/17 00:21:07 - mmengine - INFO - Epoch(train) [36][5450/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:21:34  time: 0.6728  data_time: 0.0248  memory: 9520  loss: 1.1080  loss_rpn_cls: 0.0340  loss_rpn_bbox: 0.0282  s0.loss_cls: 0.1715  s0.acc: 91.9922  s0.loss_bbox: 0.2247  s0.loss_mask: 0.2291  s1.loss_cls: 0.0740  s1.acc: 93.9394  s1.loss_bbox: 0.1036  s1.loss_mask: 0.1123  s2.loss_cls: 0.0361  s2.acc: 93.3594  s2.loss_bbox: 0.0418  s2.loss_mask: 0.0525
2024/02/17 00:21:41 - mmengine - INFO - Epoch(train) [36][5500/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:20:59  time: 0.6827  data_time: 0.0277  memory: 9579  loss: 1.1319  loss_rpn_cls: 0.0381  loss_rpn_bbox: 0.0264  s0.loss_cls: 0.1747  s0.acc: 93.8477  s0.loss_bbox: 0.2319  s0.loss_mask: 0.2355  s1.loss_cls: 0.0764  s1.acc: 95.9406  s1.loss_bbox: 0.1053  s1.loss_mask: 0.1142  s2.loss_cls: 0.0351  s2.acc: 96.4179  s2.loss_bbox: 0.0420  s2.loss_mask: 0.0523
2024/02/17 00:22:15 - mmengine - INFO - Epoch(train) [36][5550/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:20:25  time: 0.6864  data_time: 0.0307  memory: 9355  loss: 1.2949  loss_rpn_cls: 0.0453  loss_rpn_bbox: 0.0333  s0.loss_cls: 0.2046  s0.acc: 93.5547  s0.loss_bbox: 0.2824  s0.loss_mask: 0.2527  s1.loss_cls: 0.0890  s1.acc: 92.0898  s1.loss_bbox: 0.1217  s1.loss_mask: 0.1210  s2.loss_cls: 0.0427  s2.acc: 94.1406  s2.loss_bbox: 0.0465  s2.loss_mask: 0.0558
2024/02/17 00:22:50 - mmengine - INFO - Epoch(train) [36][5600/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:19:50  time: 0.6920  data_time: 0.0277  memory: 9776  loss: 1.1234  loss_rpn_cls: 0.0360  loss_rpn_bbox: 0.0255  s0.loss_cls: 0.1668  s0.acc: 91.1133  s0.loss_bbox: 0.2382  s0.loss_mask: 0.2308  s1.loss_cls: 0.0757  s1.acc: 91.3690  s1.loss_bbox: 0.1076  s1.loss_mask: 0.1121  s2.loss_cls: 0.0360  s2.acc: 91.6914  s2.loss_bbox: 0.0424  s2.loss_mask: 0.0523
2024/02/17 00:23:25 - mmengine - INFO - Epoch(train) [36][5650/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:19:16  time: 0.6909  data_time: 0.0252  memory: 8848  loss: 1.1902  loss_rpn_cls: 0.0408  loss_rpn_bbox: 0.0295  s0.loss_cls: 0.2020  s0.acc: 87.1094  s0.loss_bbox: 0.2440  s0.loss_mask: 0.2304  s1.loss_cls: 0.0887  s1.acc: 87.8882  s1.loss_bbox: 0.1076  s1.loss_mask: 0.1115  s2.loss_cls: 0.0414  s2.acc: 90.1247  s2.loss_bbox: 0.0427  s2.loss_mask: 0.0517
2024/02/17 00:23:59 - mmengine - INFO - Epoch(train) [36][5700/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:18:41  time: 0.6855  data_time: 0.0259  memory: 9587  loss: 1.2314  loss_rpn_cls: 0.0519  loss_rpn_bbox: 0.0324  s0.loss_cls: 0.1961  s0.acc: 88.5742  s0.loss_bbox: 0.2446  s0.loss_mask: 0.2520  s1.loss_cls: 0.0863  s1.acc: 91.6412  s1.loss_bbox: 0.1083  s1.loss_mask: 0.1215  s2.loss_cls: 0.0397  s2.acc: 91.9372  s2.loss_bbox: 0.0424  s2.loss_mask: 0.0563
2024/02/17 00:24:33 - mmengine - INFO - Epoch(train) [36][5750/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:18:07  time: 0.6866  data_time: 0.0287  memory: 10135  loss: 1.2552  loss_rpn_cls: 0.0396  loss_rpn_bbox: 0.0282  s0.loss_cls: 0.1984  s0.acc: 98.6328  s0.loss_bbox: 0.2664  s0.loss_mask: 0.2510  s1.loss_cls: 0.0872  s1.acc: 99.1211  s1.loss_bbox: 0.1171  s1.loss_mask: 0.1232  s2.loss_cls: 0.0422  s2.acc: 99.5117  s2.loss_bbox: 0.0447  s2.loss_mask: 0.0572
2024/02/17 00:25:07 - mmengine - INFO - Epoch(train) [36][5800/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:17:33  time: 0.6832  data_time: 0.0262  memory: 9203  loss: 1.2463  loss_rpn_cls: 0.0455  loss_rpn_bbox: 0.0323  s0.loss_cls: 0.2022  s0.acc: 94.1406  s0.loss_bbox: 0.2617  s0.loss_mask: 0.2456  s1.loss_cls: 0.0881  s1.acc: 95.7341  s1.loss_bbox: 0.1157  s1.loss_mask: 0.1151  s2.loss_cls: 0.0407  s2.acc: 94.8617  s2.loss_bbox: 0.0461  s2.loss_mask: 0.0533
2024/02/17 00:25:42 - mmengine - INFO - Epoch(train) [36][5850/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:16:58  time: 0.6948  data_time: 0.0268  memory: 10100  loss: 1.1000  loss_rpn_cls: 0.0365  loss_rpn_bbox: 0.0245  s0.loss_cls: 0.1680  s0.acc: 95.1172  s0.loss_bbox: 0.2253  s0.loss_mask: 0.2291  s1.loss_cls: 0.0730  s1.acc: 94.9219  s1.loss_bbox: 0.1033  s1.loss_mask: 0.1125  s2.loss_cls: 0.0343  s2.acc: 95.4102  s2.loss_bbox: 0.0408  s2.loss_mask: 0.0527
2024/02/17 00:26:17 - mmengine - INFO - Epoch(train) [36][5900/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:16:24  time: 0.6958  data_time: 0.0278  memory: 9219  loss: 1.2603  loss_rpn_cls: 0.0474  loss_rpn_bbox: 0.0334  s0.loss_cls: 0.2039  s0.acc: 92.0898  s0.loss_bbox: 0.2609  s0.loss_mask: 0.2424  s1.loss_cls: 0.0920  s1.acc: 90.6409  s1.loss_bbox: 0.1164  s1.loss_mask: 0.1194  s2.loss_cls: 0.0442  s2.acc: 93.7183  s2.loss_bbox: 0.0448  s2.loss_mask: 0.0556
2024/02/17 00:26:51 - mmengine - INFO - Epoch(train) [36][5950/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:15:49  time: 0.6865  data_time: 0.0268  memory: 9468  loss: 1.1889  loss_rpn_cls: 0.0472  loss_rpn_bbox: 0.0337  s0.loss_cls: 0.1873  s0.acc: 98.8281  s0.loss_bbox: 0.2431  s0.loss_mask: 0.2429  s1.loss_cls: 0.0809  s1.acc: 99.4141  s1.loss_bbox: 0.1057  s1.loss_mask: 0.1151  s2.loss_cls: 0.0379  s2.acc: 99.4141  s2.loss_bbox: 0.0412  s2.loss_mask: 0.0540
2024/02/17 00:27:25 - mmengine - INFO - Epoch(train) [36][6000/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:15:15  time: 0.6808  data_time: 0.0275  memory: 9319  loss: 1.2111  loss_rpn_cls: 0.0386  loss_rpn_bbox: 0.0298  s0.loss_cls: 0.1867  s0.acc: 97.1680  s0.loss_bbox: 0.2570  s0.loss_mask: 0.2485  s1.loss_cls: 0.0824  s1.acc: 96.5820  s1.loss_bbox: 0.1127  s1.loss_mask: 0.1195  s2.loss_cls: 0.0374  s2.acc: 96.8750  s2.loss_bbox: 0.0441  s2.loss_mask: 0.0544
2024/02/17 00:28:00 - mmengine - INFO - Epoch(train) [36][6050/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:14:41  time: 0.6936  data_time: 0.0240  memory: 9748  loss: 1.1744  loss_rpn_cls: 0.0380  loss_rpn_bbox: 0.0281  s0.loss_cls: 0.1777  s0.acc: 97.5586  s0.loss_bbox: 0.2418  s0.loss_mask: 0.2465  s1.loss_cls: 0.0780  s1.acc: 98.4520  s1.loss_bbox: 0.1103  s1.loss_mask: 0.1187  s2.loss_cls: 0.0366  s2.acc: 99.0596  s2.loss_bbox: 0.0436  s2.loss_mask: 0.0551
2024/02/17 00:28:35 - mmengine - INFO - Epoch(train) [36][6100/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:14:06  time: 0.6957  data_time: 0.0293  memory: 9928  loss: 1.1868  loss_rpn_cls: 0.0399  loss_rpn_bbox: 0.0315  s0.loss_cls: 0.1848  s0.acc: 96.2891  s0.loss_bbox: 0.2553  s0.loss_mask: 0.2377  s1.loss_cls: 0.0785  s1.acc: 97.9492  s1.loss_bbox: 0.1100  s1.loss_mask: 0.1144  s2.loss_cls: 0.0378  s2.acc: 98.8281  s2.loss_bbox: 0.0431  s2.loss_mask: 0.0537
2024/02/17 00:29:10 - mmengine - INFO - Epoch(train) [36][6150/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:13:32  time: 0.6914  data_time: 0.0264  memory: 9234  loss: 1.1772  loss_rpn_cls: 0.0473  loss_rpn_bbox: 0.0273  s0.loss_cls: 0.1870  s0.acc: 93.0664  s0.loss_bbox: 0.2460  s0.loss_mask: 0.2291  s1.loss_cls: 0.0839  s1.acc: 94.3787  s1.loss_bbox: 0.1107  s1.loss_mask: 0.1116  s2.loss_cls: 0.0388  s2.acc: 96.8473  s2.loss_bbox: 0.0433  s2.loss_mask: 0.0523
2024/02/17 00:29:44 - mmengine - INFO - Epoch(train) [36][6200/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:12:57  time: 0.6856  data_time: 0.0255  memory: 9587  loss: 1.1413  loss_rpn_cls: 0.0382  loss_rpn_bbox: 0.0289  s0.loss_cls: 0.1856  s0.acc: 94.7266  s0.loss_bbox: 0.2233  s0.loss_mask: 0.2413  s1.loss_cls: 0.0803  s1.acc: 96.7774  s1.loss_bbox: 0.0991  s1.loss_mask: 0.1141  s2.loss_cls: 0.0377  s2.acc: 96.1771  s2.loss_bbox: 0.0389  s2.loss_mask: 0.0539
2024/02/17 00:30:19 - mmengine - INFO - Epoch(train) [36][6250/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:12:23  time: 0.6950  data_time: 0.0237  memory: 9713  loss: 1.1930  loss_rpn_cls: 0.0433  loss_rpn_bbox: 0.0265  s0.loss_cls: 0.1870  s0.acc: 95.2148  s0.loss_bbox: 0.2542  s0.loss_mask: 0.2411  s1.loss_cls: 0.0829  s1.acc: 95.9961  s1.loss_bbox: 0.1118  s1.loss_mask: 0.1116  s2.loss_cls: 0.0390  s2.acc: 97.1680  s2.loss_bbox: 0.0445  s2.loss_mask: 0.0511
2024/02/17 00:30:53 - mmengine - INFO - Epoch(train) [36][6300/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:11:48  time: 0.6846  data_time: 0.0246  memory: 8957  loss: 1.1367  loss_rpn_cls: 0.0395  loss_rpn_bbox: 0.0246  s0.loss_cls: 0.1800  s0.acc: 98.8281  s0.loss_bbox: 0.2332  s0.loss_mask: 0.2323  s1.loss_cls: 0.0779  s1.acc: 99.3164  s1.loss_bbox: 0.1055  s1.loss_mask: 0.1128  s2.loss_cls: 0.0371  s2.acc: 98.4375  s2.loss_bbox: 0.0415  s2.loss_mask: 0.0521
2024/02/17 00:31:27 - mmengine - INFO - Epoch(train) [36][6350/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:11:14  time: 0.6890  data_time: 0.0308  memory: 9508  loss: 1.3001  loss_rpn_cls: 0.0523  loss_rpn_bbox: 0.0350  s0.loss_cls: 0.1931  s0.acc: 94.3359  s0.loss_bbox: 0.2822  s0.loss_mask: 0.2589  s1.loss_cls: 0.0833  s1.acc: 95.1244  s1.loss_bbox: 0.1265  s1.loss_mask: 0.1226  s2.loss_cls: 0.0401  s2.acc: 96.3928  s2.loss_bbox: 0.0493  s2.loss_mask: 0.0567
2024/02/17 00:32:02 - mmengine - INFO - Epoch(train) [36][6400/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:10:40  time: 0.6879  data_time: 0.0269  memory: 9504  loss: 1.1313  loss_rpn_cls: 0.0370  loss_rpn_bbox: 0.0239  s0.loss_cls: 0.1769  s0.acc: 91.5039  s0.loss_bbox: 0.2248  s0.loss_mask: 0.2342  s1.loss_cls: 0.0803  s1.acc: 91.9483  s1.loss_bbox: 0.1032  s1.loss_mask: 0.1156  s2.loss_cls: 0.0383  s2.acc: 92.1627  s2.loss_bbox: 0.0420  s2.loss_mask: 0.0550
2024/02/17 00:32:36 - mmengine - INFO - Exp name: cascade_mask_rcnn_swin_tiny_patch4_window7_mstrain_480-800_giou_4conv1f_adamw_3x_coco_20240216_214910
2024/02/17 00:32:36 - mmengine - INFO - Epoch(train) [36][6450/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:10:05  time: 0.6824  data_time: 0.0274  memory: 9511  loss: 1.2204  loss_rpn_cls: 0.0417  loss_rpn_bbox: 0.0334  s0.loss_cls: 0.1889  s0.acc: 93.3594  s0.loss_bbox: 0.2664  s0.loss_mask: 0.2401  s1.loss_cls: 0.0828  s1.acc: 95.3299  s1.loss_bbox: 0.1172  s1.loss_mask: 0.1139  s2.loss_cls: 0.0398  s2.acc: 94.2973  s2.loss_bbox: 0.0442  s2.loss_mask: 0.0521
2024/02/17 00:33:10 - mmengine - INFO - Epoch(train) [36][6500/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:09:31  time: 0.6877  data_time: 0.0265  memory: 11297  loss: 1.2377  loss_rpn_cls: 0.0456  loss_rpn_bbox: 0.0333  s0.loss_cls: 0.2006  s0.acc: 96.9727  s0.loss_bbox: 0.2542  s0.loss_mask: 0.2446  s1.loss_cls: 0.0892  s1.acc: 97.3633  s1.loss_bbox: 0.1114  s1.loss_mask: 0.1184  s2.loss_cls: 0.0424  s2.acc: 97.2656  s2.loss_bbox: 0.0435  s2.loss_mask: 0.0544
2024/02/17 00:33:44 - mmengine - INFO - Epoch(train) [36][6550/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:08:56  time: 0.6762  data_time: 0.0262  memory: 9085  loss: 1.0309  loss_rpn_cls: 0.0353  loss_rpn_bbox: 0.0255  s0.loss_cls: 0.1465  s0.acc: 98.2422  s0.loss_bbox: 0.2084  s0.loss_mask: 0.2282  s1.loss_cls: 0.0647  s1.acc: 98.1445  s1.loss_bbox: 0.0925  s1.loss_mask: 0.1111  s2.loss_cls: 0.0301  s2.acc: 98.3398  s2.loss_bbox: 0.0368  s2.loss_mask: 0.0517
2024/02/17 00:34:19 - mmengine - INFO - Epoch(train) [36][6600/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:08:22  time: 0.6917  data_time: 0.0263  memory: 9621  loss: 1.2070  loss_rpn_cls: 0.0497  loss_rpn_bbox: 0.0283  s0.loss_cls: 0.1891  s0.acc: 95.3125  s0.loss_bbox: 0.2568  s0.loss_mask: 0.2432  s1.loss_cls: 0.0791  s1.acc: 95.3125  s1.loss_bbox: 0.1138  s1.loss_mask: 0.1132  s2.loss_cls: 0.0373  s2.acc: 96.1914  s2.loss_bbox: 0.0445  s2.loss_mask: 0.0519
2024/02/17 00:34:53 - mmengine - INFO - Epoch(train) [36][6650/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:07:48  time: 0.6816  data_time: 0.0241  memory: 9735  loss: 1.1095  loss_rpn_cls: 0.0313  loss_rpn_bbox: 0.0214  s0.loss_cls: 0.1656  s0.acc: 94.0430  s0.loss_bbox: 0.2342  s0.loss_mask: 0.2296  s1.loss_cls: 0.0740  s1.acc: 95.6055  s1.loss_bbox: 0.1091  s1.loss_mask: 0.1135  s2.loss_cls: 0.0346  s2.acc: 98.0469  s2.loss_bbox: 0.0436  s2.loss_mask: 0.0526
2024/02/17 00:35:27 - mmengine - INFO - Epoch(train) [36][6700/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:07:13  time: 0.6829  data_time: 0.0255  memory: 10930  loss: 1.1563  loss_rpn_cls: 0.0378  loss_rpn_bbox: 0.0240  s0.loss_cls: 0.1927  s0.acc: 86.9141  s0.loss_bbox: 0.2381  s0.loss_mask: 0.2262  s1.loss_cls: 0.0869  s1.acc: 89.2927  s1.loss_bbox: 0.1074  s1.loss_mask: 0.1101  s2.loss_cls: 0.0390  s2.acc: 92.2397  s2.loss_bbox: 0.0423  s2.loss_mask: 0.0517
2024/02/17 00:36:02 - mmengine - INFO - Epoch(train) [36][6750/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:06:39  time: 0.7005  data_time: 0.0267  memory: 9720  loss: 1.2724  loss_rpn_cls: 0.0507  loss_rpn_bbox: 0.0305  s0.loss_cls: 0.2077  s0.acc: 95.3125  s0.loss_bbox: 0.2569  s0.loss_mask: 0.2570  s1.loss_cls: 0.0916  s1.acc: 95.9058  s1.loss_bbox: 0.1108  s1.loss_mask: 0.1245  s2.loss_cls: 0.0421  s2.acc: 97.4174  s2.loss_bbox: 0.0425  s2.loss_mask: 0.0582
2024/02/17 00:36:37 - mmengine - INFO - Epoch(train) [36][6800/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:06:04  time: 0.6869  data_time: 0.0268  memory: 9308  loss: 1.1897  loss_rpn_cls: 0.0413  loss_rpn_bbox: 0.0275  s0.loss_cls: 0.1761  s0.acc: 98.2422  s0.loss_bbox: 0.2412  s0.loss_mask: 0.2574  s1.loss_cls: 0.0792  s1.acc: 98.2422  s1.loss_bbox: 0.1063  s1.loss_mask: 0.1261  s2.loss_cls: 0.0369  s2.acc: 99.0234  s2.loss_bbox: 0.0412  s2.loss_mask: 0.0566
2024/02/17 00:37:11 - mmengine - INFO - Epoch(train) [36][6850/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:05:30  time: 0.6954  data_time: 0.0280  memory: 9699  loss: 1.1602  loss_rpn_cls: 0.0379  loss_rpn_bbox: 0.0280  s0.loss_cls: 0.1761  s0.acc: 95.8984  s0.loss_bbox: 0.2347  s0.loss_mask: 0.2435  s1.loss_cls: 0.0778  s1.acc: 96.4036  s1.loss_bbox: 0.1068  s1.loss_mask: 0.1195  s2.loss_cls: 0.0361  s2.acc: 95.6132  s2.loss_bbox: 0.0436  s2.loss_mask: 0.0561
2024/02/17 00:37:46 - mmengine - INFO - Epoch(train) [36][6900/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:04:55  time: 0.6887  data_time: 0.0256  memory: 9723  loss: 1.0956  loss_rpn_cls: 0.0357  loss_rpn_bbox: 0.0253  s0.loss_cls: 0.1705  s0.acc: 95.2148  s0.loss_bbox: 0.2192  s0.loss_mask: 0.2297  s1.loss_cls: 0.0744  s1.acc: 96.1538  s1.loss_bbox: 0.0989  s1.loss_mask: 0.1147  s2.loss_cls: 0.0356  s2.acc: 96.6270  s2.loss_bbox: 0.0386  s2.loss_mask: 0.0530
2024/02/17 00:38:20 - mmengine - INFO - Epoch(train) [36][6950/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:04:21  time: 0.6888  data_time: 0.0249  memory: 9670  loss: 1.1712  loss_rpn_cls: 0.0443  loss_rpn_bbox: 0.0338  s0.loss_cls: 0.1905  s0.acc: 95.0195  s0.loss_bbox: 0.2380  s0.loss_mask: 0.2326  s1.loss_cls: 0.0828  s1.acc: 95.8008  s1.loss_bbox: 0.1046  s1.loss_mask: 0.1120  s2.loss_cls: 0.0379  s2.acc: 96.6797  s2.loss_bbox: 0.0421  s2.loss_mask: 0.0525
2024/02/17 00:38:55 - mmengine - INFO - Epoch(train) [36][7000/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:03:47  time: 0.6867  data_time: 0.0287  memory: 9684  loss: 1.2799  loss_rpn_cls: 0.0395  loss_rpn_bbox: 0.0337  s0.loss_cls: 0.2007  s0.acc: 89.4531  s0.loss_bbox: 0.2831  s0.loss_mask: 0.2416  s1.loss_cls: 0.0897  s1.acc: 91.3741  s1.loss_bbox: 0.1283  s1.loss_mask: 0.1178  s2.loss_cls: 0.0415  s2.acc: 89.7898  s2.loss_bbox: 0.0496  s2.loss_mask: 0.0545
2024/02/17 00:39:29 - mmengine - INFO - Epoch(train) [36][7050/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:03:12  time: 0.6775  data_time: 0.0244  memory: 9629  loss: 1.1321  loss_rpn_cls: 0.0410  loss_rpn_bbox: 0.0324  s0.loss_cls: 0.1724  s0.acc: 96.7773  s0.loss_bbox: 0.2253  s0.loss_mask: 0.2356  s1.loss_cls: 0.0757  s1.acc: 96.2891  s1.loss_bbox: 0.1034  s1.loss_mask: 0.1159  s2.loss_cls: 0.0353  s2.acc: 92.8711  s2.loss_bbox: 0.0412  s2.loss_mask: 0.0539
2024/02/17 00:40:03 - mmengine - INFO - Epoch(train) [36][7100/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:02:38  time: 0.6908  data_time: 0.0234  memory: 10673  loss: 1.0592  loss_rpn_cls: 0.0364  loss_rpn_bbox: 0.0269  s0.loss_cls: 0.1603  s0.acc: 87.0117  s0.loss_bbox: 0.2137  s0.loss_mask: 0.2218  s1.loss_cls: 0.0707  s1.acc: 87.7654  s1.loss_bbox: 0.0987  s1.loss_mask: 0.1075  s2.loss_cls: 0.0327  s2.acc: 87.6008  s2.loss_bbox: 0.0402  s2.loss_mask: 0.0502
2024/02/17 00:40:37 - mmengine - INFO - Epoch(train) [36][7150/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:02:03  time: 0.6775  data_time: 0.0269  memory: 9633  loss: 1.2361  loss_rpn_cls: 0.0437  loss_rpn_bbox: 0.0317  s0.loss_cls: 0.1966  s0.acc: 96.5820  s0.loss_bbox: 0.2639  s0.loss_mask: 0.2444  s1.loss_cls: 0.0846  s1.acc: 98.1910  s1.loss_bbox: 0.1153  s1.loss_mask: 0.1177  s2.loss_cls: 0.0397  s2.acc: 97.9613  s2.loss_bbox: 0.0437  s2.loss_mask: 0.0549
2024/02/17 00:41:11 - mmengine - INFO - Epoch(train) [36][7200/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:01:29  time: 0.6870  data_time: 0.0267  memory: 9142  loss: 1.2027  loss_rpn_cls: 0.0397  loss_rpn_bbox: 0.0300  s0.loss_cls: 0.1934  s0.acc: 86.4258  s0.loss_bbox: 0.2432  s0.loss_mask: 0.2490  s1.loss_cls: 0.0868  s1.acc: 88.2812  s1.loss_bbox: 0.1032  s1.loss_mask: 0.1217  s2.loss_cls: 0.0390  s2.acc: 86.6211  s2.loss_bbox: 0.0396  s2.loss_mask: 0.0571
2024/02/17 00:41:46 - mmengine - INFO - Epoch(train) [36][7250/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:00:55  time: 0.6929  data_time: 0.0260  memory: 9382  loss: 1.0625  loss_rpn_cls: 0.0394  loss_rpn_bbox: 0.0259  s0.loss_cls: 0.1574  s0.acc: 97.8516  s0.loss_bbox: 0.2076  s0.loss_mask: 0.2328  s1.loss_cls: 0.0691  s1.acc: 98.3398  s1.loss_bbox: 0.0952  s1.loss_mask: 0.1122  s2.loss_cls: 0.0317  s2.acc: 98.0469  s2.loss_bbox: 0.0385  s2.loss_mask: 0.0526
2024/02/17 00:42:20 - mmengine - INFO - Epoch(train) [36][7300/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:00:20  time: 0.6830  data_time: 0.0262  memory: 9712  loss: 1.1766  loss_rpn_cls: 0.0402  loss_rpn_bbox: 0.0275  s0.loss_cls: 0.1881  s0.acc: 93.0664  s0.loss_bbox: 0.2489  s0.loss_mask: 0.2382  s1.loss_cls: 0.0817  s1.acc: 94.4106  s1.loss_bbox: 0.1065  s1.loss_mask: 0.1135  s2.loss_cls: 0.0372  s2.acc: 94.4502  s2.loss_bbox: 0.0428  s2.loss_mask: 0.0520
2024/02/17 00:42:41 - mmengine - INFO - Exp name: cascade_mask_rcnn_swin_tiny_patch4_window7_mstrain_480-800_giou_4conv1f_adamw_3x_coco_20240216_214910
2024/02/17 00:42:41 - mmengine - INFO - Saving checkpoint at 36 epochs
2024/02/17 00:42:56 - mmengine - INFO - Epoch(val) [36][ 50/625]    eta: 0:01:52  time: 0.1963  data_time: 0.0229  memory: 10282  
2024/02/17 00:43:06 - mmengine - INFO - Epoch(val) [36][100/625]    eta: 0:01:44  time: 0.2025  data_time: 0.0292  memory: 2665  
2024/02/17 00:43:16 - mmengine - INFO - Epoch(val) [36][150/625]    eta: 0:01:34  time: 0.1977  data_time: 0.0249  memory: 2661  
2024/02/17 00:43:25 - mmengine - INFO - Epoch(val) [36][200/625]    eta: 0:01:24  time: 0.1947  data_time: 0.0217  memory: 2661  
2024/02/17 00:43:35 - mmengine - INFO - Epoch(val) [36][250/625]    eta: 0:01:14  time: 0.2015  data_time: 0.0267  memory: 2665  
2024/02/17 00:43:45 - mmengine - INFO - Epoch(val) [36][300/625]    eta: 0:01:04  time: 0.1963  data_time: 0.0235  memory: 2661  
2024/02/17 00:43:55 - mmengine - INFO - Epoch(val) [36][350/625]    eta: 0:00:54  time: 0.2008  data_time: 0.0257  memory: 2662  
2024/02/17 00:44:05 - mmengine - INFO - Epoch(val) [36][400/625]    eta: 0:00:44  time: 0.1994  data_time: 0.0252  memory: 2665  
2024/02/17 00:44:15 - mmengine - INFO - Epoch(val) [36][450/625]    eta: 0:00:34  time: 0.1977  data_time: 0.0230  memory: 2665  
2024/02/17 00:44:25 - mmengine - INFO - Epoch(val) [36][500/625]    eta: 0:00:24  time: 0.2010  data_time: 0.0272  memory: 2662  
2024/02/17 00:44:36 - mmengine - INFO - Epoch(val) [36][550/625]    eta: 0:00:14  time: 0.2070  data_time: 0.0288  memory: 2665  
2024/02/17 00:44:46 - mmengine - INFO - Epoch(val) [36][600/625]    eta: 0:00:04  time: 0.2001  data_time: 0.0240  memory: 2661  
2024/02/17 00:45:03 - mmengine - INFO - Evaluating bbox...
2024/02/17 00:45:53 - mmengine - INFO - bbox_mAP_copypaste: 0.438 0.622 0.478 0.291 0.465 0.573
2024/02/17 00:45:53 - mmengine - INFO - Evaluating segm...
2024/02/17 00:46:48 - mmengine - INFO - segm_mAP_copypaste: 0.383 0.595 0.412 0.209 0.407 0.560
2024/02/17 00:46:49 - mmengine - INFO - Epoch(val) [36][625/625]    coco/bbox_mAP: 0.4380  coco/bbox_mAP_50: 0.6220  coco/bbox_mAP_75: 0.4780  coco/bbox_mAP_s: 0.2910  coco/bbox_mAP_m: 0.4650  coco/bbox_mAP_l: 0.5730  coco/segm_mAP: 0.3830  coco/segm_mAP_50: 0.5950  coco/segm_mAP_75: 0.4120  coco/segm_mAP_s: 0.2090  coco/segm_mAP_m: 0.4070  coco/segm_mAP_l: 0.5600  data_time: 0.0250  time: 0.1992
