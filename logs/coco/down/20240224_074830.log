2024/02/24 07:48:37 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.10.13 (main, Sep 11 2023, 13:44:35) [GCC 11.2.0]
    CUDA available: True
    MUSA available: False
    numpy_random_seed: 1368010620
    GPU 0,1,2,3,4,5,6,7: Tesla V100-SXM2-16GB
    CUDA_HOME: None
    GCC: n/a
    PyTorch: 1.11.0+cu113
    PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.12.0+cu113
    OpenCV: 4.9.0
    MMEngine: 0.10.3

Runtime environment:
    cudnn_benchmark: False
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 1368010620
    Distributed launcher: pytorch
    Distributed training: True
    GPU number: 8
------------------------------------------------------------

2024/02/24 07:48:39 - mmengine - INFO - Config:
auto_scale_lr = dict(base_batch_size=16, enable=False)
backend_args = None
data_root = 'data/coco/'
dataset_type = 'CocoDataset'
default_hooks = dict(
    checkpoint=dict(interval=1, type='CheckpointHook'),
    logger=dict(interval=50, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'),
    visualization=dict(type='DetVisualizationHook'))
default_scope = 'mmdet'
env_cfg = dict(
    cudnn_benchmark=False,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
launcher = 'pytorch'
load_from = '/results/epoch_34.pth'
log_level = 'INFO'
log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)
max_epochs = 36
model = dict(
    backbone=dict(
        attn_drop_rate=0.0,
        convert_weights=False,
        depths=[
            2,
            2,
            6,
            2,
        ],
        drop_path_rate=0.2,
        drop_rate=0.0,
        embed_dims=96,
        init_cfg=None,
        mlp_ratio=4,
        num_heads=[
            3,
            6,
            12,
            24,
        ],
        out_indices=(
            0,
            1,
            2,
            3,
        ),
        patch_norm=True,
        qk_scale=None,
        qkv_bias=True,
        schemes=(
            'down',
            'down',
            'down',
            'down',
        ),
        type='SwinTransformerMultipleSchemes',
        window_size=(
            7,
            7,
            7,
            7,
        ),
        with_cp=False),
    data_preprocessor=dict(
        bgr_to_rgb=True,
        mean=[
            123.675,
            116.28,
            103.53,
        ],
        pad_mask=True,
        pad_size_divisor=32,
        std=[
            58.395,
            57.12,
            57.375,
        ],
        type='DetDataPreprocessor'),
    neck=dict(
        in_channels=[
            96,
            192,
            384,
            768,
        ],
        num_outs=5,
        out_channels=256,
        type='FPN'),
    roi_head=dict(
        bbox_head=[
            dict(
                bbox_coder=dict(
                    target_means=[
                        0.0,
                        0.0,
                        0.0,
                        0.0,
                    ],
                    target_stds=[
                        0.1,
                        0.1,
                        0.2,
                        0.2,
                    ],
                    type='DeltaXYWHBBoxCoder'),
                conv_out_channels=256,
                fc_out_channels=1024,
                in_channels=256,
                loss_bbox=dict(loss_weight=10.0, type='GIoULoss'),
                loss_cls=dict(
                    loss_weight=1.0,
                    type='CrossEntropyLoss',
                    use_sigmoid=False),
                norm_cfg=dict(requires_grad=True, type='SyncBN'),
                num_classes=80,
                num_shared_convs=4,
                num_shared_fcs=1,
                reg_class_agnostic=False,
                reg_decoded_bbox=True,
                roi_feat_size=7,
                type='ConvFCBBoxHead'),
            dict(
                bbox_coder=dict(
                    target_means=[
                        0.0,
                        0.0,
                        0.0,
                        0.0,
                    ],
                    target_stds=[
                        0.05,
                        0.05,
                        0.1,
                        0.1,
                    ],
                    type='DeltaXYWHBBoxCoder'),
                conv_out_channels=256,
                fc_out_channels=1024,
                in_channels=256,
                loss_bbox=dict(loss_weight=10.0, type='GIoULoss'),
                loss_cls=dict(
                    loss_weight=1.0,
                    type='CrossEntropyLoss',
                    use_sigmoid=False),
                norm_cfg=dict(requires_grad=True, type='SyncBN'),
                num_classes=80,
                num_shared_convs=4,
                num_shared_fcs=1,
                reg_class_agnostic=False,
                reg_decoded_bbox=True,
                roi_feat_size=7,
                type='ConvFCBBoxHead'),
            dict(
                bbox_coder=dict(
                    target_means=[
                        0.0,
                        0.0,
                        0.0,
                        0.0,
                    ],
                    target_stds=[
                        0.033,
                        0.033,
                        0.067,
                        0.067,
                    ],
                    type='DeltaXYWHBBoxCoder'),
                conv_out_channels=256,
                fc_out_channels=1024,
                in_channels=256,
                loss_bbox=dict(loss_weight=10.0, type='GIoULoss'),
                loss_cls=dict(
                    loss_weight=1.0,
                    type='CrossEntropyLoss',
                    use_sigmoid=False),
                norm_cfg=dict(requires_grad=True, type='SyncBN'),
                num_classes=80,
                num_shared_convs=4,
                num_shared_fcs=1,
                reg_class_agnostic=False,
                reg_decoded_bbox=True,
                roi_feat_size=7,
                type='ConvFCBBoxHead'),
        ],
        bbox_roi_extractor=dict(
            featmap_strides=[
                4,
                8,
                16,
                32,
            ],
            out_channels=256,
            roi_layer=dict(output_size=7, sampling_ratio=0, type='RoIAlign'),
            type='SingleRoIExtractor'),
        mask_head=dict(
            conv_out_channels=256,
            in_channels=256,
            loss_mask=dict(
                loss_weight=1.0, type='CrossEntropyLoss', use_mask=True),
            num_classes=80,
            num_convs=4,
            type='FCNMaskHead'),
        mask_roi_extractor=dict(
            featmap_strides=[
                4,
                8,
                16,
                32,
            ],
            out_channels=256,
            roi_layer=dict(output_size=14, sampling_ratio=0, type='RoIAlign'),
            type='SingleRoIExtractor'),
        num_stages=3,
        stage_loss_weights=[
            1,
            0.5,
            0.25,
        ],
        type='CascadeRoIHead'),
    rpn_head=dict(
        anchor_generator=dict(
            ratios=[
                0.5,
                1.0,
                2.0,
            ],
            scales=[
                8,
            ],
            strides=[
                4,
                8,
                16,
                32,
                64,
            ],
            type='AnchorGenerator'),
        bbox_coder=dict(
            target_means=[
                0.0,
                0.0,
                0.0,
                0.0,
            ],
            target_stds=[
                1.0,
                1.0,
                1.0,
                1.0,
            ],
            type='DeltaXYWHBBoxCoder'),
        feat_channels=256,
        in_channels=256,
        loss_bbox=dict(
            beta=0.1111111111111111, loss_weight=1.0, type='SmoothL1Loss'),
        loss_cls=dict(
            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=True),
        type='RPNHead'),
    test_cfg=dict(
        rcnn=dict(
            mask_thr_binary=0.5,
            max_per_img=100,
            nms=dict(iou_threshold=0.5, type='nms'),
            score_thr=0.05),
        rpn=dict(
            max_per_img=1000,
            min_bbox_size=0,
            nms=dict(iou_threshold=0.7, type='nms'),
            nms_pre=1000)),
    train_cfg=dict(
        rcnn=[
            dict(
                assigner=dict(
                    ignore_iof_thr=-1,
                    match_low_quality=False,
                    min_pos_iou=0.5,
                    neg_iou_thr=0.5,
                    pos_iou_thr=0.5,
                    type='MaxIoUAssigner'),
                debug=False,
                mask_size=28,
                pos_weight=-1,
                sampler=dict(
                    add_gt_as_proposals=True,
                    neg_pos_ub=-1,
                    num=512,
                    pos_fraction=0.25,
                    type='RandomSampler')),
            dict(
                assigner=dict(
                    ignore_iof_thr=-1,
                    match_low_quality=False,
                    min_pos_iou=0.6,
                    neg_iou_thr=0.6,
                    pos_iou_thr=0.6,
                    type='MaxIoUAssigner'),
                debug=False,
                mask_size=28,
                pos_weight=-1,
                sampler=dict(
                    add_gt_as_proposals=True,
                    neg_pos_ub=-1,
                    num=512,
                    pos_fraction=0.25,
                    type='RandomSampler')),
            dict(
                assigner=dict(
                    ignore_iof_thr=-1,
                    match_low_quality=False,
                    min_pos_iou=0.7,
                    neg_iou_thr=0.7,
                    pos_iou_thr=0.7,
                    type='MaxIoUAssigner'),
                debug=False,
                mask_size=28,
                pos_weight=-1,
                sampler=dict(
                    add_gt_as_proposals=True,
                    neg_pos_ub=-1,
                    num=512,
                    pos_fraction=0.25,
                    type='RandomSampler')),
        ],
        rpn=dict(
            allowed_border=0,
            assigner=dict(
                ignore_iof_thr=-1,
                match_low_quality=True,
                min_pos_iou=0.3,
                neg_iou_thr=0.3,
                pos_iou_thr=0.7,
                type='MaxIoUAssigner'),
            debug=False,
            pos_weight=-1,
            sampler=dict(
                add_gt_as_proposals=False,
                neg_pos_ub=-1,
                num=256,
                pos_fraction=0.5,
                type='RandomSampler')),
        rpn_proposal=dict(
            max_per_img=2000,
            min_bbox_size=0,
            nms=dict(iou_threshold=0.7, type='nms'),
            nms_pre=2000)),
    type='CascadeRCNN')
optim_wrapper = dict(
    optimizer=dict(
        betas=(
            0.9,
            0.999,
        ), lr=0.0001, type='AdamW', weight_decay=0.05),
    paramwise_cfg=dict(
        custom_keys=dict(
            absolute_pos_embed=dict(decay_mult=0.0),
            norm=dict(decay_mult=0.0),
            relative_position_bias_table=dict(decay_mult=0.0))),
    type='OptimWrapper')
param_scheduler = [
    dict(
        begin=0, by_epoch=False, end=1000, start_factor=0.001,
        type='LinearLR'),
    dict(
        begin=0,
        by_epoch=True,
        end=36,
        gamma=0.1,
        milestones=[
            27,
            33,
        ],
        type='MultiStepLR'),
]
randomness = dict(seed=1368010620)
resume = True
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=1,
    dataset=dict(
        ann_file='annotations/instances_val2017.json',
        backend_args=None,
        data_prefix=dict(img='val2017/'),
        data_root='data/coco/',
        pipeline=[
            dict(backend_args=None, type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                1333,
                800,
            ), type='Resize'),
            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),
            dict(
                meta_keys=(
                    'img_id',
                    'img_path',
                    'ori_shape',
                    'img_shape',
                    'scale_factor',
                ),
                type='PackDetInputs'),
        ],
        test_mode=True,
        type='CocoDataset'),
    drop_last=False,
    num_workers=2,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(
    ann_file='data/coco/annotations/instances_val2017.json',
    backend_args=None,
    format_only=False,
    metric=[
        'bbox',
        'segm',
    ],
    type='CocoMetric')
test_pipeline = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(keep_ratio=True, scale=(
        1333,
        800,
    ), type='Resize'),
    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),
    dict(
        meta_keys=(
            'img_id',
            'img_path',
            'ori_shape',
            'img_shape',
            'scale_factor',
        ),
        type='PackDetInputs'),
]
train_cfg = dict(max_epochs=36, type='EpochBasedTrainLoop', val_interval=1)
train_dataloader = dict(
    batch_sampler=dict(type='AspectRatioBatchSampler'),
    batch_size=2,
    dataset=dict(
        ann_file='annotations/instances_train2017.json',
        backend_args=None,
        data_prefix=dict(img='train2017/'),
        data_root='data/coco/',
        filter_cfg=dict(filter_empty_gt=True, min_size=32),
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),
            dict(prob=0.5, type='RandomFlip'),
            dict(
                policies=[
                    [
                        dict(
                            keep_ratio=True,
                            scales=[
                                (
                                    480,
                                    1333,
                                ),
                                (
                                    512,
                                    1333,
                                ),
                                (
                                    544,
                                    1333,
                                ),
                                (
                                    576,
                                    1333,
                                ),
                                (
                                    608,
                                    1333,
                                ),
                                (
                                    640,
                                    1333,
                                ),
                                (
                                    672,
                                    1333,
                                ),
                                (
                                    704,
                                    1333,
                                ),
                                (
                                    736,
                                    1333,
                                ),
                                (
                                    768,
                                    1333,
                                ),
                                (
                                    800,
                                    1333,
                                ),
                            ],
                            type='RandomChoiceResize'),
                    ],
                    [
                        dict(
                            keep_ratio=True,
                            scales=[
                                (
                                    400,
                                    1333,
                                ),
                                (
                                    500,
                                    1333,
                                ),
                                (
                                    600,
                                    1333,
                                ),
                            ],
                            type='RandomChoiceResize'),
                        dict(
                            allow_negative_crop=True,
                            crop_size=(
                                384,
                                600,
                            ),
                            crop_type='absolute_range',
                            type='RandomCrop'),
                        dict(
                            keep_ratio=True,
                            scales=[
                                (
                                    480,
                                    1333,
                                ),
                                (
                                    512,
                                    1333,
                                ),
                                (
                                    544,
                                    1333,
                                ),
                                (
                                    576,
                                    1333,
                                ),
                                (
                                    608,
                                    1333,
                                ),
                                (
                                    640,
                                    1333,
                                ),
                                (
                                    672,
                                    1333,
                                ),
                                (
                                    704,
                                    1333,
                                ),
                                (
                                    736,
                                    1333,
                                ),
                                (
                                    768,
                                    1333,
                                ),
                                (
                                    800,
                                    1333,
                                ),
                            ],
                            type='RandomChoiceResize'),
                    ],
                ],
                type='AutoAugment'),
            dict(type='PackDetInputs'),
        ],
        type='CocoDataset'),
    num_workers=2,
    persistent_workers=True,
    sampler=dict(shuffle=True, type='DefaultSampler'))
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),
    dict(prob=0.5, type='RandomFlip'),
    dict(
        policies=[
            [
                dict(
                    keep_ratio=True,
                    scales=[
                        (
                            480,
                            1333,
                        ),
                        (
                            512,
                            1333,
                        ),
                        (
                            544,
                            1333,
                        ),
                        (
                            576,
                            1333,
                        ),
                        (
                            608,
                            1333,
                        ),
                        (
                            640,
                            1333,
                        ),
                        (
                            672,
                            1333,
                        ),
                        (
                            704,
                            1333,
                        ),
                        (
                            736,
                            1333,
                        ),
                        (
                            768,
                            1333,
                        ),
                        (
                            800,
                            1333,
                        ),
                    ],
                    type='RandomChoiceResize'),
            ],
            [
                dict(
                    keep_ratio=True,
                    scales=[
                        (
                            400,
                            1333,
                        ),
                        (
                            500,
                            1333,
                        ),
                        (
                            600,
                            1333,
                        ),
                    ],
                    type='RandomChoiceResize'),
                dict(
                    allow_negative_crop=True,
                    crop_size=(
                        384,
                        600,
                    ),
                    crop_type='absolute_range',
                    type='RandomCrop'),
                dict(
                    keep_ratio=True,
                    scales=[
                        (
                            480,
                            1333,
                        ),
                        (
                            512,
                            1333,
                        ),
                        (
                            544,
                            1333,
                        ),
                        (
                            576,
                            1333,
                        ),
                        (
                            608,
                            1333,
                        ),
                        (
                            640,
                            1333,
                        ),
                        (
                            672,
                            1333,
                        ),
                        (
                            704,
                            1333,
                        ),
                        (
                            736,
                            1333,
                        ),
                        (
                            768,
                            1333,
                        ),
                        (
                            800,
                            1333,
                        ),
                    ],
                    type='RandomChoiceResize'),
            ],
        ],
        type='AutoAugment'),
    dict(type='PackDetInputs'),
]
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=1,
    dataset=dict(
        ann_file='annotations/instances_val2017.json',
        backend_args=None,
        data_prefix=dict(img='val2017/'),
        data_root='data/coco/',
        pipeline=[
            dict(backend_args=None, type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                1333,
                800,
            ), type='Resize'),
            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),
            dict(
                meta_keys=(
                    'img_id',
                    'img_path',
                    'ori_shape',
                    'img_shape',
                    'scale_factor',
                ),
                type='PackDetInputs'),
        ],
        test_mode=True,
        type='CocoDataset'),
    drop_last=False,
    num_workers=2,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(
    ann_file='data/coco/annotations/instances_val2017.json',
    backend_args=None,
    format_only=False,
    metric=[
        'bbox',
        'segm',
    ],
    type='CocoMetric')
vis_backends = [
    dict(type='LocalVisBackend'),
]
visualizer = dict(
    name='visualizer',
    type='DetLocalVisualizer',
    vis_backends=[
        dict(type='LocalVisBackend'),
    ])
work_dir = '/results'

2024/02/24 07:48:42 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DetVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DetVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.weight:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.weight:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.weight:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.bias:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.bias:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.bias:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.weight:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.weight:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.weight:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.bias:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.bias:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.bias:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.weight:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.weight:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.weight:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.bias:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.bias:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.bias:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.weight:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.weight:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.weight:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.bias:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.bias:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.bias:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.weight:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.weight:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.weight:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.bias:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.bias:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.bias:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.weight:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.weight:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.weight:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.bias:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.bias:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.bias:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.weight:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.weight:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.weight:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.bias:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.bias:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.bias:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.weight:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.weight:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.weight:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.bias:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.bias:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.bias:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.weight:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.weight:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.weight:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.bias:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.bias:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.bias:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.weight:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.weight:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.weight:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.bias:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.bias:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.bias:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.weight:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.weight:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.weight:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.bias:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.bias:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.bias:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.weight:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.weight:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.weight:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.bias:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.bias:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.bias:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.weight:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.weight:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.weight:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.bias:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.bias:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.bias:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.weight:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.weight:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.weight:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.bias:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.bias:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.bias:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.weight:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.weight:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.weight:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.bias:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.bias:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.bias:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.weight:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.weight:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.weight:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.bias:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.bias:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.bias:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.weight:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.weight:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.weight:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.bias:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.bias:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.bias:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.weight:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.weight:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.weight:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.bias:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.bias:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.bias:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.weight:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.weight:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.weight:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.bias:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.bias:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.bias:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.weight:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.weight:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.weight:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.bias:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.bias:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.bias:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.weight:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.weight:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.weight:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.bias:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.bias:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.bias:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.weight:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.weight:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.weight:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.bias:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.bias:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.bias:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.weight:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.weight:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.weight:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.bias:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.bias:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.bias:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.weight:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.weight:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.weight:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.bias:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.bias:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.bias:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:decay_mult=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:lr=0.0001
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:weight_decay=0.0
2024/02/24 07:49:22 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:decay_mult=0.0
2024/02/24 07:49:26 - mmengine - WARNING - No pre-trained weights for SwinTransformerMultipleSchemes, training start from scratch
Name of parameter - Initialization information

backbone.patch_embed.projection.weight - torch.Size([96, 3, 4, 4]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.patch_embed.projection.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.patch_embed.norm.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.patch_embed.norm.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.0.blocks.0.norm1.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.0.blocks.0.norm1.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([169, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.0.blocks.0.attn.w_msa.qkv.weight - torch.Size([288, 96]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.0.blocks.0.attn.w_msa.qkv.bias - torch.Size([288]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.0.blocks.0.attn.w_msa.proj.weight - torch.Size([96, 96]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.0.blocks.0.attn.w_msa.proj.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.0.blocks.0.norm2.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.0.blocks.0.norm2.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.0.blocks.0.ffn.layers.0.0.weight - torch.Size([384, 96]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.0.blocks.0.ffn.layers.0.0.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.0.blocks.0.ffn.layers.1.weight - torch.Size([96, 384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.0.blocks.0.ffn.layers.1.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.0.blocks.1.norm1.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.0.blocks.1.norm1.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([169, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.0.blocks.1.attn.w_msa.qkv.weight - torch.Size([288, 96]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.0.blocks.1.attn.w_msa.qkv.bias - torch.Size([288]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.0.blocks.1.attn.w_msa.proj.weight - torch.Size([96, 96]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.0.blocks.1.attn.w_msa.proj.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.0.blocks.1.norm2.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.0.blocks.1.norm2.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.0.blocks.1.ffn.layers.0.0.weight - torch.Size([384, 96]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.0.blocks.1.ffn.layers.0.0.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.0.blocks.1.ffn.layers.1.weight - torch.Size([96, 384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.0.blocks.1.ffn.layers.1.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.0.downsample.norm.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.0.downsample.norm.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.0.downsample.reduction.weight - torch.Size([192, 384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.1.blocks.0.norm1.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.1.blocks.0.norm1.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([169, 6]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.1.blocks.0.attn.w_msa.qkv.weight - torch.Size([576, 192]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.1.blocks.0.attn.w_msa.qkv.bias - torch.Size([576]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.1.blocks.0.attn.w_msa.proj.weight - torch.Size([192, 192]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.1.blocks.0.attn.w_msa.proj.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.1.blocks.0.norm2.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.1.blocks.0.norm2.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.1.blocks.0.ffn.layers.0.0.weight - torch.Size([768, 192]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.1.blocks.0.ffn.layers.0.0.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.1.blocks.0.ffn.layers.1.weight - torch.Size([192, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.1.blocks.0.ffn.layers.1.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.1.blocks.1.norm1.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.1.blocks.1.norm1.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([169, 6]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.1.blocks.1.attn.w_msa.qkv.weight - torch.Size([576, 192]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.1.blocks.1.attn.w_msa.qkv.bias - torch.Size([576]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.1.blocks.1.attn.w_msa.proj.weight - torch.Size([192, 192]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.1.blocks.1.attn.w_msa.proj.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.1.blocks.1.norm2.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.1.blocks.1.norm2.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.1.blocks.1.ffn.layers.0.0.weight - torch.Size([768, 192]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.1.blocks.1.ffn.layers.0.0.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.1.blocks.1.ffn.layers.1.weight - torch.Size([192, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.1.blocks.1.ffn.layers.1.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.1.downsample.norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.1.downsample.norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.1.downsample.reduction.weight - torch.Size([384, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.0.norm1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.blocks.0.norm1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.blocks.0.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.0.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.0.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.0.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.0.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.blocks.0.norm2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.blocks.0.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.0.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.0.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.0.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.1.norm1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.blocks.1.norm1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.blocks.1.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.1.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.1.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.1.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.1.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.blocks.1.norm2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.blocks.1.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.1.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.1.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.1.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.2.norm1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.blocks.2.norm1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.blocks.2.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.2.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.2.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.2.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.2.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.blocks.2.norm2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.blocks.2.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.2.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.2.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.2.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.3.norm1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.blocks.3.norm1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.blocks.3.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.3.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.3.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.3.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.3.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.blocks.3.norm2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.blocks.3.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.3.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.3.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.3.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.4.norm1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.blocks.4.norm1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.blocks.4.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.4.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.4.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.4.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.4.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.blocks.4.norm2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.blocks.4.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.4.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.4.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.4.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.5.norm1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.blocks.5.norm1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.blocks.5.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.5.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.5.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.5.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.5.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.blocks.5.norm2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.blocks.5.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.5.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.5.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.blocks.5.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.2.downsample.norm.weight - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.downsample.norm.bias - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.2.downsample.reduction.weight - torch.Size([768, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.3.blocks.0.norm1.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.3.blocks.0.norm1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([169, 24]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.3.blocks.0.attn.w_msa.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.3.blocks.0.attn.w_msa.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.3.blocks.0.attn.w_msa.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.3.blocks.0.attn.w_msa.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.3.blocks.0.norm2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.3.blocks.0.norm2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.3.blocks.0.ffn.layers.0.0.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.3.blocks.0.ffn.layers.0.0.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.3.blocks.0.ffn.layers.1.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.3.blocks.0.ffn.layers.1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.3.blocks.1.norm1.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.3.blocks.1.norm1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([169, 24]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.3.blocks.1.attn.w_msa.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.3.blocks.1.attn.w_msa.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.3.blocks.1.attn.w_msa.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.3.blocks.1.attn.w_msa.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.3.blocks.1.norm2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.3.blocks.1.norm2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.stages.3.blocks.1.ffn.layers.0.0.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.3.blocks.1.ffn.layers.0.0.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.3.blocks.1.ffn.layers.1.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.stages.3.blocks.1.ffn.layers.1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformerMultipleSchemes  

backbone.norm0.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.norm0.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.norm1.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.norm1.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.norm2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.norm3.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.norm3.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.lateral_convs.0.conv.weight - torch.Size([256, 96, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.lateral_convs.1.conv.weight - torch.Size([256, 192, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.lateral_convs.2.conv.weight - torch.Size([256, 384, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.lateral_convs.3.conv.weight - torch.Size([256, 768, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

rpn_head.rpn_conv.weight - torch.Size([256, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_conv.bias - torch.Size([256]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_cls.weight - torch.Size([3, 256, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_cls.bias - torch.Size([3]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_reg.weight - torch.Size([12, 256, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_reg.bias - torch.Size([12]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.0.fc_cls.weight - torch.Size([81, 1024]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.0.fc_cls.bias - torch.Size([81]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.0.fc_reg.weight - torch.Size([320, 1024]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.0.fc_reg.bias - torch.Size([320]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.0.shared_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.0.shared_convs.0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.0.shared_convs.0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.0.shared_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.0.shared_convs.1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.0.shared_convs.1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.0.shared_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.0.shared_convs.2.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.0.shared_convs.2.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.0.shared_convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.0.shared_convs.3.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.0.shared_convs.3.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.0.shared_fcs.0.weight - torch.Size([1024, 12544]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.0.shared_fcs.0.bias - torch.Size([1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.1.fc_cls.weight - torch.Size([81, 1024]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.1.fc_cls.bias - torch.Size([81]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.1.fc_reg.weight - torch.Size([320, 1024]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.1.fc_reg.bias - torch.Size([320]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.1.shared_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.1.shared_convs.0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.1.shared_convs.0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.1.shared_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.1.shared_convs.1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.1.shared_convs.1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.1.shared_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.1.shared_convs.2.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.1.shared_convs.2.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.1.shared_convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.1.shared_convs.3.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.1.shared_convs.3.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.1.shared_fcs.0.weight - torch.Size([1024, 12544]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.1.shared_fcs.0.bias - torch.Size([1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.2.fc_cls.weight - torch.Size([81, 1024]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.2.fc_cls.bias - torch.Size([81]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.2.fc_reg.weight - torch.Size([320, 1024]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.2.fc_reg.bias - torch.Size([320]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.2.shared_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.2.shared_convs.0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.2.shared_convs.0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.2.shared_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.2.shared_convs.1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.2.shared_convs.1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.2.shared_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.2.shared_convs.2.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.2.shared_convs.2.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.2.shared_convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.2.shared_convs.3.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.2.shared_convs.3.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.bbox_head.2.shared_fcs.0.weight - torch.Size([1024, 12544]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.2.shared_fcs.0.bias - torch.Size([1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.mask_head.0.convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.upsample.weight - torch.Size([256, 256, 2, 2]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.upsample.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.conv_logits.weight - torch.Size([80, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.0.conv_logits.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.upsample.weight - torch.Size([256, 256, 2, 2]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.upsample.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.conv_logits.weight - torch.Size([80, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.1.conv_logits.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.upsample.weight - torch.Size([256, 256, 2, 2]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.upsample.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.conv_logits.weight - torch.Size([80, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

roi_head.mask_head.2.conv_logits.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  
2024/02/24 07:49:29 - mmengine - INFO - Load checkpoint from /results/epoch_34.pth
2024/02/24 07:49:29 - mmengine - INFO - resumed epoch: 34, iter: 249220
2024/02/24 07:49:29 - mmengine - WARNING - "FileClient" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io
2024/02/24 07:49:29 - mmengine - WARNING - "HardDiskBackend" is the alias of "LocalBackend" and the former will be deprecated in future.
2024/02/24 07:49:29 - mmengine - INFO - Checkpoints will be saved to /results.
2024/02/24 07:50:05 - mmengine - INFO - Epoch(train) [35][  50/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:53:50  time: 0.7139  data_time: 0.0445  memory: 9589  loss: 1.1764  loss_rpn_cls: 0.0376  loss_rpn_bbox: 0.0307  s0.loss_cls: 0.1929  s0.acc: 93.8477  s0.loss_bbox: 0.2481  s0.loss_mask: 0.2252  s1.loss_cls: 0.0857  s1.acc: 94.8515  s1.loss_bbox: 0.1100  s1.loss_mask: 0.1101  s2.loss_cls: 0.0406  s2.acc: 96.3221  s2.loss_bbox: 0.0438  s2.loss_mask: 0.0517
2024/02/24 07:50:39 - mmengine - INFO - Epoch(train) [35][ 100/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:49:33  time: 0.6835  data_time: 0.0278  memory: 10740  loss: 1.0940  loss_rpn_cls: 0.0353  loss_rpn_bbox: 0.0260  s0.loss_cls: 0.1607  s0.acc: 93.1641  s0.loss_bbox: 0.2235  s0.loss_mask: 0.2349  s1.loss_cls: 0.0712  s1.acc: 95.6790  s1.loss_bbox: 0.1012  s1.loss_mask: 0.1135  s2.loss_cls: 0.0344  s2.acc: 96.2963  s2.loss_bbox: 0.0405  s2.loss_mask: 0.0528
2024/02/24 07:51:13 - mmengine - INFO - Epoch(train) [35][ 150/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:47:59  time: 0.6865  data_time: 0.0269  memory: 9369  loss: 1.1484  loss_rpn_cls: 0.0403  loss_rpn_bbox: 0.0272  s0.loss_cls: 0.1845  s0.acc: 83.8867  s0.loss_bbox: 0.2286  s0.loss_mask: 0.2374  s1.loss_cls: 0.0839  s1.acc: 82.9488  s1.loss_bbox: 0.1006  s1.loss_mask: 0.1124  s2.loss_cls: 0.0389  s2.acc: 79.7798  s2.loss_bbox: 0.0408  s2.loss_mask: 0.0539
2024/02/24 07:51:48 - mmengine - INFO - Epoch(train) [35][ 200/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:47:28  time: 0.6958  data_time: 0.0267  memory: 9439  loss: 1.1385  loss_rpn_cls: 0.0360  loss_rpn_bbox: 0.0238  s0.loss_cls: 0.1843  s0.acc: 98.7305  s0.loss_bbox: 0.2354  s0.loss_mask: 0.2325  s1.loss_cls: 0.0824  s1.acc: 98.2422  s1.loss_bbox: 0.1030  s1.loss_mask: 0.1119  s2.loss_cls: 0.0370  s2.acc: 97.4609  s2.loss_bbox: 0.0403  s2.loss_mask: 0.0520
2024/02/24 07:52:23 - mmengine - INFO - Epoch(train) [35][ 250/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:46:52  time: 0.6946  data_time: 0.0272  memory: 9535  loss: 1.1444  loss_rpn_cls: 0.0400  loss_rpn_bbox: 0.0281  s0.loss_cls: 0.1824  s0.acc: 92.4805  s0.loss_bbox: 0.2325  s0.loss_mask: 0.2356  s1.loss_cls: 0.0815  s1.acc: 90.8275  s1.loss_bbox: 0.1017  s1.loss_mask: 0.1133  s2.loss_cls: 0.0371  s2.acc: 91.4767  s2.loss_bbox: 0.0393  s2.loss_mask: 0.0529
2024/02/24 07:52:57 - mmengine - INFO - Epoch(train) [35][ 300/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:46:07  time: 0.6903  data_time: 0.0247  memory: 9114  loss: 1.0845  loss_rpn_cls: 0.0306  loss_rpn_bbox: 0.0233  s0.loss_cls: 0.1664  s0.acc: 94.2383  s0.loss_bbox: 0.2264  s0.loss_mask: 0.2274  s1.loss_cls: 0.0732  s1.acc: 95.6392  s1.loss_bbox: 0.0989  s1.loss_mask: 0.1111  s2.loss_cls: 0.0358  s2.acc: 94.7577  s2.loss_bbox: 0.0392  s2.loss_mask: 0.0524
2024/02/24 07:53:32 - mmengine - INFO - Epoch(train) [35][ 350/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:45:42  time: 0.6990  data_time: 0.0280  memory: 9200  loss: 1.1610  loss_rpn_cls: 0.0417  loss_rpn_bbox: 0.0260  s0.loss_cls: 0.1851  s0.acc: 98.5352  s0.loss_bbox: 0.2390  s0.loss_mask: 0.2235  s1.loss_cls: 0.0829  s1.acc: 99.6094  s1.loss_bbox: 0.1123  s1.loss_mask: 0.1116  s2.loss_cls: 0.0406  s2.acc: 99.7070  s2.loss_bbox: 0.0457  s2.loss_mask: 0.0526
2024/02/24 07:54:07 - mmengine - INFO - Epoch(train) [35][ 400/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:45:17  time: 0.7001  data_time: 0.0319  memory: 10227  loss: 1.2613  loss_rpn_cls: 0.0464  loss_rpn_bbox: 0.0331  s0.loss_cls: 0.2036  s0.acc: 93.5547  s0.loss_bbox: 0.2581  s0.loss_mask: 0.2480  s1.loss_cls: 0.0894  s1.acc: 94.2744  s1.loss_bbox: 0.1165  s1.loss_mask: 0.1221  s2.loss_cls: 0.0424  s2.acc: 94.6798  s2.loss_bbox: 0.0452  s2.loss_mask: 0.0565
2024/02/24 07:54:42 - mmengine - INFO - Epoch(train) [35][ 450/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:44:54  time: 0.7030  data_time: 0.0279  memory: 11425  loss: 1.1387  loss_rpn_cls: 0.0340  loss_rpn_bbox: 0.0229  s0.loss_cls: 0.1767  s0.acc: 95.0195  s0.loss_bbox: 0.2392  s0.loss_mask: 0.2334  s1.loss_cls: 0.0780  s1.acc: 97.3057  s1.loss_bbox: 0.1101  s1.loss_mask: 0.1131  s2.loss_cls: 0.0367  s2.acc: 97.7107  s2.loss_bbox: 0.0426  s2.loss_mask: 0.0520
2024/02/24 07:55:17 - mmengine - INFO - Epoch(train) [35][ 500/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:44:16  time: 0.6942  data_time: 0.0281  memory: 9396  loss: 1.1963  loss_rpn_cls: 0.0405  loss_rpn_bbox: 0.0270  s0.loss_cls: 0.1862  s0.acc: 92.7734  s0.loss_bbox: 0.2503  s0.loss_mask: 0.2470  s1.loss_cls: 0.0807  s1.acc: 94.6375  s1.loss_bbox: 0.1098  s1.loss_mask: 0.1178  s2.loss_cls: 0.0383  s2.acc: 92.1627  s2.loss_bbox: 0.0436  s2.loss_mask: 0.0549
2024/02/24 07:55:52 - mmengine - INFO - Epoch(train) [35][ 550/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:43:32  time: 0.6887  data_time: 0.0286  memory: 9337  loss: 1.1367  loss_rpn_cls: 0.0338  loss_rpn_bbox: 0.0256  s0.loss_cls: 0.1792  s0.acc: 97.8516  s0.loss_bbox: 0.2483  s0.loss_mask: 0.2219  s1.loss_cls: 0.0805  s1.acc: 98.8281  s1.loss_bbox: 0.1091  s1.loss_mask: 0.1072  s2.loss_cls: 0.0376  s2.acc: 97.2656  s2.loss_bbox: 0.0432  s2.loss_mask: 0.0503
2024/02/24 07:56:26 - mmengine - INFO - Epoch(train) [35][ 600/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:42:56  time: 0.6950  data_time: 0.0254  memory: 9569  loss: 1.1043  loss_rpn_cls: 0.0357  loss_rpn_bbox: 0.0251  s0.loss_cls: 0.1669  s0.acc: 93.7500  s0.loss_bbox: 0.2271  s0.loss_mask: 0.2266  s1.loss_cls: 0.0770  s1.acc: 94.3898  s1.loss_bbox: 0.1057  s1.loss_mask: 0.1114  s2.loss_cls: 0.0351  s2.acc: 95.2381  s2.loss_bbox: 0.0421  s2.loss_mask: 0.0517
2024/02/24 07:57:01 - mmengine - INFO - Epoch(train) [35][ 650/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:42:19  time: 0.6924  data_time: 0.0246  memory: 9712  loss: 1.1632  loss_rpn_cls: 0.0352  loss_rpn_bbox: 0.0296  s0.loss_cls: 0.1865  s0.acc: 96.9727  s0.loss_bbox: 0.2318  s0.loss_mask: 0.2366  s1.loss_cls: 0.0829  s1.acc: 97.2656  s1.loss_bbox: 0.1080  s1.loss_mask: 0.1167  s2.loss_cls: 0.0390  s2.acc: 97.2656  s2.loss_bbox: 0.0431  s2.loss_mask: 0.0538
2024/02/24 07:57:36 - mmengine - INFO - Epoch(train) [35][ 700/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:41:46  time: 0.6976  data_time: 0.0289  memory: 11106  loss: 1.1663  loss_rpn_cls: 0.0388  loss_rpn_bbox: 0.0265  s0.loss_cls: 0.1898  s0.acc: 93.8477  s0.loss_bbox: 0.2438  s0.loss_mask: 0.2358  s1.loss_cls: 0.0785  s1.acc: 95.1042  s1.loss_bbox: 0.1058  s1.loss_mask: 0.1142  s2.loss_cls: 0.0366  s2.acc: 93.0380  s2.loss_bbox: 0.0426  s2.loss_mask: 0.0537
2024/02/24 07:58:10 - mmengine - INFO - Epoch(train) [35][ 750/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:41:05  time: 0.6885  data_time: 0.0279  memory: 9721  loss: 1.2231  loss_rpn_cls: 0.0358  loss_rpn_bbox: 0.0288  s0.loss_cls: 0.1850  s0.acc: 94.8242  s0.loss_bbox: 0.2504  s0.loss_mask: 0.2528  s1.loss_cls: 0.0837  s1.acc: 96.1000  s1.loss_bbox: 0.1160  s1.loss_mask: 0.1252  s2.loss_cls: 0.0409  s2.acc: 94.2173  s2.loss_bbox: 0.0458  s2.loss_mask: 0.0587
2024/02/24 07:58:31 - mmengine - INFO - Exp name: cascade_mask_rcnn_swin_tiny_patch4_window7_mstrain_480-800_giou_4conv1f_adamw_3x_coco_20240224_074830
2024/02/24 07:58:44 - mmengine - INFO - Epoch(train) [35][ 800/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:40:13  time: 0.6748  data_time: 0.0270  memory: 9207  loss: 1.1573  loss_rpn_cls: 0.0371  loss_rpn_bbox: 0.0234  s0.loss_cls: 0.1771  s0.acc: 98.0469  s0.loss_bbox: 0.2364  s0.loss_mask: 0.2430  s1.loss_cls: 0.0805  s1.acc: 98.7305  s1.loss_bbox: 0.1062  s1.loss_mask: 0.1189  s2.loss_cls: 0.0372  s2.acc: 97.9492  s2.loss_bbox: 0.0412  s2.loss_mask: 0.0564
2024/02/24 07:59:18 - mmengine - INFO - Epoch(train) [35][ 850/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:39:29  time: 0.6822  data_time: 0.0267  memory: 10090  loss: 1.1475  loss_rpn_cls: 0.0374  loss_rpn_bbox: 0.0296  s0.loss_cls: 0.1837  s0.acc: 88.6719  s0.loss_bbox: 0.2446  s0.loss_mask: 0.2274  s1.loss_cls: 0.0788  s1.acc: 90.8905  s1.loss_bbox: 0.1060  s1.loss_mask: 0.1112  s2.loss_cls: 0.0367  s2.acc: 90.5447  s2.loss_bbox: 0.0413  s2.loss_mask: 0.0507
2024/02/24 07:59:53 - mmengine - INFO - Epoch(train) [35][ 900/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:38:50  time: 0.6876  data_time: 0.0241  memory: 9395  loss: 0.9633  loss_rpn_cls: 0.0253  loss_rpn_bbox: 0.0200  s0.loss_cls: 0.1376  s0.acc: 95.8984  s0.loss_bbox: 0.1969  s0.loss_mask: 0.2146  s1.loss_cls: 0.0597  s1.acc: 96.0938  s1.loss_bbox: 0.0898  s1.loss_mask: 0.1044  s2.loss_cls: 0.0287  s2.acc: 95.7031  s2.loss_bbox: 0.0368  s2.loss_mask: 0.0495
2024/02/24 08:00:27 - mmengine - INFO - Epoch(train) [35][ 950/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:38:15  time: 0.6917  data_time: 0.0298  memory: 9758  loss: 1.2881  loss_rpn_cls: 0.0416  loss_rpn_bbox: 0.0299  s0.loss_cls: 0.2108  s0.acc: 94.3359  s0.loss_bbox: 0.2781  s0.loss_mask: 0.2442  s1.loss_cls: 0.0908  s1.acc: 96.3867  s1.loss_bbox: 0.1230  s1.loss_mask: 0.1205  s2.loss_cls: 0.0431  s2.acc: 97.2656  s2.loss_bbox: 0.0489  s2.loss_mask: 0.0573
2024/02/24 08:01:02 - mmengine - INFO - Epoch(train) [35][1000/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:37:41  time: 0.6932  data_time: 0.0266  memory: 9496  loss: 1.1820  loss_rpn_cls: 0.0377  loss_rpn_bbox: 0.0266  s0.loss_cls: 0.1799  s0.acc: 97.4609  s0.loss_bbox: 0.2437  s0.loss_mask: 0.2463  s1.loss_cls: 0.0820  s1.acc: 98.1445  s1.loss_bbox: 0.1084  s1.loss_mask: 0.1200  s2.loss_cls: 0.0391  s2.acc: 98.8281  s2.loss_bbox: 0.0430  s2.loss_mask: 0.0552
2024/02/24 08:01:37 - mmengine - INFO - Epoch(train) [35][1050/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:37:03  time: 0.6886  data_time: 0.0230  memory: 10270  loss: 1.0718  loss_rpn_cls: 0.0351  loss_rpn_bbox: 0.0269  s0.loss_cls: 0.1608  s0.acc: 87.3047  s0.loss_bbox: 0.2107  s0.loss_mask: 0.2318  s1.loss_cls: 0.0685  s1.acc: 92.6955  s1.loss_bbox: 0.0996  s1.loss_mask: 0.1141  s2.loss_cls: 0.0316  s2.acc: 94.2149  s2.loss_bbox: 0.0398  s2.loss_mask: 0.0529
2024/02/24 08:02:11 - mmengine - INFO - Epoch(train) [35][1100/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:36:30  time: 0.6945  data_time: 0.0268  memory: 9779  loss: 1.1206  loss_rpn_cls: 0.0397  loss_rpn_bbox: 0.0265  s0.loss_cls: 0.1627  s0.acc: 98.5352  s0.loss_bbox: 0.2264  s0.loss_mask: 0.2425  s1.loss_cls: 0.0724  s1.acc: 98.4375  s1.loss_bbox: 0.1032  s1.loss_mask: 0.1183  s2.loss_cls: 0.0337  s2.acc: 97.7539  s2.loss_bbox: 0.0405  s2.loss_mask: 0.0547
2024/02/24 08:02:46 - mmengine - INFO - Epoch(train) [35][1150/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:35:53  time: 0.6886  data_time: 0.0315  memory: 9995  loss: 1.2599  loss_rpn_cls: 0.0469  loss_rpn_bbox: 0.0308  s0.loss_cls: 0.1918  s0.acc: 91.9922  s0.loss_bbox: 0.2585  s0.loss_mask: 0.2590  s1.loss_cls: 0.0900  s1.acc: 92.4699  s1.loss_bbox: 0.1140  s1.loss_mask: 0.1248  s2.loss_cls: 0.0427  s2.acc: 93.4804  s2.loss_bbox: 0.0436  s2.loss_mask: 0.0579
2024/02/24 08:03:21 - mmengine - INFO - Epoch(train) [35][1200/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:35:22  time: 0.6992  data_time: 0.0287  memory: 9447  loss: 1.1114  loss_rpn_cls: 0.0381  loss_rpn_bbox: 0.0264  s0.loss_cls: 0.1848  s0.acc: 99.1211  s0.loss_bbox: 0.2272  s0.loss_mask: 0.2209  s1.loss_cls: 0.0825  s1.acc: 98.9258  s1.loss_bbox: 0.1007  s1.loss_mask: 0.1051  s2.loss_cls: 0.0372  s2.acc: 99.5117  s2.loss_bbox: 0.0403  s2.loss_mask: 0.0485
2024/02/24 08:03:56 - mmengine - INFO - Epoch(train) [35][1250/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:34:48  time: 0.6938  data_time: 0.0264  memory: 9651  loss: 1.2208  loss_rpn_cls: 0.0424  loss_rpn_bbox: 0.0267  s0.loss_cls: 0.2089  s0.acc: 94.7266  s0.loss_bbox: 0.2491  s0.loss_mask: 0.2362  s1.loss_cls: 0.0888  s1.acc: 95.7031  s1.loss_bbox: 0.1115  s1.loss_mask: 0.1155  s2.loss_cls: 0.0422  s2.acc: 96.2891  s2.loss_bbox: 0.0449  s2.loss_mask: 0.0545
2024/02/24 08:04:30 - mmengine - INFO - Epoch(train) [35][1300/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:34:12  time: 0.6884  data_time: 0.0274  memory: 9721  loss: 1.1433  loss_rpn_cls: 0.0316  loss_rpn_bbox: 0.0239  s0.loss_cls: 0.1752  s0.acc: 94.2383  s0.loss_bbox: 0.2445  s0.loss_mask: 0.2352  s1.loss_cls: 0.0730  s1.acc: 94.8242  s1.loss_bbox: 0.1116  s1.loss_mask: 0.1140  s2.loss_cls: 0.0357  s2.acc: 95.4102  s2.loss_bbox: 0.0449  s2.loss_mask: 0.0537
2024/02/24 08:05:05 - mmengine - INFO - Epoch(train) [35][1350/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:33:38  time: 0.6955  data_time: 0.0353  memory: 9911  loss: 1.2080  loss_rpn_cls: 0.0470  loss_rpn_bbox: 0.0323  s0.loss_cls: 0.1901  s0.acc: 96.7773  s0.loss_bbox: 0.2541  s0.loss_mask: 0.2369  s1.loss_cls: 0.0837  s1.acc: 97.0707  s1.loss_bbox: 0.1117  s1.loss_mask: 0.1137  s2.loss_cls: 0.0398  s2.acc: 96.4718  s2.loss_bbox: 0.0448  s2.loss_mask: 0.0540
2024/02/24 08:05:39 - mmengine - INFO - Epoch(train) [35][1400/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:33:04  time: 0.6936  data_time: 0.0280  memory: 9735  loss: 1.2221  loss_rpn_cls: 0.0464  loss_rpn_bbox: 0.0286  s0.loss_cls: 0.1920  s0.acc: 92.3828  s0.loss_bbox: 0.2575  s0.loss_mask: 0.2396  s1.loss_cls: 0.0849  s1.acc: 92.0276  s1.loss_bbox: 0.1170  s1.loss_mask: 0.1161  s2.loss_cls: 0.0396  s2.acc: 94.1986  s2.loss_bbox: 0.0461  s2.loss_mask: 0.0543
2024/02/24 08:06:14 - mmengine - INFO - Epoch(train) [35][1450/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:32:30  time: 0.6935  data_time: 0.0303  memory: 9465  loss: 1.1447  loss_rpn_cls: 0.0420  loss_rpn_bbox: 0.0312  s0.loss_cls: 0.1780  s0.acc: 98.4375  s0.loss_bbox: 0.2400  s0.loss_mask: 0.2199  s1.loss_cls: 0.0769  s1.acc: 99.1211  s1.loss_bbox: 0.1115  s1.loss_mask: 0.1098  s2.loss_cls: 0.0385  s2.acc: 97.8516  s2.loss_bbox: 0.0453  s2.loss_mask: 0.0515
2024/02/24 08:06:49 - mmengine - INFO - Epoch(train) [35][1500/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:31:55  time: 0.6913  data_time: 0.0292  memory: 9712  loss: 1.2259  loss_rpn_cls: 0.0402  loss_rpn_bbox: 0.0295  s0.loss_cls: 0.1938  s0.acc: 92.5781  s0.loss_bbox: 0.2532  s0.loss_mask: 0.2480  s1.loss_cls: 0.0864  s1.acc: 95.7468  s1.loss_bbox: 0.1106  s1.loss_mask: 0.1230  s2.loss_cls: 0.0405  s2.acc: 96.2038  s2.loss_bbox: 0.0428  s2.loss_mask: 0.0579
2024/02/24 08:07:23 - mmengine - INFO - Epoch(train) [35][1550/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:31:14  time: 0.6790  data_time: 0.0232  memory: 9389  loss: 1.2025  loss_rpn_cls: 0.0369  loss_rpn_bbox: 0.0253  s0.loss_cls: 0.1940  s0.acc: 93.0664  s0.loss_bbox: 0.2565  s0.loss_mask: 0.2360  s1.loss_cls: 0.0832  s1.acc: 96.1348  s1.loss_bbox: 0.1148  s1.loss_mask: 0.1161  s2.loss_cls: 0.0408  s2.acc: 94.5328  s2.loss_bbox: 0.0444  s2.loss_mask: 0.0544
2024/02/24 08:07:57 - mmengine - INFO - Epoch(train) [35][1600/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:30:35  time: 0.6799  data_time: 0.0262  memory: 9301  loss: 1.1790  loss_rpn_cls: 0.0382  loss_rpn_bbox: 0.0276  s0.loss_cls: 0.1807  s0.acc: 99.7070  s0.loss_bbox: 0.2355  s0.loss_mask: 0.2545  s1.loss_cls: 0.0815  s1.acc: 99.9023  s1.loss_bbox: 0.1021  s1.loss_mask: 0.1243  s2.loss_cls: 0.0394  s2.acc: 100.0000  s2.loss_bbox: 0.0390  s2.loss_mask: 0.0563
2024/02/24 08:08:32 - mmengine - INFO - Epoch(train) [35][1650/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:30:01  time: 0.6949  data_time: 0.0268  memory: 9760  loss: 1.1882  loss_rpn_cls: 0.0429  loss_rpn_bbox: 0.0251  s0.loss_cls: 0.1882  s0.acc: 97.7539  s0.loss_bbox: 0.2388  s0.loss_mask: 0.2532  s1.loss_cls: 0.0812  s1.acc: 99.6094  s1.loss_bbox: 0.1024  s1.loss_mask: 0.1218  s2.loss_cls: 0.0375  s2.acc: 99.9023  s2.loss_bbox: 0.0405  s2.loss_mask: 0.0565
2024/02/24 08:09:07 - mmengine - INFO - Epoch(train) [35][1700/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:29:31  time: 0.7027  data_time: 0.0291  memory: 9081  loss: 1.2702  loss_rpn_cls: 0.0452  loss_rpn_bbox: 0.0327  s0.loss_cls: 0.1965  s0.acc: 90.1367  s0.loss_bbox: 0.2644  s0.loss_mask: 0.2597  s1.loss_cls: 0.0872  s1.acc: 91.1021  s1.loss_bbox: 0.1150  s1.loss_mask: 0.1268  s2.loss_cls: 0.0403  s2.acc: 90.0910  s2.loss_bbox: 0.0438  s2.loss_mask: 0.0586
2024/02/24 08:09:41 - mmengine - INFO - Epoch(train) [35][1750/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:28:56  time: 0.6907  data_time: 0.0300  memory: 9665  loss: 1.2444  loss_rpn_cls: 0.0409  loss_rpn_bbox: 0.0295  s0.loss_cls: 0.1983  s0.acc: 93.2617  s0.loss_bbox: 0.2652  s0.loss_mask: 0.2413  s1.loss_cls: 0.0865  s1.acc: 94.7475  s1.loss_bbox: 0.1194  s1.loss_mask: 0.1196  s2.loss_cls: 0.0416  s2.acc: 92.1053  s2.loss_bbox: 0.0463  s2.loss_mask: 0.0557
2024/02/24 08:10:02 - mmengine - INFO - Exp name: cascade_mask_rcnn_swin_tiny_patch4_window7_mstrain_480-800_giou_4conv1f_adamw_3x_coco_20240224_074830
2024/02/24 08:10:16 - mmengine - INFO - Epoch(train) [35][1800/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:28:20  time: 0.6905  data_time: 0.0279  memory: 9291  loss: 1.1379  loss_rpn_cls: 0.0318  loss_rpn_bbox: 0.0253  s0.loss_cls: 0.1759  s0.acc: 97.2656  s0.loss_bbox: 0.2458  s0.loss_mask: 0.2262  s1.loss_cls: 0.0797  s1.acc: 98.1445  s1.loss_bbox: 0.1112  s1.loss_mask: 0.1089  s2.loss_cls: 0.0364  s2.acc: 96.7773  s2.loss_bbox: 0.0455  s2.loss_mask: 0.0512
2024/02/24 08:10:50 - mmengine - INFO - Epoch(train) [35][1850/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:27:45  time: 0.6904  data_time: 0.0265  memory: 9480  loss: 1.1553  loss_rpn_cls: 0.0412  loss_rpn_bbox: 0.0285  s0.loss_cls: 0.1749  s0.acc: 90.7227  s0.loss_bbox: 0.2416  s0.loss_mask: 0.2357  s1.loss_cls: 0.0755  s1.acc: 92.4753  s1.loss_bbox: 0.1106  s1.loss_mask: 0.1144  s2.loss_cls: 0.0352  s2.acc: 92.6733  s2.loss_bbox: 0.0442  s2.loss_mask: 0.0535
2024/02/24 08:11:24 - mmengine - INFO - Epoch(train) [35][1900/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:27:06  time: 0.6797  data_time: 0.0246  memory: 10389  loss: 1.1391  loss_rpn_cls: 0.0351  loss_rpn_bbox: 0.0251  s0.loss_cls: 0.1810  s0.acc: 96.0938  s0.loss_bbox: 0.2362  s0.loss_mask: 0.2324  s1.loss_cls: 0.0798  s1.acc: 97.4609  s1.loss_bbox: 0.1055  s1.loss_mask: 0.1123  s2.loss_cls: 0.0363  s2.acc: 98.3398  s2.loss_bbox: 0.0426  s2.loss_mask: 0.0528
2024/02/24 08:11:59 - mmengine - INFO - Epoch(train) [35][1950/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:26:31  time: 0.6897  data_time: 0.0283  memory: 9452  loss: 1.1328  loss_rpn_cls: 0.0347  loss_rpn_bbox: 0.0246  s0.loss_cls: 0.1817  s0.acc: 85.7422  s0.loss_bbox: 0.2345  s0.loss_mask: 0.2276  s1.loss_cls: 0.0821  s1.acc: 86.5580  s1.loss_bbox: 0.1055  s1.loss_mask: 0.1101  s2.loss_cls: 0.0394  s2.acc: 89.8148  s2.loss_bbox: 0.0404  s2.loss_mask: 0.0521
2024/02/24 08:12:33 - mmengine - INFO - Epoch(train) [35][2000/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:25:56  time: 0.6886  data_time: 0.0303  memory: 9988  loss: 1.2484  loss_rpn_cls: 0.0429  loss_rpn_bbox: 0.0303  s0.loss_cls: 0.1996  s0.acc: 96.6797  s0.loss_bbox: 0.2734  s0.loss_mask: 0.2341  s1.loss_cls: 0.0890  s1.acc: 96.9727  s1.loss_bbox: 0.1210  s1.loss_mask: 0.1142  s2.loss_cls: 0.0418  s2.acc: 96.0938  s2.loss_bbox: 0.0480  s2.loss_mask: 0.0540
2024/02/24 08:13:08 - mmengine - INFO - Epoch(train) [35][2050/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:25:21  time: 0.6903  data_time: 0.0305  memory: 9080  loss: 1.1819  loss_rpn_cls: 0.0375  loss_rpn_bbox: 0.0270  s0.loss_cls: 0.1836  s0.acc: 98.0469  s0.loss_bbox: 0.2396  s0.loss_mask: 0.2529  s1.loss_cls: 0.0817  s1.acc: 98.2422  s1.loss_bbox: 0.1064  s1.loss_mask: 0.1198  s2.loss_cls: 0.0381  s2.acc: 97.5586  s2.loss_bbox: 0.0401  s2.loss_mask: 0.0554
2024/02/24 08:13:42 - mmengine - INFO - Epoch(train) [35][2100/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:24:44  time: 0.6855  data_time: 0.0271  memory: 9991  loss: 1.2840  loss_rpn_cls: 0.0384  loss_rpn_bbox: 0.0267  s0.loss_cls: 0.2089  s0.acc: 91.1133  s0.loss_bbox: 0.2785  s0.loss_mask: 0.2472  s1.loss_cls: 0.0916  s1.acc: 92.3307  s1.loss_bbox: 0.1211  s1.loss_mask: 0.1229  s2.loss_cls: 0.0426  s2.acc: 93.2540  s2.loss_bbox: 0.0479  s2.loss_mask: 0.0581
2024/02/24 08:14:16 - mmengine - INFO - Epoch(train) [35][2150/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:24:07  time: 0.6826  data_time: 0.0273  memory: 9946  loss: 1.2815  loss_rpn_cls: 0.0424  loss_rpn_bbox: 0.0289  s0.loss_cls: 0.2063  s0.acc: 93.9453  s0.loss_bbox: 0.2611  s0.loss_mask: 0.2568  s1.loss_cls: 0.0934  s1.acc: 94.8242  s1.loss_bbox: 0.1179  s1.loss_mask: 0.1263  s2.loss_cls: 0.0447  s2.acc: 94.0430  s2.loss_bbox: 0.0459  s2.loss_mask: 0.0578
2024/02/24 08:14:51 - mmengine - INFO - Epoch(train) [35][2200/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:23:32  time: 0.6878  data_time: 0.0264  memory: 9606  loss: 1.1543  loss_rpn_cls: 0.0330  loss_rpn_bbox: 0.0233  s0.loss_cls: 0.1813  s0.acc: 93.6523  s0.loss_bbox: 0.2275  s0.loss_mask: 0.2458  s1.loss_cls: 0.0850  s1.acc: 92.4805  s1.loss_bbox: 0.1025  s1.loss_mask: 0.1196  s2.loss_cls: 0.0394  s2.acc: 93.6523  s2.loss_bbox: 0.0409  s2.loss_mask: 0.0559
2024/02/24 08:15:25 - mmengine - INFO - Epoch(train) [35][2250/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:22:56  time: 0.6869  data_time: 0.0285  memory: 9207  loss: 1.2125  loss_rpn_cls: 0.0407  loss_rpn_bbox: 0.0274  s0.loss_cls: 0.1865  s0.acc: 91.2109  s0.loss_bbox: 0.2491  s0.loss_mask: 0.2500  s1.loss_cls: 0.0805  s1.acc: 91.6583  s1.loss_bbox: 0.1159  s1.loss_mask: 0.1213  s2.loss_cls: 0.0393  s2.acc: 91.4744  s2.loss_bbox: 0.0462  s2.loss_mask: 0.0556
2024/02/24 08:15:59 - mmengine - INFO - Epoch(train) [35][2300/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:22:19  time: 0.6812  data_time: 0.0279  memory: 9350  loss: 1.1378  loss_rpn_cls: 0.0316  loss_rpn_bbox: 0.0259  s0.loss_cls: 0.1691  s0.acc: 97.3633  s0.loss_bbox: 0.2245  s0.loss_mask: 0.2564  s1.loss_cls: 0.0748  s1.acc: 98.9258  s1.loss_bbox: 0.1027  s1.loss_mask: 0.1204  s2.loss_cls: 0.0359  s2.acc: 97.2656  s2.loss_bbox: 0.0404  s2.loss_mask: 0.0560
2024/02/24 08:16:34 - mmengine - INFO - Epoch(train) [35][2350/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:21:44  time: 0.6909  data_time: 0.0279  memory: 9796  loss: 1.1979  loss_rpn_cls: 0.0374  loss_rpn_bbox: 0.0289  s0.loss_cls: 0.1900  s0.acc: 98.2422  s0.loss_bbox: 0.2438  s0.loss_mask: 0.2458  s1.loss_cls: 0.0855  s1.acc: 99.0234  s1.loss_bbox: 0.1077  s1.loss_mask: 0.1204  s2.loss_cls: 0.0404  s2.acc: 97.7539  s2.loss_bbox: 0.0431  s2.loss_mask: 0.0548
2024/02/24 08:17:09 - mmengine - INFO - Epoch(train) [35][2400/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:21:11  time: 0.6958  data_time: 0.0271  memory: 9718  loss: 1.2607  loss_rpn_cls: 0.0376  loss_rpn_bbox: 0.0254  s0.loss_cls: 0.1923  s0.acc: 93.4570  s0.loss_bbox: 0.2661  s0.loss_mask: 0.2589  s1.loss_cls: 0.0890  s1.acc: 93.3400  s1.loss_bbox: 0.1187  s1.loss_mask: 0.1249  s2.loss_cls: 0.0424  s2.acc: 92.9423  s2.loss_bbox: 0.0468  s2.loss_mask: 0.0588
2024/02/24 08:17:43 - mmengine - INFO - Epoch(train) [35][2450/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:20:33  time: 0.6775  data_time: 0.0285  memory: 9372  loss: 1.1646  loss_rpn_cls: 0.0322  loss_rpn_bbox: 0.0260  s0.loss_cls: 0.1737  s0.acc: 92.9688  s0.loss_bbox: 0.2400  s0.loss_mask: 0.2536  s1.loss_cls: 0.0783  s1.acc: 95.6055  s1.loss_bbox: 0.1048  s1.loss_mask: 0.1208  s2.loss_cls: 0.0385  s2.acc: 97.9492  s2.loss_bbox: 0.0412  s2.loss_mask: 0.0555
2024/02/24 08:18:17 - mmengine - INFO - Epoch(train) [35][2500/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:19:59  time: 0.6924  data_time: 0.0283  memory: 10367  loss: 1.2145  loss_rpn_cls: 0.0475  loss_rpn_bbox: 0.0320  s0.loss_cls: 0.1923  s0.acc: 95.9961  s0.loss_bbox: 0.2506  s0.loss_mask: 0.2395  s1.loss_cls: 0.0840  s1.acc: 97.2656  s1.loss_bbox: 0.1118  s1.loss_mask: 0.1177  s2.loss_cls: 0.0386  s2.acc: 97.1680  s2.loss_bbox: 0.0453  s2.loss_mask: 0.0552
2024/02/24 08:18:51 - mmengine - INFO - Epoch(train) [35][2550/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:19:22  time: 0.6821  data_time: 0.0237  memory: 9399  loss: 1.1004  loss_rpn_cls: 0.0320  loss_rpn_bbox: 0.0244  s0.loss_cls: 0.1713  s0.acc: 93.5547  s0.loss_bbox: 0.2208  s0.loss_mask: 0.2316  s1.loss_cls: 0.0752  s1.acc: 94.9850  s1.loss_bbox: 0.0997  s1.loss_mask: 0.1144  s2.loss_cls: 0.0363  s2.acc: 93.1864  s2.loss_bbox: 0.0408  s2.loss_mask: 0.0537
2024/02/24 08:19:26 - mmengine - INFO - Epoch(train) [35][2600/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:18:48  time: 0.6937  data_time: 0.0265  memory: 9651  loss: 1.2362  loss_rpn_cls: 0.0483  loss_rpn_bbox: 0.0349  s0.loss_cls: 0.2007  s0.acc: 95.4102  s0.loss_bbox: 0.2597  s0.loss_mask: 0.2356  s1.loss_cls: 0.0884  s1.acc: 96.4844  s1.loss_bbox: 0.1164  s1.loss_mask: 0.1137  s2.loss_cls: 0.0409  s2.acc: 93.2617  s2.loss_bbox: 0.0447  s2.loss_mask: 0.0529
2024/02/24 08:20:01 - mmengine - INFO - Epoch(train) [35][2650/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:18:14  time: 0.6907  data_time: 0.0290  memory: 9372  loss: 1.1815  loss_rpn_cls: 0.0366  loss_rpn_bbox: 0.0256  s0.loss_cls: 0.1873  s0.acc: 92.4805  s0.loss_bbox: 0.2549  s0.loss_mask: 0.2315  s1.loss_cls: 0.0831  s1.acc: 92.8858  s1.loss_bbox: 0.1160  s1.loss_mask: 0.1120  s2.loss_cls: 0.0390  s2.acc: 94.9900  s2.loss_bbox: 0.0441  s2.loss_mask: 0.0516
2024/02/24 08:20:35 - mmengine - INFO - Epoch(train) [35][2700/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:17:39  time: 0.6909  data_time: 0.0258  memory: 9701  loss: 1.1180  loss_rpn_cls: 0.0411  loss_rpn_bbox: 0.0314  s0.loss_cls: 0.1701  s0.acc: 94.9219  s0.loss_bbox: 0.2232  s0.loss_mask: 0.2307  s1.loss_cls: 0.0760  s1.acc: 94.6289  s1.loss_bbox: 0.1012  s1.loss_mask: 0.1140  s2.loss_cls: 0.0363  s2.acc: 96.0938  s2.loss_bbox: 0.0400  s2.loss_mask: 0.0540
2024/02/24 08:21:10 - mmengine - INFO - Epoch(train) [35][2750/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:17:03  time: 0.6835  data_time: 0.0274  memory: 9695  loss: 1.1189  loss_rpn_cls: 0.0327  loss_rpn_bbox: 0.0229  s0.loss_cls: 0.1759  s0.acc: 91.2109  s0.loss_bbox: 0.2327  s0.loss_mask: 0.2264  s1.loss_cls: 0.0772  s1.acc: 92.6160  s1.loss_bbox: 0.1079  s1.loss_mask: 0.1107  s2.loss_cls: 0.0374  s2.acc: 93.5553  s2.loss_bbox: 0.0432  s2.loss_mask: 0.0519
2024/02/24 08:21:30 - mmengine - INFO - Exp name: cascade_mask_rcnn_swin_tiny_patch4_window7_mstrain_480-800_giou_4conv1f_adamw_3x_coco_20240224_074830
2024/02/24 08:21:44 - mmengine - INFO - Epoch(train) [35][2800/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:16:28  time: 0.6874  data_time: 0.0265  memory: 9725  loss: 1.0636  loss_rpn_cls: 0.0328  loss_rpn_bbox: 0.0219  s0.loss_cls: 0.1579  s0.acc: 92.8711  s0.loss_bbox: 0.2179  s0.loss_mask: 0.2301  s1.loss_cls: 0.0667  s1.acc: 95.4102  s1.loss_bbox: 0.0986  s1.loss_mask: 0.1135  s2.loss_cls: 0.0318  s2.acc: 94.2383  s2.loss_bbox: 0.0395  s2.loss_mask: 0.0527
2024/02/24 08:22:19 - mmengine - INFO - Epoch(train) [35][2850/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:15:55  time: 0.6988  data_time: 0.0291  memory: 9728  loss: 1.1879  loss_rpn_cls: 0.0353  loss_rpn_bbox: 0.0283  s0.loss_cls: 0.1881  s0.acc: 88.1836  s0.loss_bbox: 0.2492  s0.loss_mask: 0.2392  s1.loss_cls: 0.0826  s1.acc: 88.8889  s1.loss_bbox: 0.1108  s1.loss_mask: 0.1181  s2.loss_cls: 0.0382  s2.acc: 91.8346  s2.loss_bbox: 0.0432  s2.loss_mask: 0.0548
2024/02/24 08:22:54 - mmengine - INFO - Epoch(train) [35][2900/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:15:22  time: 0.6971  data_time: 0.0293  memory: 9464  loss: 1.1761  loss_rpn_cls: 0.0435  loss_rpn_bbox: 0.0294  s0.loss_cls: 0.1803  s0.acc: 96.5820  s0.loss_bbox: 0.2424  s0.loss_mask: 0.2368  s1.loss_cls: 0.0803  s1.acc: 97.0703  s1.loss_bbox: 0.1110  s1.loss_mask: 0.1169  s2.loss_cls: 0.0379  s2.acc: 98.4375  s2.loss_bbox: 0.0442  s2.loss_mask: 0.0535
2024/02/24 08:23:28 - mmengine - INFO - Epoch(train) [35][2950/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:14:48  time: 0.6911  data_time: 0.0276  memory: 8928  loss: 1.1796  loss_rpn_cls: 0.0469  loss_rpn_bbox: 0.0279  s0.loss_cls: 0.1855  s0.acc: 98.0469  s0.loss_bbox: 0.2394  s0.loss_mask: 0.2394  s1.loss_cls: 0.0834  s1.acc: 99.0234  s1.loss_bbox: 0.1078  s1.loss_mask: 0.1154  s2.loss_cls: 0.0388  s2.acc: 98.1445  s2.loss_bbox: 0.0417  s2.loss_mask: 0.0534
2024/02/24 08:24:03 - mmengine - INFO - Epoch(train) [35][3000/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:14:15  time: 0.6982  data_time: 0.0259  memory: 9500  loss: 1.1674  loss_rpn_cls: 0.0390  loss_rpn_bbox: 0.0242  s0.loss_cls: 0.1842  s0.acc: 98.5352  s0.loss_bbox: 0.2404  s0.loss_mask: 0.2435  s1.loss_cls: 0.0795  s1.acc: 99.5117  s1.loss_bbox: 0.1074  s1.loss_mask: 0.1171  s2.loss_cls: 0.0373  s2.acc: 99.6094  s2.loss_bbox: 0.0413  s2.loss_mask: 0.0534
2024/02/24 08:24:38 - mmengine - INFO - Epoch(train) [35][3050/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:13:40  time: 0.6931  data_time: 0.0282  memory: 9431  loss: 1.2103  loss_rpn_cls: 0.0423  loss_rpn_bbox: 0.0276  s0.loss_cls: 0.1982  s0.acc: 87.7930  s0.loss_bbox: 0.2567  s0.loss_mask: 0.2405  s1.loss_cls: 0.0859  s1.acc: 89.3555  s1.loss_bbox: 0.1105  s1.loss_mask: 0.1129  s2.loss_cls: 0.0393  s2.acc: 92.2852  s2.loss_bbox: 0.0438  s2.loss_mask: 0.0526
2024/02/24 08:25:12 - mmengine - INFO - Epoch(train) [35][3100/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:13:05  time: 0.6848  data_time: 0.0273  memory: 9526  loss: 1.2417  loss_rpn_cls: 0.0389  loss_rpn_bbox: 0.0257  s0.loss_cls: 0.2059  s0.acc: 90.5273  s0.loss_bbox: 0.2562  s0.loss_mask: 0.2475  s1.loss_cls: 0.0901  s1.acc: 91.8946  s1.loss_bbox: 0.1126  s1.loss_mask: 0.1210  s2.loss_cls: 0.0424  s2.acc: 92.1827  s2.loss_bbox: 0.0449  s2.loss_mask: 0.0565
2024/02/24 08:25:47 - mmengine - INFO - Epoch(train) [35][3150/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:12:30  time: 0.6869  data_time: 0.0244  memory: 8990  loss: 1.1220  loss_rpn_cls: 0.0296  loss_rpn_bbox: 0.0261  s0.loss_cls: 0.1634  s0.acc: 95.3125  s0.loss_bbox: 0.2351  s0.loss_mask: 0.2407  s1.loss_cls: 0.0727  s1.acc: 94.5135  s1.loss_bbox: 0.1049  s1.loss_mask: 0.1178  s2.loss_cls: 0.0353  s2.acc: 95.5743  s2.loss_bbox: 0.0413  s2.loss_mask: 0.0550
2024/02/24 08:26:21 - mmengine - INFO - Epoch(train) [35][3200/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:11:53  time: 0.6781  data_time: 0.0259  memory: 9481  loss: 1.1426  loss_rpn_cls: 0.0452  loss_rpn_bbox: 0.0304  s0.loss_cls: 0.1780  s0.acc: 97.7539  s0.loss_bbox: 0.2325  s0.loss_mask: 0.2373  s1.loss_cls: 0.0788  s1.acc: 96.5820  s1.loss_bbox: 0.1022  s1.loss_mask: 0.1110  s2.loss_cls: 0.0359  s2.acc: 97.8516  s2.loss_bbox: 0.0404  s2.loss_mask: 0.0508
2024/02/24 08:26:55 - mmengine - INFO - Epoch(train) [35][3250/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:11:17  time: 0.6815  data_time: 0.0238  memory: 11549  loss: 1.1344  loss_rpn_cls: 0.0348  loss_rpn_bbox: 0.0266  s0.loss_cls: 0.1680  s0.acc: 96.0938  s0.loss_bbox: 0.2357  s0.loss_mask: 0.2364  s1.loss_cls: 0.0727  s1.acc: 96.6135  s1.loss_bbox: 0.1065  s1.loss_mask: 0.1171  s2.loss_cls: 0.0351  s2.acc: 95.7171  s2.loss_bbox: 0.0444  s2.loss_mask: 0.0571
2024/02/24 08:27:29 - mmengine - INFO - Epoch(train) [35][3300/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:10:41  time: 0.6849  data_time: 0.0290  memory: 10627  loss: 1.1132  loss_rpn_cls: 0.0368  loss_rpn_bbox: 0.0257  s0.loss_cls: 0.1659  s0.acc: 90.1367  s0.loss_bbox: 0.2368  s0.loss_mask: 0.2242  s1.loss_cls: 0.0743  s1.acc: 91.4062  s1.loss_bbox: 0.1071  s1.loss_mask: 0.1127  s2.loss_cls: 0.0352  s2.acc: 94.4336  s2.loss_bbox: 0.0424  s2.loss_mask: 0.0522
2024/02/24 08:28:03 - mmengine - INFO - Epoch(train) [35][3350/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:10:05  time: 0.6827  data_time: 0.0251  memory: 9693  loss: 1.0850  loss_rpn_cls: 0.0313  loss_rpn_bbox: 0.0197  s0.loss_cls: 0.1619  s0.acc: 91.4062  s0.loss_bbox: 0.2192  s0.loss_mask: 0.2315  s1.loss_cls: 0.0727  s1.acc: 93.2338  s1.loss_bbox: 0.1018  s1.loss_mask: 0.1160  s2.loss_cls: 0.0353  s2.acc: 94.0358  s2.loss_bbox: 0.0410  s2.loss_mask: 0.0547
2024/02/24 08:28:37 - mmengine - INFO - Epoch(train) [35][3400/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:09:30  time: 0.6854  data_time: 0.0271  memory: 9739  loss: 1.2496  loss_rpn_cls: 0.0362  loss_rpn_bbox: 0.0310  s0.loss_cls: 0.1954  s0.acc: 95.2148  s0.loss_bbox: 0.2455  s0.loss_mask: 0.2705  s1.loss_cls: 0.0886  s1.acc: 95.0195  s1.loss_bbox: 0.1096  s1.loss_mask: 0.1296  s2.loss_cls: 0.0417  s2.acc: 95.0195  s2.loss_bbox: 0.0426  s2.loss_mask: 0.0591
2024/02/24 08:29:12 - mmengine - INFO - Epoch(train) [35][3450/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:08:56  time: 0.6914  data_time: 0.0281  memory: 9747  loss: 1.1685  loss_rpn_cls: 0.0471  loss_rpn_bbox: 0.0290  s0.loss_cls: 0.1873  s0.acc: 92.9688  s0.loss_bbox: 0.2403  s0.loss_mask: 0.2252  s1.loss_cls: 0.0833  s1.acc: 95.2148  s1.loss_bbox: 0.1083  s1.loss_mask: 0.1119  s2.loss_cls: 0.0392  s2.acc: 94.9219  s2.loss_bbox: 0.0437  s2.loss_mask: 0.0533
2024/02/24 08:29:47 - mmengine - INFO - Epoch(train) [35][3500/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:08:21  time: 0.6890  data_time: 0.0299  memory: 9360  loss: 1.1688  loss_rpn_cls: 0.0416  loss_rpn_bbox: 0.0282  s0.loss_cls: 0.1777  s0.acc: 98.5352  s0.loss_bbox: 0.2478  s0.loss_mask: 0.2357  s1.loss_cls: 0.0772  s1.acc: 99.0234  s1.loss_bbox: 0.1123  s1.loss_mask: 0.1151  s2.loss_cls: 0.0362  s2.acc: 97.5586  s2.loss_bbox: 0.0436  s2.loss_mask: 0.0534
2024/02/24 08:30:21 - mmengine - INFO - Epoch(train) [35][3550/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:07:47  time: 0.6908  data_time: 0.0275  memory: 9575  loss: 1.1590  loss_rpn_cls: 0.0486  loss_rpn_bbox: 0.0349  s0.loss_cls: 0.1881  s0.acc: 95.1172  s0.loss_bbox: 0.2345  s0.loss_mask: 0.2250  s1.loss_cls: 0.0850  s1.acc: 96.7773  s1.loss_bbox: 0.1032  s1.loss_mask: 0.1082  s2.loss_cls: 0.0404  s2.acc: 96.7773  s2.loss_bbox: 0.0414  s2.loss_mask: 0.0497
2024/02/24 08:30:56 - mmengine - INFO - Epoch(train) [35][3600/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:07:12  time: 0.6898  data_time: 0.0279  memory: 9740  loss: 1.1215  loss_rpn_cls: 0.0403  loss_rpn_bbox: 0.0278  s0.loss_cls: 0.1724  s0.acc: 99.5117  s0.loss_bbox: 0.2348  s0.loss_mask: 0.2259  s1.loss_cls: 0.0746  s1.acc: 99.8047  s1.loss_bbox: 0.1058  s1.loss_mask: 0.1092  s2.loss_cls: 0.0360  s2.acc: 99.8047  s2.loss_bbox: 0.0434  s2.loss_mask: 0.0513
2024/02/24 08:31:30 - mmengine - INFO - Epoch(train) [35][3650/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:06:37  time: 0.6851  data_time: 0.0280  memory: 9630  loss: 1.1688  loss_rpn_cls: 0.0385  loss_rpn_bbox: 0.0291  s0.loss_cls: 0.1765  s0.acc: 90.4297  s0.loss_bbox: 0.2540  s0.loss_mask: 0.2326  s1.loss_cls: 0.0798  s1.acc: 89.9209  s1.loss_bbox: 0.1118  s1.loss_mask: 0.1119  s2.loss_cls: 0.0381  s2.acc: 90.0296  s2.loss_bbox: 0.0443  s2.loss_mask: 0.0521
2024/02/24 08:32:04 - mmengine - INFO - Epoch(train) [35][3700/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:06:01  time: 0.6806  data_time: 0.0279  memory: 9897  loss: 1.1348  loss_rpn_cls: 0.0389  loss_rpn_bbox: 0.0235  s0.loss_cls: 0.1723  s0.acc: 85.0586  s0.loss_bbox: 0.2327  s0.loss_mask: 0.2340  s1.loss_cls: 0.0798  s1.acc: 85.6445  s1.loss_bbox: 0.1045  s1.loss_mask: 0.1154  s2.loss_cls: 0.0377  s2.acc: 88.2812  s2.loss_bbox: 0.0418  s2.loss_mask: 0.0541
2024/02/24 08:32:38 - mmengine - INFO - Epoch(train) [35][3750/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:05:26  time: 0.6832  data_time: 0.0281  memory: 9754  loss: 1.3167  loss_rpn_cls: 0.0488  loss_rpn_bbox: 0.0335  s0.loss_cls: 0.2128  s0.acc: 99.1211  s0.loss_bbox: 0.2831  s0.loss_mask: 0.2534  s1.loss_cls: 0.0977  s1.acc: 99.5117  s1.loss_bbox: 0.1200  s1.loss_mask: 0.1188  s2.loss_cls: 0.0467  s2.acc: 99.0234  s2.loss_bbox: 0.0457  s2.loss_mask: 0.0561
2024/02/24 08:32:59 - mmengine - INFO - Exp name: cascade_mask_rcnn_swin_tiny_patch4_window7_mstrain_480-800_giou_4conv1f_adamw_3x_coco_20240224_074830
2024/02/24 08:33:12 - mmengine - INFO - Epoch(train) [35][3800/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:04:50  time: 0.6834  data_time: 0.0260  memory: 9458  loss: 1.2097  loss_rpn_cls: 0.0319  loss_rpn_bbox: 0.0312  s0.loss_cls: 0.1949  s0.acc: 93.1641  s0.loss_bbox: 0.2490  s0.loss_mask: 0.2498  s1.loss_cls: 0.0874  s1.acc: 93.7500  s1.loss_bbox: 0.1108  s1.loss_mask: 0.1177  s2.loss_cls: 0.0396  s2.acc: 95.2525  s2.loss_bbox: 0.0420  s2.loss_mask: 0.0553
2024/02/24 08:33:47 - mmengine - INFO - Epoch(train) [35][3850/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:04:16  time: 0.6899  data_time: 0.0275  memory: 10306  loss: 1.2358  loss_rpn_cls: 0.0374  loss_rpn_bbox: 0.0338  s0.loss_cls: 0.2067  s0.acc: 93.9453  s0.loss_bbox: 0.2543  s0.loss_mask: 0.2345  s1.loss_cls: 0.0932  s1.acc: 93.3267  s1.loss_bbox: 0.1165  s1.loss_mask: 0.1147  s2.loss_cls: 0.0449  s2.acc: 93.1480  s2.loss_bbox: 0.0460  s2.loss_mask: 0.0537
2024/02/24 08:34:21 - mmengine - INFO - Epoch(train) [35][3900/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:03:39  time: 0.6773  data_time: 0.0281  memory: 9582  loss: 1.1402  loss_rpn_cls: 0.0407  loss_rpn_bbox: 0.0297  s0.loss_cls: 0.1763  s0.acc: 94.8242  s0.loss_bbox: 0.2406  s0.loss_mask: 0.2248  s1.loss_cls: 0.0770  s1.acc: 95.5078  s1.loss_bbox: 0.1086  s1.loss_mask: 0.1092  s2.loss_cls: 0.0372  s2.acc: 94.2214  s2.loss_bbox: 0.0440  s2.loss_mask: 0.0521
2024/02/24 08:34:55 - mmengine - INFO - Epoch(train) [35][3950/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:03:05  time: 0.6915  data_time: 0.0259  memory: 9576  loss: 1.1702  loss_rpn_cls: 0.0339  loss_rpn_bbox: 0.0251  s0.loss_cls: 0.1791  s0.acc: 90.0391  s0.loss_bbox: 0.2465  s0.loss_mask: 0.2418  s1.loss_cls: 0.0808  s1.acc: 91.7969  s1.loss_bbox: 0.1107  s1.loss_mask: 0.1169  s2.loss_cls: 0.0383  s2.acc: 93.3594  s2.loss_bbox: 0.0443  s2.loss_mask: 0.0529
2024/02/24 08:35:30 - mmengine - INFO - Epoch(train) [35][4000/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:02:30  time: 0.6859  data_time: 0.0254  memory: 10598  loss: 1.1139  loss_rpn_cls: 0.0346  loss_rpn_bbox: 0.0245  s0.loss_cls: 0.1722  s0.acc: 90.0391  s0.loss_bbox: 0.2211  s0.loss_mask: 0.2326  s1.loss_cls: 0.0792  s1.acc: 90.7093  s1.loss_bbox: 0.1030  s1.loss_mask: 0.1145  s2.loss_cls: 0.0369  s2.acc: 92.9283  s2.loss_bbox: 0.0418  s2.loss_mask: 0.0534
2024/02/24 08:36:04 - mmengine - INFO - Epoch(train) [35][4050/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:01:55  time: 0.6819  data_time: 0.0286  memory: 9989  loss: 1.1622  loss_rpn_cls: 0.0366  loss_rpn_bbox: 0.0297  s0.loss_cls: 0.1864  s0.acc: 91.6992  s0.loss_bbox: 0.2440  s0.loss_mask: 0.2312  s1.loss_cls: 0.0811  s1.acc: 90.6953  s1.loss_bbox: 0.1089  s1.loss_mask: 0.1101  s2.loss_cls: 0.0389  s2.acc: 90.2340  s2.loss_bbox: 0.0440  s2.loss_mask: 0.0512
2024/02/24 08:36:37 - mmengine - INFO - Epoch(train) [35][4100/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:01:18  time: 0.6725  data_time: 0.0288  memory: 9951  loss: 1.0897  loss_rpn_cls: 0.0338  loss_rpn_bbox: 0.0236  s0.loss_cls: 0.1688  s0.acc: 98.2422  s0.loss_bbox: 0.2199  s0.loss_mask: 0.2285  s1.loss_cls: 0.0744  s1.acc: 98.5352  s1.loss_bbox: 0.1019  s1.loss_mask: 0.1093  s2.loss_cls: 0.0358  s2.acc: 99.2188  s2.loss_bbox: 0.0418  s2.loss_mask: 0.0519
2024/02/24 08:37:12 - mmengine - INFO - Epoch(train) [35][4150/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:00:43  time: 0.6809  data_time: 0.0265  memory: 10037  loss: 1.2803  loss_rpn_cls: 0.0453  loss_rpn_bbox: 0.0292  s0.loss_cls: 0.2026  s0.acc: 93.3594  s0.loss_bbox: 0.2684  s0.loss_mask: 0.2604  s1.loss_cls: 0.0888  s1.acc: 95.5078  s1.loss_bbox: 0.1178  s1.loss_mask: 0.1252  s2.loss_cls: 0.0402  s2.acc: 94.3026  s2.loss_bbox: 0.0444  s2.loss_mask: 0.0580
2024/02/24 08:37:46 - mmengine - INFO - Epoch(train) [35][4200/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:00:08  time: 0.6893  data_time: 0.0270  memory: 9535  loss: 1.1545  loss_rpn_cls: 0.0402  loss_rpn_bbox: 0.0262  s0.loss_cls: 0.1765  s0.acc: 96.5820  s0.loss_bbox: 0.2482  s0.loss_mask: 0.2342  s1.loss_cls: 0.0773  s1.acc: 96.0938  s1.loss_bbox: 0.1121  s1.loss_mask: 0.1102  s2.loss_cls: 0.0352  s2.acc: 95.7031  s2.loss_bbox: 0.0436  s2.loss_mask: 0.0506
2024/02/24 08:38:21 - mmengine - INFO - Epoch(train) [35][4250/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:59:35  time: 0.6966  data_time: 0.0283  memory: 9585  loss: 1.2699  loss_rpn_cls: 0.0437  loss_rpn_bbox: 0.0274  s0.loss_cls: 0.2027  s0.acc: 95.9961  s0.loss_bbox: 0.2816  s0.loss_mask: 0.2408  s1.loss_cls: 0.0914  s1.acc: 95.5078  s1.loss_bbox: 0.1235  s1.loss_mask: 0.1156  s2.loss_cls: 0.0428  s2.acc: 96.5820  s2.loss_bbox: 0.0470  s2.loss_mask: 0.0534
2024/02/24 08:38:56 - mmengine - INFO - Epoch(train) [35][4300/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:59:01  time: 0.6940  data_time: 0.0264  memory: 9506  loss: 1.2072  loss_rpn_cls: 0.0453  loss_rpn_bbox: 0.0298  s0.loss_cls: 0.1935  s0.acc: 98.4375  s0.loss_bbox: 0.2502  s0.loss_mask: 0.2367  s1.loss_cls: 0.0849  s1.acc: 99.5117  s1.loss_bbox: 0.1119  s1.loss_mask: 0.1153  s2.loss_cls: 0.0412  s2.acc: 99.1211  s2.loss_bbox: 0.0441  s2.loss_mask: 0.0542
2024/02/24 08:39:30 - mmengine - INFO - Epoch(train) [35][4350/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:58:26  time: 0.6907  data_time: 0.0260  memory: 9281  loss: 1.1027  loss_rpn_cls: 0.0385  loss_rpn_bbox: 0.0226  s0.loss_cls: 0.1729  s0.acc: 94.0430  s0.loss_bbox: 0.2378  s0.loss_mask: 0.2185  s1.loss_cls: 0.0729  s1.acc: 94.8869  s1.loss_bbox: 0.1077  s1.loss_mask: 0.1053  s2.loss_cls: 0.0332  s2.acc: 95.0836  s2.loss_bbox: 0.0435  s2.loss_mask: 0.0500
2024/02/24 08:40:05 - mmengine - INFO - Epoch(train) [35][4400/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:57:52  time: 0.6896  data_time: 0.0246  memory: 8851  loss: 1.0705  loss_rpn_cls: 0.0305  loss_rpn_bbox: 0.0251  s0.loss_cls: 0.1656  s0.acc: 98.0469  s0.loss_bbox: 0.2136  s0.loss_mask: 0.2302  s1.loss_cls: 0.0739  s1.acc: 97.8516  s1.loss_bbox: 0.0960  s1.loss_mask: 0.1119  s2.loss_cls: 0.0340  s2.acc: 97.5586  s2.loss_bbox: 0.0377  s2.loss_mask: 0.0520
2024/02/24 08:40:39 - mmengine - INFO - Epoch(train) [35][4450/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:57:17  time: 0.6827  data_time: 0.0272  memory: 9482  loss: 1.1547  loss_rpn_cls: 0.0365  loss_rpn_bbox: 0.0251  s0.loss_cls: 0.1838  s0.acc: 82.4219  s0.loss_bbox: 0.2326  s0.loss_mask: 0.2419  s1.loss_cls: 0.0797  s1.acc: 83.5851  s1.loss_bbox: 0.1060  s1.loss_mask: 0.1148  s2.loss_cls: 0.0382  s2.acc: 83.6345  s2.loss_bbox: 0.0429  s2.loss_mask: 0.0534
2024/02/24 08:41:13 - mmengine - INFO - Epoch(train) [35][4500/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:56:42  time: 0.6831  data_time: 0.0269  memory: 9264  loss: 1.1576  loss_rpn_cls: 0.0358  loss_rpn_bbox: 0.0241  s0.loss_cls: 0.1832  s0.acc: 94.0430  s0.loss_bbox: 0.2361  s0.loss_mask: 0.2435  s1.loss_cls: 0.0801  s1.acc: 96.9727  s1.loss_bbox: 0.1042  s1.loss_mask: 0.1183  s2.loss_cls: 0.0386  s2.acc: 96.5820  s2.loss_bbox: 0.0393  s2.loss_mask: 0.0543
2024/02/24 08:41:47 - mmengine - INFO - Epoch(train) [35][4550/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:56:06  time: 0.6812  data_time: 0.0289  memory: 10071  loss: 1.1939  loss_rpn_cls: 0.0431  loss_rpn_bbox: 0.0257  s0.loss_cls: 0.1831  s0.acc: 90.6250  s0.loss_bbox: 0.2514  s0.loss_mask: 0.2394  s1.loss_cls: 0.0787  s1.acc: 90.1099  s1.loss_bbox: 0.1154  s1.loss_mask: 0.1181  s2.loss_cls: 0.0378  s2.acc: 89.1109  s2.loss_bbox: 0.0460  s2.loss_mask: 0.0553
2024/02/24 08:42:21 - mmengine - INFO - Epoch(train) [35][4600/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:55:31  time: 0.6853  data_time: 0.0274  memory: 9333  loss: 1.1903  loss_rpn_cls: 0.0440  loss_rpn_bbox: 0.0283  s0.loss_cls: 0.1908  s0.acc: 92.1875  s0.loss_bbox: 0.2481  s0.loss_mask: 0.2345  s1.loss_cls: 0.0816  s1.acc: 92.3001  s1.loss_bbox: 0.1118  s1.loss_mask: 0.1144  s2.loss_cls: 0.0393  s2.acc: 91.6091  s2.loss_bbox: 0.0440  s2.loss_mask: 0.0537
2024/02/24 08:42:56 - mmengine - INFO - Epoch(train) [35][4650/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:54:57  time: 0.6886  data_time: 0.0244  memory: 9699  loss: 1.1524  loss_rpn_cls: 0.0319  loss_rpn_bbox: 0.0233  s0.loss_cls: 0.1859  s0.acc: 93.5547  s0.loss_bbox: 0.2380  s0.loss_mask: 0.2404  s1.loss_cls: 0.0836  s1.acc: 93.3668  s1.loss_bbox: 0.1037  s1.loss_mask: 0.1159  s2.loss_cls: 0.0380  s2.acc: 93.3200  s2.loss_bbox: 0.0393  s2.loss_mask: 0.0525
2024/02/24 08:43:31 - mmengine - INFO - Epoch(train) [35][4700/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:54:23  time: 0.6918  data_time: 0.0297  memory: 9746  loss: 1.1696  loss_rpn_cls: 0.0410  loss_rpn_bbox: 0.0322  s0.loss_cls: 0.1754  s0.acc: 92.9688  s0.loss_bbox: 0.2509  s0.loss_mask: 0.2276  s1.loss_cls: 0.0797  s1.acc: 92.7419  s1.loss_bbox: 0.1142  s1.loss_mask: 0.1121  s2.loss_cls: 0.0375  s2.acc: 94.2540  s2.loss_bbox: 0.0464  s2.loss_mask: 0.0525
2024/02/24 08:44:05 - mmengine - INFO - Epoch(train) [35][4750/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:53:48  time: 0.6820  data_time: 0.0276  memory: 10441  loss: 1.1582  loss_rpn_cls: 0.0336  loss_rpn_bbox: 0.0252  s0.loss_cls: 0.1836  s0.acc: 92.1875  s0.loss_bbox: 0.2421  s0.loss_mask: 0.2364  s1.loss_cls: 0.0845  s1.acc: 94.2249  s1.loss_bbox: 0.1065  s1.loss_mask: 0.1125  s2.loss_cls: 0.0396  s2.acc: 93.9086  s2.loss_bbox: 0.0416  s2.loss_mask: 0.0526
2024/02/24 08:44:25 - mmengine - INFO - Exp name: cascade_mask_rcnn_swin_tiny_patch4_window7_mstrain_480-800_giou_4conv1f_adamw_3x_coco_20240224_074830
2024/02/24 08:44:39 - mmengine - INFO - Epoch(train) [35][4800/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:53:13  time: 0.6888  data_time: 0.0253  memory: 9765  loss: 1.1982  loss_rpn_cls: 0.0391  loss_rpn_bbox: 0.0321  s0.loss_cls: 0.1828  s0.acc: 92.4805  s0.loss_bbox: 0.2451  s0.loss_mask: 0.2542  s1.loss_cls: 0.0820  s1.acc: 91.4401  s1.loss_bbox: 0.1072  s1.loss_mask: 0.1208  s2.loss_cls: 0.0370  s2.acc: 93.9333  s2.loss_bbox: 0.0418  s2.loss_mask: 0.0561
2024/02/24 08:45:13 - mmengine - INFO - Epoch(train) [35][4850/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:52:38  time: 0.6853  data_time: 0.0243  memory: 9678  loss: 1.1486  loss_rpn_cls: 0.0425  loss_rpn_bbox: 0.0280  s0.loss_cls: 0.1791  s0.acc: 91.2109  s0.loss_bbox: 0.2350  s0.loss_mask: 0.2331  s1.loss_cls: 0.0796  s1.acc: 88.9648  s1.loss_bbox: 0.1050  s1.loss_mask: 0.1141  s2.loss_cls: 0.0361  s2.acc: 89.3555  s2.loss_bbox: 0.0419  s2.loss_mask: 0.0543
2024/02/24 08:45:47 - mmengine - INFO - Epoch(train) [35][4900/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:52:03  time: 0.6788  data_time: 0.0215  memory: 9397  loss: 1.0777  loss_rpn_cls: 0.0338  loss_rpn_bbox: 0.0247  s0.loss_cls: 0.1769  s0.acc: 93.9453  s0.loss_bbox: 0.2131  s0.loss_mask: 0.2220  s1.loss_cls: 0.0764  s1.acc: 93.4459  s1.loss_bbox: 0.0985  s1.loss_mask: 0.1068  s2.loss_cls: 0.0352  s2.acc: 93.1615  s2.loss_bbox: 0.0397  s2.loss_mask: 0.0505
2024/02/24 08:46:22 - mmengine - INFO - Epoch(train) [35][4950/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:51:29  time: 0.6983  data_time: 0.0244  memory: 9943  loss: 1.1607  loss_rpn_cls: 0.0326  loss_rpn_bbox: 0.0239  s0.loss_cls: 0.1882  s0.acc: 91.6016  s0.loss_bbox: 0.2360  s0.loss_mask: 0.2335  s1.loss_cls: 0.0844  s1.acc: 90.7753  s1.loss_bbox: 0.1078  s1.loss_mask: 0.1157  s2.loss_cls: 0.0399  s2.acc: 90.0000  s2.loss_bbox: 0.0437  s2.loss_mask: 0.0549
2024/02/24 08:46:57 - mmengine - INFO - Epoch(train) [35][5000/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:50:55  time: 0.6885  data_time: 0.0277  memory: 9737  loss: 1.1472  loss_rpn_cls: 0.0411  loss_rpn_bbox: 0.0254  s0.loss_cls: 0.1803  s0.acc: 96.2891  s0.loss_bbox: 0.2367  s0.loss_mask: 0.2275  s1.loss_cls: 0.0837  s1.acc: 96.8750  s1.loss_bbox: 0.1083  s1.loss_mask: 0.1110  s2.loss_cls: 0.0389  s2.acc: 97.7539  s2.loss_bbox: 0.0426  s2.loss_mask: 0.0518
2024/02/24 08:47:31 - mmengine - INFO - Epoch(train) [35][5050/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:50:19  time: 0.6786  data_time: 0.0249  memory: 9524  loss: 1.1431  loss_rpn_cls: 0.0395  loss_rpn_bbox: 0.0281  s0.loss_cls: 0.1720  s0.acc: 92.0898  s0.loss_bbox: 0.2324  s0.loss_mask: 0.2425  s1.loss_cls: 0.0759  s1.acc: 94.0756  s1.loss_bbox: 0.1059  s1.loss_mask: 0.1155  s2.loss_cls: 0.0348  s2.acc: 94.5863  s2.loss_bbox: 0.0429  s2.loss_mask: 0.0535
2024/02/24 08:48:05 - mmengine - INFO - Epoch(train) [35][5100/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:49:44  time: 0.6844  data_time: 0.0244  memory: 9644  loss: 1.1978  loss_rpn_cls: 0.0364  loss_rpn_bbox: 0.0247  s0.loss_cls: 0.1948  s0.acc: 85.6445  s0.loss_bbox: 0.2495  s0.loss_mask: 0.2461  s1.loss_cls: 0.0837  s1.acc: 86.7163  s1.loss_bbox: 0.1098  s1.loss_mask: 0.1155  s2.loss_cls: 0.0404  s2.acc: 87.5659  s2.loss_bbox: 0.0433  s2.loss_mask: 0.0535
2024/02/24 08:48:40 - mmengine - INFO - Epoch(train) [35][5150/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:49:11  time: 0.6957  data_time: 0.0257  memory: 10014  loss: 1.1869  loss_rpn_cls: 0.0303  loss_rpn_bbox: 0.0262  s0.loss_cls: 0.1817  s0.acc: 97.1680  s0.loss_bbox: 0.2480  s0.loss_mask: 0.2469  s1.loss_cls: 0.0852  s1.acc: 97.7539  s1.loss_bbox: 0.1111  s1.loss_mask: 0.1192  s2.loss_cls: 0.0399  s2.acc: 97.0703  s2.loss_bbox: 0.0421  s2.loss_mask: 0.0563
2024/02/24 08:49:14 - mmengine - INFO - Epoch(train) [35][5200/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:48:36  time: 0.6907  data_time: 0.0239  memory: 9391  loss: 1.0743  loss_rpn_cls: 0.0364  loss_rpn_bbox: 0.0269  s0.loss_cls: 0.1632  s0.acc: 89.9414  s0.loss_bbox: 0.2256  s0.loss_mask: 0.2199  s1.loss_cls: 0.0714  s1.acc: 87.4387  s1.loss_bbox: 0.1043  s1.loss_mask: 0.1041  s2.loss_cls: 0.0345  s2.acc: 88.1373  s2.loss_bbox: 0.0406  s2.loss_mask: 0.0474
2024/02/24 08:49:49 - mmengine - INFO - Epoch(train) [35][5250/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:48:02  time: 0.6915  data_time: 0.0290  memory: 10743  loss: 1.2319  loss_rpn_cls: 0.0449  loss_rpn_bbox: 0.0324  s0.loss_cls: 0.1884  s0.acc: 98.1445  s0.loss_bbox: 0.2700  s0.loss_mask: 0.2454  s1.loss_cls: 0.0810  s1.acc: 99.0234  s1.loss_bbox: 0.1151  s1.loss_mask: 0.1174  s2.loss_cls: 0.0384  s2.acc: 97.3633  s2.loss_bbox: 0.0443  s2.loss_mask: 0.0545
2024/02/24 08:50:23 - mmengine - INFO - Epoch(train) [35][5300/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:47:28  time: 0.6883  data_time: 0.0229  memory: 9482  loss: 1.0102  loss_rpn_cls: 0.0301  loss_rpn_bbox: 0.0254  s0.loss_cls: 0.1516  s0.acc: 97.8516  s0.loss_bbox: 0.1987  s0.loss_mask: 0.2247  s1.loss_cls: 0.0637  s1.acc: 98.2422  s1.loss_bbox: 0.0905  s1.loss_mask: 0.1071  s2.loss_cls: 0.0309  s2.acc: 99.0234  s2.loss_bbox: 0.0371  s2.loss_mask: 0.0502
2024/02/24 08:50:58 - mmengine - INFO - Epoch(train) [35][5350/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:46:53  time: 0.6825  data_time: 0.0245  memory: 9702  loss: 1.0941  loss_rpn_cls: 0.0341  loss_rpn_bbox: 0.0257  s0.loss_cls: 0.1631  s0.acc: 91.6016  s0.loss_bbox: 0.2248  s0.loss_mask: 0.2318  s1.loss_cls: 0.0717  s1.acc: 93.0000  s1.loss_bbox: 0.1029  s1.loss_mask: 0.1126  s2.loss_cls: 0.0344  s2.acc: 94.1000  s2.loss_bbox: 0.0403  s2.loss_mask: 0.0528
2024/02/24 08:51:32 - mmengine - INFO - Epoch(train) [35][5400/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:46:17  time: 0.6797  data_time: 0.0263  memory: 9700  loss: 1.0773  loss_rpn_cls: 0.0288  loss_rpn_bbox: 0.0239  s0.loss_cls: 0.1629  s0.acc: 97.1680  s0.loss_bbox: 0.2215  s0.loss_mask: 0.2262  s1.loss_cls: 0.0770  s1.acc: 96.4844  s1.loss_bbox: 0.1006  s1.loss_mask: 0.1114  s2.loss_cls: 0.0342  s2.acc: 97.5514  s2.loss_bbox: 0.0399  s2.loss_mask: 0.0509
2024/02/24 08:52:06 - mmengine - INFO - Epoch(train) [35][5450/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:45:43  time: 0.6897  data_time: 0.0285  memory: 9368  loss: 1.2635  loss_rpn_cls: 0.0463  loss_rpn_bbox: 0.0359  s0.loss_cls: 0.1996  s0.acc: 88.0859  s0.loss_bbox: 0.2678  s0.loss_mask: 0.2479  s1.loss_cls: 0.0885  s1.acc: 88.4843  s1.loss_bbox: 0.1180  s1.loss_mask: 0.1179  s2.loss_cls: 0.0413  s2.acc: 88.7033  s2.loss_bbox: 0.0459  s2.loss_mask: 0.0543
2024/02/24 08:52:41 - mmengine - INFO - Epoch(train) [35][5500/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:45:10  time: 0.6997  data_time: 0.0293  memory: 9494  loss: 1.2053  loss_rpn_cls: 0.0396  loss_rpn_bbox: 0.0307  s0.loss_cls: 0.1737  s0.acc: 87.5977  s0.loss_bbox: 0.2550  s0.loss_mask: 0.2525  s1.loss_cls: 0.0761  s1.acc: 88.8672  s1.loss_bbox: 0.1156  s1.loss_mask: 0.1216  s2.loss_cls: 0.0366  s2.acc: 84.2773  s2.loss_bbox: 0.0464  s2.loss_mask: 0.0575
2024/02/24 08:53:15 - mmengine - INFO - Epoch(train) [35][5550/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:44:35  time: 0.6830  data_time: 0.0306  memory: 9285  loss: 1.1527  loss_rpn_cls: 0.0446  loss_rpn_bbox: 0.0286  s0.loss_cls: 0.1794  s0.acc: 85.0586  s0.loss_bbox: 0.2357  s0.loss_mask: 0.2348  s1.loss_cls: 0.0806  s1.acc: 88.6660  s1.loss_bbox: 0.1053  s1.loss_mask: 0.1113  s2.loss_cls: 0.0380  s2.acc: 87.5377  s2.loss_bbox: 0.0425  s2.loss_mask: 0.0521
2024/02/24 08:53:50 - mmengine - INFO - Epoch(train) [35][5600/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:44:00  time: 0.6848  data_time: 0.0276  memory: 9353  loss: 1.1558  loss_rpn_cls: 0.0435  loss_rpn_bbox: 0.0309  s0.loss_cls: 0.1861  s0.acc: 92.0898  s0.loss_bbox: 0.2445  s0.loss_mask: 0.2194  s1.loss_cls: 0.0812  s1.acc: 91.1443  s1.loss_bbox: 0.1103  s1.loss_mask: 0.1076  s2.loss_cls: 0.0385  s2.acc: 91.6418  s2.loss_bbox: 0.0433  s2.loss_mask: 0.0506
2024/02/24 08:54:24 - mmengine - INFO - Epoch(train) [35][5650/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:43:25  time: 0.6838  data_time: 0.0299  memory: 9641  loss: 1.2112  loss_rpn_cls: 0.0526  loss_rpn_bbox: 0.0342  s0.loss_cls: 0.1768  s0.acc: 94.9219  s0.loss_bbox: 0.2478  s0.loss_mask: 0.2456  s1.loss_cls: 0.0802  s1.acc: 93.9453  s1.loss_bbox: 0.1121  s1.loss_mask: 0.1226  s2.loss_cls: 0.0383  s2.acc: 92.5781  s2.loss_bbox: 0.0438  s2.loss_mask: 0.0572
2024/02/24 08:54:58 - mmengine - INFO - Epoch(train) [35][5700/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:42:50  time: 0.6806  data_time: 0.0248  memory: 9688  loss: 1.1435  loss_rpn_cls: 0.0358  loss_rpn_bbox: 0.0245  s0.loss_cls: 0.1725  s0.acc: 93.3594  s0.loss_bbox: 0.2366  s0.loss_mask: 0.2388  s1.loss_cls: 0.0761  s1.acc: 89.9414  s1.loss_bbox: 0.1105  s1.loss_mask: 0.1158  s2.loss_cls: 0.0362  s2.acc: 90.4297  s2.loss_bbox: 0.0430  s2.loss_mask: 0.0537
2024/02/24 08:55:32 - mmengine - INFO - Epoch(train) [35][5750/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:42:15  time: 0.6828  data_time: 0.0257  memory: 9498  loss: 1.2232  loss_rpn_cls: 0.0429  loss_rpn_bbox: 0.0286  s0.loss_cls: 0.1871  s0.acc: 94.4336  s0.loss_bbox: 0.2634  s0.loss_mask: 0.2419  s1.loss_cls: 0.0837  s1.acc: 95.6479  s1.loss_bbox: 0.1188  s1.loss_mask: 0.1150  s2.loss_cls: 0.0397  s2.acc: 95.3557  s2.loss_bbox: 0.0482  s2.loss_mask: 0.0540
2024/02/24 08:55:53 - mmengine - INFO - Exp name: cascade_mask_rcnn_swin_tiny_patch4_window7_mstrain_480-800_giou_4conv1f_adamw_3x_coco_20240224_074830
2024/02/24 08:56:07 - mmengine - INFO - Epoch(train) [35][5800/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:41:41  time: 0.6922  data_time: 0.0261  memory: 9936  loss: 1.1998  loss_rpn_cls: 0.0376  loss_rpn_bbox: 0.0285  s0.loss_cls: 0.1976  s0.acc: 96.2891  s0.loss_bbox: 0.2565  s0.loss_mask: 0.2315  s1.loss_cls: 0.0822  s1.acc: 97.3633  s1.loss_bbox: 0.1156  s1.loss_mask: 0.1134  s2.loss_cls: 0.0389  s2.acc: 96.3867  s2.loss_bbox: 0.0454  s2.loss_mask: 0.0526
2024/02/24 08:56:41 - mmengine - INFO - Epoch(train) [35][5850/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:41:06  time: 0.6771  data_time: 0.0239  memory: 9746  loss: 1.1644  loss_rpn_cls: 0.0307  loss_rpn_bbox: 0.0240  s0.loss_cls: 0.1896  s0.acc: 90.5273  s0.loss_bbox: 0.2432  s0.loss_mask: 0.2359  s1.loss_cls: 0.0834  s1.acc: 92.0276  s1.loss_bbox: 0.1085  s1.loss_mask: 0.1138  s2.loss_cls: 0.0399  s2.acc: 89.9804  s2.loss_bbox: 0.0428  s2.loss_mask: 0.0526
2024/02/24 08:57:14 - mmengine - INFO - Epoch(train) [35][5900/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:40:30  time: 0.6770  data_time: 0.0267  memory: 9736  loss: 1.2013  loss_rpn_cls: 0.0393  loss_rpn_bbox: 0.0252  s0.loss_cls: 0.1813  s0.acc: 90.3320  s0.loss_bbox: 0.2657  s0.loss_mask: 0.2371  s1.loss_cls: 0.0834  s1.acc: 91.3086  s1.loss_bbox: 0.1184  s1.loss_mask: 0.1142  s2.loss_cls: 0.0389  s2.acc: 92.7734  s2.loss_bbox: 0.0458  s2.loss_mask: 0.0520
2024/02/24 08:57:49 - mmengine - INFO - Epoch(train) [35][5950/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:39:56  time: 0.6847  data_time: 0.0285  memory: 9652  loss: 1.2225  loss_rpn_cls: 0.0429  loss_rpn_bbox: 0.0310  s0.loss_cls: 0.1986  s0.acc: 93.7500  s0.loss_bbox: 0.2673  s0.loss_mask: 0.2328  s1.loss_cls: 0.0830  s1.acc: 94.1406  s1.loss_bbox: 0.1170  s1.loss_mask: 0.1114  s2.loss_cls: 0.0399  s2.acc: 95.3125  s2.loss_bbox: 0.0463  s2.loss_mask: 0.0524
2024/02/24 08:58:23 - mmengine - INFO - Epoch(train) [35][6000/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:39:21  time: 0.6919  data_time: 0.0281  memory: 9778  loss: 1.1041  loss_rpn_cls: 0.0306  loss_rpn_bbox: 0.0259  s0.loss_cls: 0.1770  s0.acc: 97.6562  s0.loss_bbox: 0.2335  s0.loss_mask: 0.2168  s1.loss_cls: 0.0784  s1.acc: 98.2422  s1.loss_bbox: 0.1058  s1.loss_mask: 0.1052  s2.loss_cls: 0.0377  s2.acc: 97.9492  s2.loss_bbox: 0.0436  s2.loss_mask: 0.0496
2024/02/24 08:58:57 - mmengine - INFO - Epoch(train) [35][6050/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:38:47  time: 0.6814  data_time: 0.0290  memory: 9543  loss: 1.2546  loss_rpn_cls: 0.0424  loss_rpn_bbox: 0.0310  s0.loss_cls: 0.1947  s0.acc: 90.1367  s0.loss_bbox: 0.2707  s0.loss_mask: 0.2526  s1.loss_cls: 0.0856  s1.acc: 92.0000  s1.loss_bbox: 0.1161  s1.loss_mask: 0.1213  s2.loss_cls: 0.0396  s2.acc: 92.0683  s2.loss_bbox: 0.0442  s2.loss_mask: 0.0565
2024/02/24 08:59:32 - mmengine - INFO - Epoch(train) [35][6100/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:38:12  time: 0.6867  data_time: 0.0257  memory: 10235  loss: 1.2190  loss_rpn_cls: 0.0330  loss_rpn_bbox: 0.0293  s0.loss_cls: 0.1999  s0.acc: 89.2578  s0.loss_bbox: 0.2576  s0.loss_mask: 0.2398  s1.loss_cls: 0.0895  s1.acc: 87.6349  s1.loss_bbox: 0.1137  s1.loss_mask: 0.1167  s2.loss_cls: 0.0437  s2.acc: 86.5554  s2.loss_bbox: 0.0436  s2.loss_mask: 0.0522
2024/02/24 09:00:06 - mmengine - INFO - Epoch(train) [35][6150/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:37:37  time: 0.6778  data_time: 0.0261  memory: 9582  loss: 1.2554  loss_rpn_cls: 0.0465  loss_rpn_bbox: 0.0321  s0.loss_cls: 0.1989  s0.acc: 85.9375  s0.loss_bbox: 0.2659  s0.loss_mask: 0.2457  s1.loss_cls: 0.0919  s1.acc: 84.6540  s1.loss_bbox: 0.1143  s1.loss_mask: 0.1188  s2.loss_cls: 0.0431  s2.acc: 84.4845  s2.loss_bbox: 0.0441  s2.loss_mask: 0.0542
2024/02/24 09:00:40 - mmengine - INFO - Epoch(train) [35][6200/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:37:02  time: 0.6787  data_time: 0.0257  memory: 9654  loss: 1.1646  loss_rpn_cls: 0.0404  loss_rpn_bbox: 0.0258  s0.loss_cls: 0.1770  s0.acc: 95.8984  s0.loss_bbox: 0.2424  s0.loss_mask: 0.2405  s1.loss_cls: 0.0804  s1.acc: 94.7266  s1.loss_bbox: 0.1079  s1.loss_mask: 0.1171  s2.loss_cls: 0.0369  s2.acc: 94.6289  s2.loss_bbox: 0.0422  s2.loss_mask: 0.0541
2024/02/24 09:01:14 - mmengine - INFO - Epoch(train) [35][6250/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:36:27  time: 0.6902  data_time: 0.0300  memory: 9669  loss: 1.2063  loss_rpn_cls: 0.0432  loss_rpn_bbox: 0.0307  s0.loss_cls: 0.1988  s0.acc: 91.8945  s0.loss_bbox: 0.2509  s0.loss_mask: 0.2325  s1.loss_cls: 0.0858  s1.acc: 93.7313  s1.loss_bbox: 0.1123  s1.loss_mask: 0.1131  s2.loss_cls: 0.0413  s2.acc: 93.7813  s2.loss_bbox: 0.0446  s2.loss_mask: 0.0531
2024/02/24 09:01:49 - mmengine - INFO - Epoch(train) [35][6300/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:35:53  time: 0.6879  data_time: 0.0289  memory: 9421  loss: 1.2046  loss_rpn_cls: 0.0406  loss_rpn_bbox: 0.0259  s0.loss_cls: 0.1844  s0.acc: 95.7031  s0.loss_bbox: 0.2588  s0.loss_mask: 0.2421  s1.loss_cls: 0.0821  s1.acc: 95.8457  s1.loss_bbox: 0.1154  s1.loss_mask: 0.1168  s2.loss_cls: 0.0394  s2.acc: 97.0030  s2.loss_bbox: 0.0442  s2.loss_mask: 0.0550
2024/02/24 09:02:23 - mmengine - INFO - Epoch(train) [35][6350/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:35:18  time: 0.6779  data_time: 0.0257  memory: 10984  loss: 1.1721  loss_rpn_cls: 0.0353  loss_rpn_bbox: 0.0288  s0.loss_cls: 0.1806  s0.acc: 97.4609  s0.loss_bbox: 0.2542  s0.loss_mask: 0.2293  s1.loss_cls: 0.0819  s1.acc: 96.9727  s1.loss_bbox: 0.1140  s1.loss_mask: 0.1114  s2.loss_cls: 0.0374  s2.acc: 96.1914  s2.loss_bbox: 0.0457  s2.loss_mask: 0.0535
2024/02/24 09:02:57 - mmengine - INFO - Epoch(train) [35][6400/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:34:44  time: 0.6871  data_time: 0.0255  memory: 9205  loss: 1.2405  loss_rpn_cls: 0.0466  loss_rpn_bbox: 0.0263  s0.loss_cls: 0.1935  s0.acc: 95.9961  s0.loss_bbox: 0.2532  s0.loss_mask: 0.2478  s1.loss_cls: 0.0912  s1.acc: 96.4844  s1.loss_bbox: 0.1145  s1.loss_mask: 0.1227  s2.loss_cls: 0.0438  s2.acc: 97.1680  s2.loss_bbox: 0.0435  s2.loss_mask: 0.0575
2024/02/24 09:03:31 - mmengine - INFO - Epoch(train) [35][6450/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:34:09  time: 0.6826  data_time: 0.0245  memory: 9246  loss: 1.1195  loss_rpn_cls: 0.0365  loss_rpn_bbox: 0.0242  s0.loss_cls: 0.1743  s0.acc: 90.0391  s0.loss_bbox: 0.2376  s0.loss_mask: 0.2253  s1.loss_cls: 0.0758  s1.acc: 90.3674  s1.loss_bbox: 0.1079  s1.loss_mask: 0.1104  s2.loss_cls: 0.0365  s2.acc: 91.9643  s2.loss_bbox: 0.0407  s2.loss_mask: 0.0503
2024/02/24 09:04:05 - mmengine - INFO - Epoch(train) [35][6500/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:33:34  time: 0.6852  data_time: 0.0264  memory: 9750  loss: 1.2088  loss_rpn_cls: 0.0443  loss_rpn_bbox: 0.0291  s0.loss_cls: 0.1938  s0.acc: 84.7656  s0.loss_bbox: 0.2554  s0.loss_mask: 0.2409  s1.loss_cls: 0.0837  s1.acc: 86.9307  s1.loss_bbox: 0.1094  s1.loss_mask: 0.1147  s2.loss_cls: 0.0406  s2.acc: 86.9951  s2.loss_bbox: 0.0435  s2.loss_mask: 0.0535
2024/02/24 09:04:40 - mmengine - INFO - Epoch(train) [35][6550/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:33:00  time: 0.6855  data_time: 0.0266  memory: 9487  loss: 1.0963  loss_rpn_cls: 0.0297  loss_rpn_bbox: 0.0240  s0.loss_cls: 0.1746  s0.acc: 96.8750  s0.loss_bbox: 0.2262  s0.loss_mask: 0.2194  s1.loss_cls: 0.0798  s1.acc: 99.0234  s1.loss_bbox: 0.1031  s1.loss_mask: 0.1084  s2.loss_cls: 0.0388  s2.acc: 98.2422  s2.loss_bbox: 0.0409  s2.loss_mask: 0.0513
2024/02/24 09:05:14 - mmengine - INFO - Epoch(train) [35][6600/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:32:25  time: 0.6816  data_time: 0.0241  memory: 9142  loss: 1.0856  loss_rpn_cls: 0.0417  loss_rpn_bbox: 0.0272  s0.loss_cls: 0.1570  s0.acc: 98.2422  s0.loss_bbox: 0.2250  s0.loss_mask: 0.2226  s1.loss_cls: 0.0705  s1.acc: 98.7305  s1.loss_bbox: 0.1029  s1.loss_mask: 0.1112  s2.loss_cls: 0.0339  s2.acc: 98.4375  s2.loss_bbox: 0.0411  s2.loss_mask: 0.0525
2024/02/24 09:05:48 - mmengine - INFO - Epoch(train) [35][6650/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:31:50  time: 0.6893  data_time: 0.0250  memory: 9527  loss: 1.0957  loss_rpn_cls: 0.0305  loss_rpn_bbox: 0.0264  s0.loss_cls: 0.1523  s0.acc: 94.8242  s0.loss_bbox: 0.2275  s0.loss_mask: 0.2372  s1.loss_cls: 0.0679  s1.acc: 96.3074  s1.loss_bbox: 0.1062  s1.loss_mask: 0.1167  s2.loss_cls: 0.0330  s2.acc: 95.3141  s2.loss_bbox: 0.0419  s2.loss_mask: 0.0562
2024/02/24 09:06:23 - mmengine - INFO - Epoch(train) [35][6700/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:31:16  time: 0.6952  data_time: 0.0266  memory: 9844  loss: 1.1889  loss_rpn_cls: 0.0374  loss_rpn_bbox: 0.0261  s0.loss_cls: 0.1872  s0.acc: 94.5312  s0.loss_bbox: 0.2494  s0.loss_mask: 0.2403  s1.loss_cls: 0.0844  s1.acc: 93.8477  s1.loss_bbox: 0.1110  s1.loss_mask: 0.1168  s2.loss_cls: 0.0382  s2.acc: 94.7266  s2.loss_bbox: 0.0435  s2.loss_mask: 0.0547
2024/02/24 09:06:58 - mmengine - INFO - Epoch(train) [35][6750/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:30:42  time: 0.6878  data_time: 0.0243  memory: 9444  loss: 1.0842  loss_rpn_cls: 0.0369  loss_rpn_bbox: 0.0278  s0.loss_cls: 0.1698  s0.acc: 86.3281  s0.loss_bbox: 0.2156  s0.loss_mask: 0.2260  s1.loss_cls: 0.0761  s1.acc: 85.1929  s1.loss_bbox: 0.0982  s1.loss_mask: 0.1096  s2.loss_cls: 0.0353  s2.acc: 84.7826  s2.loss_bbox: 0.0380  s2.loss_mask: 0.0508
2024/02/24 09:07:18 - mmengine - INFO - Exp name: cascade_mask_rcnn_swin_tiny_patch4_window7_mstrain_480-800_giou_4conv1f_adamw_3x_coco_20240224_074830
2024/02/24 09:07:32 - mmengine - INFO - Epoch(train) [35][6800/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:30:07  time: 0.6833  data_time: 0.0248  memory: 9815  loss: 1.2108  loss_rpn_cls: 0.0442  loss_rpn_bbox: 0.0293  s0.loss_cls: 0.1927  s0.acc: 98.1445  s0.loss_bbox: 0.2593  s0.loss_mask: 0.2339  s1.loss_cls: 0.0866  s1.acc: 96.0938  s1.loss_bbox: 0.1133  s1.loss_mask: 0.1141  s2.loss_cls: 0.0404  s2.acc: 94.7266  s2.loss_bbox: 0.0438  s2.loss_mask: 0.0530
2024/02/24 09:08:06 - mmengine - INFO - Epoch(train) [35][6850/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:29:33  time: 0.6877  data_time: 0.0240  memory: 9342  loss: 1.1547  loss_rpn_cls: 0.0408  loss_rpn_bbox: 0.0272  s0.loss_cls: 0.1716  s0.acc: 93.8477  s0.loss_bbox: 0.2389  s0.loss_mask: 0.2393  s1.loss_cls: 0.0765  s1.acc: 93.1641  s1.loss_bbox: 0.1099  s1.loss_mask: 0.1151  s2.loss_cls: 0.0365  s2.acc: 94.7266  s2.loss_bbox: 0.0448  s2.loss_mask: 0.0541
2024/02/24 09:08:41 - mmengine - INFO - Epoch(train) [35][6900/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:28:59  time: 0.6924  data_time: 0.0265  memory: 9986  loss: 1.2096  loss_rpn_cls: 0.0413  loss_rpn_bbox: 0.0283  s0.loss_cls: 0.1963  s0.acc: 91.2109  s0.loss_bbox: 0.2607  s0.loss_mask: 0.2285  s1.loss_cls: 0.0869  s1.acc: 90.2390  s1.loss_bbox: 0.1171  s1.loss_mask: 0.1099  s2.loss_cls: 0.0413  s2.acc: 89.6414  s2.loss_bbox: 0.0478  s2.loss_mask: 0.0516
2024/02/24 09:09:15 - mmengine - INFO - Epoch(train) [35][6950/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:28:24  time: 0.6849  data_time: 0.0263  memory: 9636  loss: 1.1883  loss_rpn_cls: 0.0360  loss_rpn_bbox: 0.0260  s0.loss_cls: 0.1882  s0.acc: 88.2812  s0.loss_bbox: 0.2524  s0.loss_mask: 0.2352  s1.loss_cls: 0.0825  s1.acc: 91.6585  s1.loss_bbox: 0.1149  s1.loss_mask: 0.1161  s2.loss_cls: 0.0389  s2.acc: 91.1504  s2.loss_bbox: 0.0446  s2.loss_mask: 0.0535
2024/02/24 09:09:49 - mmengine - INFO - Epoch(train) [35][7000/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:27:50  time: 0.6851  data_time: 0.0251  memory: 9210  loss: 1.2050  loss_rpn_cls: 0.0420  loss_rpn_bbox: 0.0252  s0.loss_cls: 0.2080  s0.acc: 93.4570  s0.loss_bbox: 0.2529  s0.loss_mask: 0.2251  s1.loss_cls: 0.0924  s1.acc: 93.7500  s1.loss_bbox: 0.1123  s1.loss_mask: 0.1098  s2.loss_cls: 0.0430  s2.acc: 91.4062  s2.loss_bbox: 0.0429  s2.loss_mask: 0.0513
2024/02/24 09:10:24 - mmengine - INFO - Epoch(train) [35][7050/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:27:15  time: 0.6899  data_time: 0.0237  memory: 9383  loss: 1.1747  loss_rpn_cls: 0.0402  loss_rpn_bbox: 0.0224  s0.loss_cls: 0.1765  s0.acc: 96.9727  s0.loss_bbox: 0.2600  s0.loss_mask: 0.2289  s1.loss_cls: 0.0798  s1.acc: 97.9492  s1.loss_bbox: 0.1142  s1.loss_mask: 0.1146  s2.loss_cls: 0.0380  s2.acc: 97.9492  s2.loss_bbox: 0.0454  s2.loss_mask: 0.0546
2024/02/24 09:10:58 - mmengine - INFO - Epoch(train) [35][7100/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:26:41  time: 0.6795  data_time: 0.0267  memory: 9829  loss: 1.1670  loss_rpn_cls: 0.0363  loss_rpn_bbox: 0.0291  s0.loss_cls: 0.1833  s0.acc: 88.5742  s0.loss_bbox: 0.2322  s0.loss_mask: 0.2423  s1.loss_cls: 0.0812  s1.acc: 89.5219  s1.loss_bbox: 0.1059  s1.loss_mask: 0.1205  s2.loss_cls: 0.0375  s2.acc: 90.8907  s2.loss_bbox: 0.0425  s2.loss_mask: 0.0563
2024/02/24 09:11:32 - mmengine - INFO - Epoch(train) [35][7150/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:26:06  time: 0.6865  data_time: 0.0251  memory: 9652  loss: 1.0556  loss_rpn_cls: 0.0391  loss_rpn_bbox: 0.0224  s0.loss_cls: 0.1631  s0.acc: 96.4844  s0.loss_bbox: 0.2065  s0.loss_mask: 0.2223  s1.loss_cls: 0.0691  s1.acc: 95.8008  s1.loss_bbox: 0.0958  s1.loss_mask: 0.1128  s2.loss_cls: 0.0333  s2.acc: 93.5547  s2.loss_bbox: 0.0382  s2.loss_mask: 0.0530
2024/02/24 09:12:07 - mmengine - INFO - Epoch(train) [35][7200/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:25:32  time: 0.6925  data_time: 0.0247  memory: 9254  loss: 1.1738  loss_rpn_cls: 0.0360  loss_rpn_bbox: 0.0235  s0.loss_cls: 0.1703  s0.acc: 97.5586  s0.loss_bbox: 0.2501  s0.loss_mask: 0.2456  s1.loss_cls: 0.0799  s1.acc: 96.6292  s1.loss_bbox: 0.1122  s1.loss_mask: 0.1178  s2.loss_cls: 0.0389  s2.acc: 97.5104  s2.loss_bbox: 0.0441  s2.loss_mask: 0.0554
2024/02/24 09:12:41 - mmengine - INFO - Epoch(train) [35][7250/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:24:57  time: 0.6838  data_time: 0.0275  memory: 9894  loss: 1.2090  loss_rpn_cls: 0.0467  loss_rpn_bbox: 0.0284  s0.loss_cls: 0.1931  s0.acc: 98.4375  s0.loss_bbox: 0.2518  s0.loss_mask: 0.2385  s1.loss_cls: 0.0856  s1.acc: 98.6328  s1.loss_bbox: 0.1116  s1.loss_mask: 0.1160  s2.loss_cls: 0.0392  s2.acc: 98.3398  s2.loss_bbox: 0.0439  s2.loss_mask: 0.0544
2024/02/24 09:13:15 - mmengine - INFO - Epoch(train) [35][7300/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:24:23  time: 0.6804  data_time: 0.0269  memory: 9659  loss: 1.1489  loss_rpn_cls: 0.0405  loss_rpn_bbox: 0.0301  s0.loss_cls: 0.1697  s0.acc: 90.6250  s0.loss_bbox: 0.2400  s0.loss_mask: 0.2354  s1.loss_cls: 0.0750  s1.acc: 90.3960  s1.loss_bbox: 0.1090  s1.loss_mask: 0.1156  s2.loss_cls: 0.0366  s2.acc: 91.3947  s2.loss_bbox: 0.0431  s2.loss_mask: 0.0538
2024/02/24 09:13:35 - mmengine - INFO - Exp name: cascade_mask_rcnn_swin_tiny_patch4_window7_mstrain_480-800_giou_4conv1f_adamw_3x_coco_20240224_074830
2024/02/24 09:13:35 - mmengine - INFO - Saving checkpoint at 35 epochs
2024/02/24 09:13:50 - mmengine - INFO - Epoch(val) [35][ 50/625]    eta: 0:01:56  time: 0.2029  data_time: 0.0301  memory: 9763  
2024/02/24 09:14:00 - mmengine - INFO - Epoch(val) [35][100/625]    eta: 0:01:45  time: 0.2003  data_time: 0.0286  memory: 2669  
2024/02/24 09:14:10 - mmengine - INFO - Epoch(val) [35][150/625]    eta: 0:01:34  time: 0.1927  data_time: 0.0242  memory: 2665  
2024/02/24 09:14:19 - mmengine - INFO - Epoch(val) [35][200/625]    eta: 0:01:23  time: 0.1859  data_time: 0.0201  memory: 2664  
2024/02/24 09:14:29 - mmengine - INFO - Epoch(val) [35][250/625]    eta: 0:01:13  time: 0.1947  data_time: 0.0264  memory: 2669  
2024/02/24 09:14:39 - mmengine - INFO - Epoch(val) [35][300/625]    eta: 0:01:03  time: 0.1906  data_time: 0.0246  memory: 2665  
2024/02/24 09:14:48 - mmengine - INFO - Epoch(val) [35][350/625]    eta: 0:00:53  time: 0.1947  data_time: 0.0263  memory: 2665  
2024/02/24 09:14:58 - mmengine - INFO - Epoch(val) [35][400/625]    eta: 0:00:43  time: 0.1938  data_time: 0.0253  memory: 2669  
2024/02/24 09:15:08 - mmengine - INFO - Epoch(val) [35][450/625]    eta: 0:00:33  time: 0.1921  data_time: 0.0230  memory: 2669  
2024/02/24 09:15:17 - mmengine - INFO - Epoch(val) [35][500/625]    eta: 0:00:24  time: 0.1956  data_time: 0.0264  memory: 2665  
2024/02/24 09:15:27 - mmengine - INFO - Epoch(val) [35][550/625]    eta: 0:00:14  time: 0.2008  data_time: 0.0274  memory: 2669  
2024/02/24 09:15:37 - mmengine - INFO - Epoch(val) [35][600/625]    eta: 0:00:04  time: 0.1936  data_time: 0.0232  memory: 2665  
2024/02/24 09:15:54 - mmengine - INFO - Evaluating bbox...
2024/02/24 09:16:44 - mmengine - INFO - bbox_mAP_copypaste: 0.446 0.631 0.487 0.285 0.475 0.585
2024/02/24 09:16:44 - mmengine - INFO - Evaluating segm...
2024/02/24 09:17:41 - mmengine - INFO - segm_mAP_copypaste: 0.389 0.602 0.418 0.208 0.415 0.567
2024/02/24 09:17:41 - mmengine - INFO - Epoch(val) [35][625/625]    coco/bbox_mAP: 0.4460  coco/bbox_mAP_50: 0.6310  coco/bbox_mAP_75: 0.4870  coco/bbox_mAP_s: 0.2850  coco/bbox_mAP_m: 0.4750  coco/bbox_mAP_l: 0.5850  coco/segm_mAP: 0.3890  coco/segm_mAP_50: 0.6020  coco/segm_mAP_75: 0.4180  coco/segm_mAP_s: 0.2080  coco/segm_mAP_m: 0.4150  coco/segm_mAP_l: 0.5670  data_time: 0.0252  time: 0.1943
2024/02/24 09:18:16 - mmengine - INFO - Epoch(train) [36][  50/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:23:27  time: 0.6957  data_time: 0.0278  memory: 9132  loss: 1.1881  loss_rpn_cls: 0.0441  loss_rpn_bbox: 0.0256  s0.loss_cls: 0.1913  s0.acc: 97.4609  s0.loss_bbox: 0.2367  s0.loss_mask: 0.2404  s1.loss_cls: 0.0873  s1.acc: 97.2656  s1.loss_bbox: 0.1072  s1.loss_mask: 0.1169  s2.loss_cls: 0.0423  s2.acc: 96.3867  s2.loss_bbox: 0.0417  s2.loss_mask: 0.0546
2024/02/24 09:18:51 - mmengine - INFO - Epoch(train) [36][ 100/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:22:53  time: 0.6903  data_time: 0.0274  memory: 11031  loss: 1.2637  loss_rpn_cls: 0.0470  loss_rpn_bbox: 0.0275  s0.loss_cls: 0.2127  s0.acc: 81.3477  s0.loss_bbox: 0.2565  s0.loss_mask: 0.2461  s1.loss_cls: 0.0969  s1.acc: 79.9805  s1.loss_bbox: 0.1145  s1.loss_mask: 0.1189  s2.loss_cls: 0.0446  s2.acc: 83.8867  s2.loss_bbox: 0.0436  s2.loss_mask: 0.0554
2024/02/24 09:19:25 - mmengine - INFO - Epoch(train) [36][ 150/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:22:19  time: 0.6982  data_time: 0.0266  memory: 9686  loss: 1.1941  loss_rpn_cls: 0.0383  loss_rpn_bbox: 0.0278  s0.loss_cls: 0.1776  s0.acc: 91.0156  s0.loss_bbox: 0.2426  s0.loss_mask: 0.2606  s1.loss_cls: 0.0767  s1.acc: 91.4767  s1.loss_bbox: 0.1056  s1.loss_mask: 0.1262  s2.loss_cls: 0.0367  s2.acc: 91.9960  s2.loss_bbox: 0.0424  s2.loss_mask: 0.0596
2024/02/24 09:19:59 - mmengine - INFO - Epoch(train) [36][ 200/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:21:44  time: 0.6785  data_time: 0.0271  memory: 9578  loss: 1.2662  loss_rpn_cls: 0.0447  loss_rpn_bbox: 0.0305  s0.loss_cls: 0.2164  s0.acc: 91.1133  s0.loss_bbox: 0.2606  s0.loss_mask: 0.2389  s1.loss_cls: 0.0995  s1.acc: 93.7751  s1.loss_bbox: 0.1161  s1.loss_mask: 0.1152  s2.loss_cls: 0.0456  s2.acc: 94.1591  s2.loss_bbox: 0.0449  s2.loss_mask: 0.0539
2024/02/24 09:20:34 - mmengine - INFO - Epoch(train) [36][ 250/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:21:10  time: 0.6835  data_time: 0.0270  memory: 9480  loss: 1.1172  loss_rpn_cls: 0.0332  loss_rpn_bbox: 0.0259  s0.loss_cls: 0.1693  s0.acc: 97.7539  s0.loss_bbox: 0.2399  s0.loss_mask: 0.2311  s1.loss_cls: 0.0748  s1.acc: 97.7539  s1.loss_bbox: 0.1053  s1.loss_mask: 0.1093  s2.loss_cls: 0.0349  s2.acc: 97.5586  s2.loss_bbox: 0.0430  s2.loss_mask: 0.0507
2024/02/24 09:21:07 - mmengine - INFO - Epoch(train) [36][ 300/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:20:35  time: 0.6750  data_time: 0.0278  memory: 9775  loss: 1.1241  loss_rpn_cls: 0.0333  loss_rpn_bbox: 0.0265  s0.loss_cls: 0.1832  s0.acc: 85.0586  s0.loss_bbox: 0.2376  s0.loss_mask: 0.2255  s1.loss_cls: 0.0770  s1.acc: 88.3603  s1.loss_bbox: 0.1047  s1.loss_mask: 0.1089  s2.loss_cls: 0.0351  s2.acc: 90.1822  s2.loss_bbox: 0.0413  s2.loss_mask: 0.0509
2024/02/24 09:21:41 - mmengine - INFO - Epoch(train) [36][ 350/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:20:00  time: 0.6736  data_time: 0.0288  memory: 10012  loss: 1.2255  loss_rpn_cls: 0.0488  loss_rpn_bbox: 0.0316  s0.loss_cls: 0.1883  s0.acc: 95.7031  s0.loss_bbox: 0.2563  s0.loss_mask: 0.2434  s1.loss_cls: 0.0812  s1.acc: 95.1172  s1.loss_bbox: 0.1163  s1.loss_mask: 0.1182  s2.loss_cls: 0.0388  s2.acc: 97.0703  s2.loss_bbox: 0.0475  s2.loss_mask: 0.0552
2024/02/24 09:22:16 - mmengine - INFO - Epoch(train) [36][ 400/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:19:25  time: 0.6872  data_time: 0.0274  memory: 9831  loss: 1.2177  loss_rpn_cls: 0.0400  loss_rpn_bbox: 0.0312  s0.loss_cls: 0.1768  s0.acc: 83.5938  s0.loss_bbox: 0.2536  s0.loss_mask: 0.2603  s1.loss_cls: 0.0805  s1.acc: 84.1797  s1.loss_bbox: 0.1110  s1.loss_mask: 0.1256  s2.loss_cls: 0.0378  s2.acc: 87.5000  s2.loss_bbox: 0.0427  s2.loss_mask: 0.0581
2024/02/24 09:22:50 - mmengine - INFO - Exp name: cascade_mask_rcnn_swin_tiny_patch4_window7_mstrain_480-800_giou_4conv1f_adamw_3x_coco_20240224_074830
2024/02/24 09:22:50 - mmengine - INFO - Epoch(train) [36][ 450/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:18:51  time: 0.6902  data_time: 0.0262  memory: 9705  loss: 1.1379  loss_rpn_cls: 0.0375  loss_rpn_bbox: 0.0283  s0.loss_cls: 0.1741  s0.acc: 92.8711  s0.loss_bbox: 0.2394  s0.loss_mask: 0.2300  s1.loss_cls: 0.0752  s1.acc: 95.3629  s1.loss_bbox: 0.1072  s1.loss_mask: 0.1138  s2.loss_cls: 0.0355  s2.acc: 95.3441  s2.loss_bbox: 0.0432  s2.loss_mask: 0.0538
2024/02/24 09:23:24 - mmengine - INFO - Epoch(train) [36][ 500/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:18:16  time: 0.6795  data_time: 0.0260  memory: 9731  loss: 1.2784  loss_rpn_cls: 0.0430  loss_rpn_bbox: 0.0312  s0.loss_cls: 0.1972  s0.acc: 94.8242  s0.loss_bbox: 0.2722  s0.loss_mask: 0.2592  s1.loss_cls: 0.0892  s1.acc: 93.3598  s1.loss_bbox: 0.1235  s1.loss_mask: 0.1211  s2.loss_cls: 0.0410  s2.acc: 92.3611  s2.loss_bbox: 0.0459  s2.loss_mask: 0.0547
2024/02/24 09:23:58 - mmengine - INFO - Epoch(train) [36][ 550/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:17:42  time: 0.6802  data_time: 0.0245  memory: 9555  loss: 1.1596  loss_rpn_cls: 0.0319  loss_rpn_bbox: 0.0288  s0.loss_cls: 0.1851  s0.acc: 92.8711  s0.loss_bbox: 0.2412  s0.loss_mask: 0.2321  s1.loss_cls: 0.0832  s1.acc: 93.8175  s1.loss_bbox: 0.1094  s1.loss_mask: 0.1138  s2.loss_cls: 0.0381  s2.acc: 96.4706  s2.loss_bbox: 0.0431  s2.loss_mask: 0.0529
2024/02/24 09:24:32 - mmengine - INFO - Epoch(train) [36][ 600/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:17:07  time: 0.6821  data_time: 0.0247  memory: 8925  loss: 1.2477  loss_rpn_cls: 0.0433  loss_rpn_bbox: 0.0301  s0.loss_cls: 0.2002  s0.acc: 91.7969  s0.loss_bbox: 0.2678  s0.loss_mask: 0.2380  s1.loss_cls: 0.0911  s1.acc: 93.8570  s1.loss_bbox: 0.1186  s1.loss_mask: 0.1154  s2.loss_cls: 0.0435  s2.acc: 96.3819  s2.loss_bbox: 0.0458  s2.loss_mask: 0.0539
2024/02/24 09:25:06 - mmengine - INFO - Epoch(train) [36][ 650/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:16:32  time: 0.6840  data_time: 0.0264  memory: 10099  loss: 1.2097  loss_rpn_cls: 0.0383  loss_rpn_bbox: 0.0275  s0.loss_cls: 0.1788  s0.acc: 90.0391  s0.loss_bbox: 0.2584  s0.loss_mask: 0.2565  s1.loss_cls: 0.0765  s1.acc: 90.0406  s1.loss_bbox: 0.1149  s1.loss_mask: 0.1209  s2.loss_cls: 0.0367  s2.acc: 92.8131  s2.loss_bbox: 0.0457  s2.loss_mask: 0.0555
2024/02/24 09:25:40 - mmengine - INFO - Epoch(train) [36][ 700/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:15:58  time: 0.6748  data_time: 0.0271  memory: 9724  loss: 1.1224  loss_rpn_cls: 0.0341  loss_rpn_bbox: 0.0260  s0.loss_cls: 0.1726  s0.acc: 99.4141  s0.loss_bbox: 0.2388  s0.loss_mask: 0.2307  s1.loss_cls: 0.0738  s1.acc: 99.8047  s1.loss_bbox: 0.1074  s1.loss_mask: 0.1114  s2.loss_cls: 0.0342  s2.acc: 99.4141  s2.loss_bbox: 0.0419  s2.loss_mask: 0.0515
2024/02/24 09:26:14 - mmengine - INFO - Epoch(train) [36][ 750/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:15:23  time: 0.6803  data_time: 0.0262  memory: 9603  loss: 1.1741  loss_rpn_cls: 0.0318  loss_rpn_bbox: 0.0276  s0.loss_cls: 0.1787  s0.acc: 97.5586  s0.loss_bbox: 0.2533  s0.loss_mask: 0.2352  s1.loss_cls: 0.0801  s1.acc: 97.0149  s1.loss_bbox: 0.1166  s1.loss_mask: 0.1131  s2.loss_cls: 0.0385  s2.acc: 96.4718  s2.loss_bbox: 0.0469  s2.loss_mask: 0.0524
2024/02/24 09:26:49 - mmengine - INFO - Epoch(train) [36][ 800/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:14:49  time: 0.6910  data_time: 0.0253  memory: 9193  loss: 1.0549  loss_rpn_cls: 0.0336  loss_rpn_bbox: 0.0219  s0.loss_cls: 0.1646  s0.acc: 97.4609  s0.loss_bbox: 0.2156  s0.loss_mask: 0.2138  s1.loss_cls: 0.0736  s1.acc: 96.4844  s1.loss_bbox: 0.1007  s1.loss_mask: 0.1046  s2.loss_cls: 0.0343  s2.acc: 96.5820  s2.loss_bbox: 0.0425  s2.loss_mask: 0.0498
2024/02/24 09:27:23 - mmengine - INFO - Epoch(train) [36][ 850/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:14:14  time: 0.6852  data_time: 0.0286  memory: 10116  loss: 1.1759  loss_rpn_cls: 0.0401  loss_rpn_bbox: 0.0271  s0.loss_cls: 0.1820  s0.acc: 96.4844  s0.loss_bbox: 0.2384  s0.loss_mask: 0.2494  s1.loss_cls: 0.0791  s1.acc: 97.1680  s1.loss_bbox: 0.1047  s1.loss_mask: 0.1218  s2.loss_cls: 0.0369  s2.acc: 97.3633  s2.loss_bbox: 0.0405  s2.loss_mask: 0.0560
2024/02/24 09:27:57 - mmengine - INFO - Epoch(train) [36][ 900/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:13:40  time: 0.6801  data_time: 0.0291  memory: 9465  loss: 1.2060  loss_rpn_cls: 0.0443  loss_rpn_bbox: 0.0303  s0.loss_cls: 0.1906  s0.acc: 94.4336  s0.loss_bbox: 0.2540  s0.loss_mask: 0.2363  s1.loss_cls: 0.0868  s1.acc: 93.1641  s1.loss_bbox: 0.1139  s1.loss_mask: 0.1127  s2.loss_cls: 0.0408  s2.acc: 94.0430  s2.loss_bbox: 0.0449  s2.loss_mask: 0.0513
2024/02/24 09:28:31 - mmengine - INFO - Epoch(train) [36][ 950/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:13:05  time: 0.6840  data_time: 0.0291  memory: 9703  loss: 1.2411  loss_rpn_cls: 0.0431  loss_rpn_bbox: 0.0305  s0.loss_cls: 0.2042  s0.acc: 91.1133  s0.loss_bbox: 0.2595  s0.loss_mask: 0.2391  s1.loss_cls: 0.0919  s1.acc: 92.9212  s1.loss_bbox: 0.1133  s1.loss_mask: 0.1166  s2.loss_cls: 0.0427  s2.acc: 94.7053  s2.loss_bbox: 0.0452  s2.loss_mask: 0.0550
2024/02/24 09:29:06 - mmengine - INFO - Epoch(train) [36][1000/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:12:31  time: 0.6871  data_time: 0.0279  memory: 10379  loss: 1.2534  loss_rpn_cls: 0.0435  loss_rpn_bbox: 0.0318  s0.loss_cls: 0.2025  s0.acc: 98.0469  s0.loss_bbox: 0.2582  s0.loss_mask: 0.2402  s1.loss_cls: 0.0921  s1.acc: 97.2656  s1.loss_bbox: 0.1193  s1.loss_mask: 0.1205  s2.loss_cls: 0.0430  s2.acc: 98.3398  s2.loss_bbox: 0.0465  s2.loss_mask: 0.0559
2024/02/24 09:29:40 - mmengine - INFO - Epoch(train) [36][1050/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:11:56  time: 0.6834  data_time: 0.0283  memory: 9204  loss: 1.1344  loss_rpn_cls: 0.0459  loss_rpn_bbox: 0.0281  s0.loss_cls: 0.1781  s0.acc: 94.8242  s0.loss_bbox: 0.2245  s0.loss_mask: 0.2360  s1.loss_cls: 0.0762  s1.acc: 95.1172  s1.loss_bbox: 0.1029  s1.loss_mask: 0.1133  s2.loss_cls: 0.0358  s2.acc: 97.3633  s2.loss_bbox: 0.0413  s2.loss_mask: 0.0524
2024/02/24 09:30:14 - mmengine - INFO - Epoch(train) [36][1100/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:11:22  time: 0.6864  data_time: 0.0290  memory: 9754  loss: 1.2264  loss_rpn_cls: 0.0420  loss_rpn_bbox: 0.0323  s0.loss_cls: 0.1843  s0.acc: 93.8477  s0.loss_bbox: 0.2553  s0.loss_mask: 0.2549  s1.loss_cls: 0.0844  s1.acc: 94.1406  s1.loss_bbox: 0.1133  s1.loss_mask: 0.1231  s2.loss_cls: 0.0398  s2.acc: 96.7773  s2.loss_bbox: 0.0424  s2.loss_mask: 0.0546
2024/02/24 09:30:49 - mmengine - INFO - Epoch(train) [36][1150/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:10:47  time: 0.6825  data_time: 0.0273  memory: 9032  loss: 1.1999  loss_rpn_cls: 0.0427  loss_rpn_bbox: 0.0315  s0.loss_cls: 0.1933  s0.acc: 94.7266  s0.loss_bbox: 0.2514  s0.loss_mask: 0.2382  s1.loss_cls: 0.0843  s1.acc: 94.5312  s1.loss_bbox: 0.1097  s1.loss_mask: 0.1142  s2.loss_cls: 0.0382  s2.acc: 96.2891  s2.loss_bbox: 0.0434  s2.loss_mask: 0.0531
2024/02/24 09:31:23 - mmengine - INFO - Epoch(train) [36][1200/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:10:13  time: 0.6866  data_time: 0.0294  memory: 9888  loss: 1.0320  loss_rpn_cls: 0.0339  loss_rpn_bbox: 0.0264  s0.loss_cls: 0.1574  s0.acc: 91.6016  s0.loss_bbox: 0.2032  s0.loss_mask: 0.2184  s1.loss_cls: 0.0719  s1.acc: 91.6917  s1.loss_bbox: 0.0921  s1.loss_mask: 0.1073  s2.loss_cls: 0.0337  s2.acc: 92.0080  s2.loss_bbox: 0.0376  s2.loss_mask: 0.0501
2024/02/24 09:31:57 - mmengine - INFO - Epoch(train) [36][1250/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:09:38  time: 0.6846  data_time: 0.0237  memory: 9215  loss: 1.1611  loss_rpn_cls: 0.0403  loss_rpn_bbox: 0.0273  s0.loss_cls: 0.1844  s0.acc: 92.8711  s0.loss_bbox: 0.2398  s0.loss_mask: 0.2349  s1.loss_cls: 0.0807  s1.acc: 94.3662  s1.loss_bbox: 0.1080  s1.loss_mask: 0.1125  s2.loss_cls: 0.0380  s2.acc: 93.6492  s2.loss_bbox: 0.0430  s2.loss_mask: 0.0522
2024/02/24 09:32:32 - mmengine - INFO - Epoch(train) [36][1300/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:09:04  time: 0.6864  data_time: 0.0225  memory: 9637  loss: 1.1985  loss_rpn_cls: 0.0292  loss_rpn_bbox: 0.0235  s0.loss_cls: 0.1997  s0.acc: 96.4844  s0.loss_bbox: 0.2448  s0.loss_mask: 0.2438  s1.loss_cls: 0.0877  s1.acc: 97.3633  s1.loss_bbox: 0.1101  s1.loss_mask: 0.1178  s2.loss_cls: 0.0434  s2.acc: 95.3125  s2.loss_bbox: 0.0435  s2.loss_mask: 0.0550
2024/02/24 09:33:06 - mmengine - INFO - Epoch(train) [36][1350/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:08:30  time: 0.6962  data_time: 0.0278  memory: 9815  loss: 1.2428  loss_rpn_cls: 0.0441  loss_rpn_bbox: 0.0307  s0.loss_cls: 0.1926  s0.acc: 95.4102  s0.loss_bbox: 0.2545  s0.loss_mask: 0.2542  s1.loss_cls: 0.0838  s1.acc: 95.9961  s1.loss_bbox: 0.1168  s1.loss_mask: 0.1220  s2.loss_cls: 0.0404  s2.acc: 95.9725  s2.loss_bbox: 0.0466  s2.loss_mask: 0.0572
2024/02/24 09:33:42 - mmengine - INFO - Epoch(train) [36][1400/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:07:56  time: 0.7036  data_time: 0.0263  memory: 9273  loss: 1.1748  loss_rpn_cls: 0.0433  loss_rpn_bbox: 0.0288  s0.loss_cls: 0.1793  s0.acc: 99.4141  s0.loss_bbox: 0.2437  s0.loss_mask: 0.2339  s1.loss_cls: 0.0806  s1.acc: 99.4141  s1.loss_bbox: 0.1112  s1.loss_mask: 0.1158  s2.loss_cls: 0.0387  s2.acc: 99.9023  s2.loss_bbox: 0.0455  s2.loss_mask: 0.0542
2024/02/24 09:34:16 - mmengine - INFO - Exp name: cascade_mask_rcnn_swin_tiny_patch4_window7_mstrain_480-800_giou_4conv1f_adamw_3x_coco_20240224_074830
2024/02/24 09:34:16 - mmengine - INFO - Epoch(train) [36][1450/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:07:22  time: 0.6924  data_time: 0.0244  memory: 9740  loss: 1.1832  loss_rpn_cls: 0.0376  loss_rpn_bbox: 0.0238  s0.loss_cls: 0.1889  s0.acc: 95.3125  s0.loss_bbox: 0.2503  s0.loss_mask: 0.2349  s1.loss_cls: 0.0840  s1.acc: 94.5598  s1.loss_bbox: 0.1116  s1.loss_mask: 0.1151  s2.loss_cls: 0.0379  s2.acc: 93.5452  s2.loss_bbox: 0.0447  s2.loss_mask: 0.0543
2024/02/24 09:34:50 - mmengine - INFO - Epoch(train) [36][1500/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:06:47  time: 0.6831  data_time: 0.0242  memory: 9855  loss: 1.1379  loss_rpn_cls: 0.0383  loss_rpn_bbox: 0.0238  s0.loss_cls: 0.1855  s0.acc: 96.8750  s0.loss_bbox: 0.2320  s0.loss_mask: 0.2241  s1.loss_cls: 0.0808  s1.acc: 98.7255  s1.loss_bbox: 0.1083  s1.loss_mask: 0.1113  s2.loss_cls: 0.0363  s2.acc: 98.3333  s2.loss_bbox: 0.0454  s2.loss_mask: 0.0522
2024/02/24 09:35:25 - mmengine - INFO - Epoch(train) [36][1550/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:06:13  time: 0.6846  data_time: 0.0302  memory: 9280  loss: 1.2851  loss_rpn_cls: 0.0475  loss_rpn_bbox: 0.0355  s0.loss_cls: 0.2048  s0.acc: 93.0664  s0.loss_bbox: 0.2656  s0.loss_mask: 0.2491  s1.loss_cls: 0.0912  s1.acc: 93.5547  s1.loss_bbox: 0.1213  s1.loss_mask: 0.1210  s2.loss_cls: 0.0432  s2.acc: 93.9901  s2.loss_bbox: 0.0491  s2.loss_mask: 0.0567
2024/02/24 09:35:59 - mmengine - INFO - Epoch(train) [36][1600/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:05:38  time: 0.6814  data_time: 0.0259  memory: 8828  loss: 1.1601  loss_rpn_cls: 0.0439  loss_rpn_bbox: 0.0248  s0.loss_cls: 0.1790  s0.acc: 92.8711  s0.loss_bbox: 0.2459  s0.loss_mask: 0.2329  s1.loss_cls: 0.0806  s1.acc: 93.9544  s1.loss_bbox: 0.1078  s1.loss_mask: 0.1137  s2.loss_cls: 0.0377  s2.acc: 96.4392  s2.loss_bbox: 0.0409  s2.loss_mask: 0.0527
2024/02/24 09:36:32 - mmengine - INFO - Epoch(train) [36][1650/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:05:04  time: 0.6740  data_time: 0.0236  memory: 9670  loss: 1.1224  loss_rpn_cls: 0.0329  loss_rpn_bbox: 0.0215  s0.loss_cls: 0.1785  s0.acc: 92.1875  s0.loss_bbox: 0.2234  s0.loss_mask: 0.2437  s1.loss_cls: 0.0758  s1.acc: 90.9180  s1.loss_bbox: 0.1003  s1.loss_mask: 0.1158  s2.loss_cls: 0.0368  s2.acc: 92.1875  s2.loss_bbox: 0.0396  s2.loss_mask: 0.0541
2024/02/24 09:37:06 - mmengine - INFO - Epoch(train) [36][1700/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:04:29  time: 0.6791  data_time: 0.0246  memory: 9721  loss: 1.0481  loss_rpn_cls: 0.0374  loss_rpn_bbox: 0.0282  s0.loss_cls: 0.1559  s0.acc: 96.1914  s0.loss_bbox: 0.2047  s0.loss_mask: 0.2234  s1.loss_cls: 0.0710  s1.acc: 95.9245  s1.loss_bbox: 0.0939  s1.loss_mask: 0.1113  s2.loss_cls: 0.0329  s2.acc: 96.9910  s2.loss_bbox: 0.0385  s2.loss_mask: 0.0508
2024/02/24 09:37:40 - mmengine - INFO - Epoch(train) [36][1750/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:03:54  time: 0.6772  data_time: 0.0260  memory: 9247  loss: 1.2170  loss_rpn_cls: 0.0352  loss_rpn_bbox: 0.0275  s0.loss_cls: 0.1859  s0.acc: 96.5820  s0.loss_bbox: 0.2591  s0.loss_mask: 0.2478  s1.loss_cls: 0.0861  s1.acc: 97.1680  s1.loss_bbox: 0.1151  s1.loss_mask: 0.1195  s2.loss_cls: 0.0404  s2.acc: 97.2656  s2.loss_bbox: 0.0446  s2.loss_mask: 0.0557
2024/02/24 09:38:15 - mmengine - INFO - Epoch(train) [36][1800/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:03:20  time: 0.6884  data_time: 0.0272  memory: 9352  loss: 1.0838  loss_rpn_cls: 0.0361  loss_rpn_bbox: 0.0233  s0.loss_cls: 0.1780  s0.acc: 97.7539  s0.loss_bbox: 0.2273  s0.loss_mask: 0.2113  s1.loss_cls: 0.0753  s1.acc: 97.4485  s1.loss_bbox: 0.1030  s1.loss_mask: 0.1044  s2.loss_cls: 0.0345  s2.acc: 96.6634  s2.loss_bbox: 0.0419  s2.loss_mask: 0.0488
2024/02/24 09:38:49 - mmengine - INFO - Epoch(train) [36][1850/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:02:45  time: 0.6846  data_time: 0.0279  memory: 9575  loss: 1.1175  loss_rpn_cls: 0.0299  loss_rpn_bbox: 0.0236  s0.loss_cls: 0.1725  s0.acc: 93.2617  s0.loss_bbox: 0.2335  s0.loss_mask: 0.2299  s1.loss_cls: 0.0774  s1.acc: 94.4336  s1.loss_bbox: 0.1065  s1.loss_mask: 0.1133  s2.loss_cls: 0.0353  s2.acc: 95.9961  s2.loss_bbox: 0.0426  s2.loss_mask: 0.0530
2024/02/24 09:39:23 - mmengine - INFO - Epoch(train) [36][1900/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:02:11  time: 0.6793  data_time: 0.0273  memory: 9631  loss: 1.2400  loss_rpn_cls: 0.0447  loss_rpn_bbox: 0.0299  s0.loss_cls: 0.1911  s0.acc: 92.9688  s0.loss_bbox: 0.2617  s0.loss_mask: 0.2486  s1.loss_cls: 0.0853  s1.acc: 95.0051  s1.loss_bbox: 0.1165  s1.loss_mask: 0.1194  s2.loss_cls: 0.0408  s2.acc: 95.9752  s2.loss_bbox: 0.0466  s2.loss_mask: 0.0554
2024/02/24 09:39:57 - mmengine - INFO - Epoch(train) [36][1950/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:01:36  time: 0.6821  data_time: 0.0257  memory: 8744  loss: 1.2150  loss_rpn_cls: 0.0448  loss_rpn_bbox: 0.0253  s0.loss_cls: 0.1882  s0.acc: 95.5078  s0.loss_bbox: 0.2602  s0.loss_mask: 0.2497  s1.loss_cls: 0.0800  s1.acc: 97.1680  s1.loss_bbox: 0.1136  s1.loss_mask: 0.1174  s2.loss_cls: 0.0365  s2.acc: 97.1680  s2.loss_bbox: 0.0445  s2.loss_mask: 0.0547
2024/02/24 09:40:31 - mmengine - INFO - Epoch(train) [36][2000/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:01:02  time: 0.6744  data_time: 0.0301  memory: 10132  loss: 1.2195  loss_rpn_cls: 0.0441  loss_rpn_bbox: 0.0297  s0.loss_cls: 0.1968  s0.acc: 85.1562  s0.loss_bbox: 0.2582  s0.loss_mask: 0.2400  s1.loss_cls: 0.0844  s1.acc: 87.7033  s1.loss_bbox: 0.1133  s1.loss_mask: 0.1158  s2.loss_cls: 0.0404  s2.acc: 88.1512  s2.loss_bbox: 0.0441  s2.loss_mask: 0.0528
2024/02/24 09:41:05 - mmengine - INFO - Epoch(train) [36][2050/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:00:27  time: 0.6832  data_time: 0.0308  memory: 9471  loss: 1.2779  loss_rpn_cls: 0.0434  loss_rpn_bbox: 0.0321  s0.loss_cls: 0.2110  s0.acc: 90.5273  s0.loss_bbox: 0.2764  s0.loss_mask: 0.2373  s1.loss_cls: 0.0932  s1.acc: 88.8672  s1.loss_bbox: 0.1222  s1.loss_mask: 0.1168  s2.loss_cls: 0.0430  s2.acc: 88.8672  s2.loss_bbox: 0.0477  s2.loss_mask: 0.0548
2024/02/24 09:41:39 - mmengine - INFO - Epoch(train) [36][2100/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:59:53  time: 0.6820  data_time: 0.0258  memory: 9362  loss: 1.1362  loss_rpn_cls: 0.0386  loss_rpn_bbox: 0.0239  s0.loss_cls: 0.1680  s0.acc: 95.6055  s0.loss_bbox: 0.2367  s0.loss_mask: 0.2372  s1.loss_cls: 0.0767  s1.acc: 95.4102  s1.loss_bbox: 0.1079  s1.loss_mask: 0.1141  s2.loss_cls: 0.0379  s2.acc: 95.2148  s2.loss_bbox: 0.0425  s2.loss_mask: 0.0527
2024/02/24 09:42:13 - mmengine - INFO - Epoch(train) [36][2150/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:59:18  time: 0.6828  data_time: 0.0277  memory: 9089  loss: 1.0440  loss_rpn_cls: 0.0325  loss_rpn_bbox: 0.0237  s0.loss_cls: 0.1632  s0.acc: 98.0469  s0.loss_bbox: 0.2074  s0.loss_mask: 0.2160  s1.loss_cls: 0.0721  s1.acc: 98.7867  s1.loss_bbox: 0.0972  s1.loss_mask: 0.1072  s2.loss_cls: 0.0335  s2.acc: 99.1845  s2.loss_bbox: 0.0405  s2.loss_mask: 0.0508
2024/02/24 09:42:47 - mmengine - INFO - Epoch(train) [36][2200/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:58:44  time: 0.6753  data_time: 0.0256  memory: 9657  loss: 1.0663  loss_rpn_cls: 0.0330  loss_rpn_bbox: 0.0254  s0.loss_cls: 0.1600  s0.acc: 87.9883  s0.loss_bbox: 0.2218  s0.loss_mask: 0.2166  s1.loss_cls: 0.0706  s1.acc: 90.6054  s1.loss_bbox: 0.1040  s1.loss_mask: 0.1086  s2.loss_cls: 0.0323  s2.acc: 91.2409  s2.loss_bbox: 0.0427  s2.loss_mask: 0.0512
2024/02/24 09:43:22 - mmengine - INFO - Epoch(train) [36][2250/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:58:09  time: 0.6848  data_time: 0.0254  memory: 9905  loss: 1.1918  loss_rpn_cls: 0.0336  loss_rpn_bbox: 0.0257  s0.loss_cls: 0.1838  s0.acc: 92.4805  s0.loss_bbox: 0.2520  s0.loss_mask: 0.2483  s1.loss_cls: 0.0787  s1.acc: 94.4099  s1.loss_bbox: 0.1147  s1.loss_mask: 0.1177  s2.loss_cls: 0.0384  s2.acc: 94.2768  s2.loss_bbox: 0.0437  s2.loss_mask: 0.0554
2024/02/24 09:43:56 - mmengine - INFO - Epoch(train) [36][2300/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:57:35  time: 0.6805  data_time: 0.0253  memory: 10202  loss: 1.2267  loss_rpn_cls: 0.0347  loss_rpn_bbox: 0.0259  s0.loss_cls: 0.1902  s0.acc: 95.0195  s0.loss_bbox: 0.2716  s0.loss_mask: 0.2405  s1.loss_cls: 0.0837  s1.acc: 96.7773  s1.loss_bbox: 0.1194  s1.loss_mask: 0.1175  s2.loss_cls: 0.0413  s2.acc: 95.8984  s2.loss_bbox: 0.0466  s2.loss_mask: 0.0552
2024/02/24 09:44:30 - mmengine - INFO - Epoch(train) [36][2350/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:57:00  time: 0.6826  data_time: 0.0270  memory: 10045  loss: 1.2349  loss_rpn_cls: 0.0395  loss_rpn_bbox: 0.0229  s0.loss_cls: 0.1975  s0.acc: 91.3086  s0.loss_bbox: 0.2607  s0.loss_mask: 0.2458  s1.loss_cls: 0.0874  s1.acc: 93.2643  s1.loss_bbox: 0.1177  s1.loss_mask: 0.1196  s2.loss_cls: 0.0414  s2.acc: 94.0625  s2.loss_bbox: 0.0467  s2.loss_mask: 0.0556
2024/02/24 09:45:04 - mmengine - INFO - Epoch(train) [36][2400/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:56:26  time: 0.6905  data_time: 0.0306  memory: 9335  loss: 1.3165  loss_rpn_cls: 0.0384  loss_rpn_bbox: 0.0327  s0.loss_cls: 0.2089  s0.acc: 90.7227  s0.loss_bbox: 0.2867  s0.loss_mask: 0.2545  s1.loss_cls: 0.0965  s1.acc: 93.5614  s1.loss_bbox: 0.1233  s1.loss_mask: 0.1220  s2.loss_cls: 0.0479  s2.acc: 91.6750  s2.loss_bbox: 0.0479  s2.loss_mask: 0.0577
2024/02/24 09:45:38 - mmengine - INFO - Exp name: cascade_mask_rcnn_swin_tiny_patch4_window7_mstrain_480-800_giou_4conv1f_adamw_3x_coco_20240224_074830
2024/02/24 09:45:38 - mmengine - INFO - Epoch(train) [36][2450/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:55:51  time: 0.6791  data_time: 0.0238  memory: 9365  loss: 1.1098  loss_rpn_cls: 0.0418  loss_rpn_bbox: 0.0236  s0.loss_cls: 0.1721  s0.acc: 88.3789  s0.loss_bbox: 0.2254  s0.loss_mask: 0.2270  s1.loss_cls: 0.0775  s1.acc: 89.5153  s1.loss_bbox: 0.1022  s1.loss_mask: 0.1101  s2.loss_cls: 0.0370  s2.acc: 89.9507  s2.loss_bbox: 0.0418  s2.loss_mask: 0.0513
2024/02/24 09:46:12 - mmengine - INFO - Epoch(train) [36][2500/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:55:17  time: 0.6821  data_time: 0.0246  memory: 9554  loss: 1.1755  loss_rpn_cls: 0.0353  loss_rpn_bbox: 0.0242  s0.loss_cls: 0.1933  s0.acc: 91.0156  s0.loss_bbox: 0.2525  s0.loss_mask: 0.2255  s1.loss_cls: 0.0830  s1.acc: 90.5273  s1.loss_bbox: 0.1147  s1.loss_mask: 0.1102  s2.loss_cls: 0.0382  s2.acc: 91.9922  s2.loss_bbox: 0.0467  s2.loss_mask: 0.0519
2024/02/24 09:46:47 - mmengine - INFO - Epoch(train) [36][2550/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:54:43  time: 0.6908  data_time: 0.0260  memory: 9227  loss: 1.1152  loss_rpn_cls: 0.0393  loss_rpn_bbox: 0.0273  s0.loss_cls: 0.1669  s0.acc: 98.4375  s0.loss_bbox: 0.2387  s0.loss_mask: 0.2203  s1.loss_cls: 0.0732  s1.acc: 97.7539  s1.loss_bbox: 0.1097  s1.loss_mask: 0.1074  s2.loss_cls: 0.0368  s2.acc: 96.7773  s2.loss_bbox: 0.0443  s2.loss_mask: 0.0512
2024/02/24 09:47:22 - mmengine - INFO - Epoch(train) [36][2600/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:54:08  time: 0.6915  data_time: 0.0270  memory: 9370  loss: 1.2120  loss_rpn_cls: 0.0377  loss_rpn_bbox: 0.0268  s0.loss_cls: 0.1968  s0.acc: 98.7305  s0.loss_bbox: 0.2596  s0.loss_mask: 0.2367  s1.loss_cls: 0.0856  s1.acc: 99.8047  s1.loss_bbox: 0.1162  s1.loss_mask: 0.1142  s2.loss_cls: 0.0397  s2.acc: 99.5117  s2.loss_bbox: 0.0467  s2.loss_mask: 0.0520
2024/02/24 09:47:56 - mmengine - INFO - Epoch(train) [36][2650/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:53:34  time: 0.6958  data_time: 0.0258  memory: 9891  loss: 1.0782  loss_rpn_cls: 0.0336  loss_rpn_bbox: 0.0275  s0.loss_cls: 0.1644  s0.acc: 90.7227  s0.loss_bbox: 0.2135  s0.loss_mask: 0.2285  s1.loss_cls: 0.0739  s1.acc: 92.0998  s1.loss_bbox: 0.0990  s1.loss_mask: 0.1125  s2.loss_cls: 0.0354  s2.acc: 90.8238  s2.loss_bbox: 0.0382  s2.loss_mask: 0.0517
2024/02/24 09:48:30 - mmengine - INFO - Epoch(train) [36][2700/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:53:00  time: 0.6751  data_time: 0.0275  memory: 9636  loss: 1.2496  loss_rpn_cls: 0.0447  loss_rpn_bbox: 0.0328  s0.loss_cls: 0.1959  s0.acc: 95.9961  s0.loss_bbox: 0.2730  s0.loss_mask: 0.2402  s1.loss_cls: 0.0874  s1.acc: 94.6289  s1.loss_bbox: 0.1214  s1.loss_mask: 0.1137  s2.loss_cls: 0.0406  s2.acc: 95.3125  s2.loss_bbox: 0.0477  s2.loss_mask: 0.0523
2024/02/24 09:49:04 - mmengine - INFO - Epoch(train) [36][2750/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:52:25  time: 0.6775  data_time: 0.0247  memory: 9341  loss: 1.1296  loss_rpn_cls: 0.0359  loss_rpn_bbox: 0.0270  s0.loss_cls: 0.1621  s0.acc: 97.8516  s0.loss_bbox: 0.2226  s0.loss_mask: 0.2450  s1.loss_cls: 0.0754  s1.acc: 97.4609  s1.loss_bbox: 0.1035  s1.loss_mask: 0.1223  s2.loss_cls: 0.0358  s2.acc: 97.3633  s2.loss_bbox: 0.0407  s2.loss_mask: 0.0592
2024/02/24 09:49:38 - mmengine - INFO - Epoch(train) [36][2800/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:51:51  time: 0.6785  data_time: 0.0239  memory: 9493  loss: 1.1067  loss_rpn_cls: 0.0345  loss_rpn_bbox: 0.0263  s0.loss_cls: 0.1698  s0.acc: 96.1914  s0.loss_bbox: 0.2346  s0.loss_mask: 0.2201  s1.loss_cls: 0.0747  s1.acc: 97.1680  s1.loss_bbox: 0.1094  s1.loss_mask: 0.1083  s2.loss_cls: 0.0359  s2.acc: 93.8477  s2.loss_bbox: 0.0435  s2.loss_mask: 0.0497
2024/02/24 09:50:13 - mmengine - INFO - Epoch(train) [36][2850/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:51:16  time: 0.6907  data_time: 0.0262  memory: 10247  loss: 1.2712  loss_rpn_cls: 0.0441  loss_rpn_bbox: 0.0318  s0.loss_cls: 0.2067  s0.acc: 93.7500  s0.loss_bbox: 0.2518  s0.loss_mask: 0.2592  s1.loss_cls: 0.0912  s1.acc: 95.8592  s1.loss_bbox: 0.1120  s1.loss_mask: 0.1268  s2.loss_cls: 0.0418  s2.acc: 96.8783  s2.loss_bbox: 0.0447  s2.loss_mask: 0.0609
2024/02/24 09:50:47 - mmengine - INFO - Epoch(train) [36][2900/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:50:42  time: 0.6941  data_time: 0.0267  memory: 9453  loss: 1.0828  loss_rpn_cls: 0.0375  loss_rpn_bbox: 0.0249  s0.loss_cls: 0.1718  s0.acc: 95.6055  s0.loss_bbox: 0.2233  s0.loss_mask: 0.2160  s1.loss_cls: 0.0738  s1.acc: 96.2891  s1.loss_bbox: 0.1004  s1.loss_mask: 0.1064  s2.loss_cls: 0.0362  s2.acc: 95.7031  s2.loss_bbox: 0.0419  s2.loss_mask: 0.0506
2024/02/24 09:51:21 - mmengine - INFO - Epoch(train) [36][2950/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:50:08  time: 0.6814  data_time: 0.0251  memory: 9414  loss: 1.1976  loss_rpn_cls: 0.0339  loss_rpn_bbox: 0.0258  s0.loss_cls: 0.1795  s0.acc: 94.7266  s0.loss_bbox: 0.2511  s0.loss_mask: 0.2472  s1.loss_cls: 0.0808  s1.acc: 95.1172  s1.loss_bbox: 0.1190  s1.loss_mask: 0.1209  s2.loss_cls: 0.0379  s2.acc: 93.1641  s2.loss_bbox: 0.0459  s2.loss_mask: 0.0556
2024/02/24 09:51:56 - mmengine - INFO - Epoch(train) [36][3000/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:49:33  time: 0.6891  data_time: 0.0271  memory: 9941  loss: 1.2215  loss_rpn_cls: 0.0375  loss_rpn_bbox: 0.0296  s0.loss_cls: 0.1857  s0.acc: 96.0938  s0.loss_bbox: 0.2497  s0.loss_mask: 0.2517  s1.loss_cls: 0.0864  s1.acc: 98.3398  s1.loss_bbox: 0.1175  s1.loss_mask: 0.1214  s2.loss_cls: 0.0404  s2.acc: 96.5820  s2.loss_bbox: 0.0455  s2.loss_mask: 0.0561
2024/02/24 09:52:30 - mmengine - INFO - Epoch(train) [36][3050/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:48:59  time: 0.6733  data_time: 0.0251  memory: 9561  loss: 1.1309  loss_rpn_cls: 0.0312  loss_rpn_bbox: 0.0202  s0.loss_cls: 0.1810  s0.acc: 87.1094  s0.loss_bbox: 0.2430  s0.loss_mask: 0.2251  s1.loss_cls: 0.0786  s1.acc: 89.4578  s1.loss_bbox: 0.1096  s1.loss_mask: 0.1086  s2.loss_cls: 0.0365  s2.acc: 88.4654  s2.loss_bbox: 0.0446  s2.loss_mask: 0.0525
2024/02/24 09:53:04 - mmengine - INFO - Epoch(train) [36][3100/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:48:24  time: 0.6855  data_time: 0.0251  memory: 9750  loss: 1.1930  loss_rpn_cls: 0.0377  loss_rpn_bbox: 0.0227  s0.loss_cls: 0.1825  s0.acc: 94.1406  s0.loss_bbox: 0.2528  s0.loss_mask: 0.2478  s1.loss_cls: 0.0841  s1.acc: 92.8215  s1.loss_bbox: 0.1093  s1.loss_mask: 0.1190  s2.loss_cls: 0.0396  s2.acc: 94.0417  s2.loss_bbox: 0.0421  s2.loss_mask: 0.0554
2024/02/24 09:53:38 - mmengine - INFO - Epoch(train) [36][3150/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:47:50  time: 0.6857  data_time: 0.0295  memory: 9180  loss: 1.1223  loss_rpn_cls: 0.0349  loss_rpn_bbox: 0.0300  s0.loss_cls: 0.1841  s0.acc: 93.4570  s0.loss_bbox: 0.2247  s0.loss_mask: 0.2255  s1.loss_cls: 0.0792  s1.acc: 95.0153  s1.loss_bbox: 0.1026  s1.loss_mask: 0.1104  s2.loss_cls: 0.0374  s2.acc: 95.3846  s2.loss_bbox: 0.0415  s2.loss_mask: 0.0519
2024/02/24 09:54:13 - mmengine - INFO - Epoch(train) [36][3200/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:47:16  time: 0.6943  data_time: 0.0264  memory: 9596  loss: 1.2695  loss_rpn_cls: 0.0451  loss_rpn_bbox: 0.0314  s0.loss_cls: 0.2183  s0.acc: 93.4570  s0.loss_bbox: 0.2678  s0.loss_mask: 0.2343  s1.loss_cls: 0.0971  s1.acc: 96.6797  s1.loss_bbox: 0.1195  s1.loss_mask: 0.1120  s2.loss_cls: 0.0462  s2.acc: 97.1680  s2.loss_bbox: 0.0472  s2.loss_mask: 0.0509
2024/02/24 09:54:47 - mmengine - INFO - Epoch(train) [36][3250/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:46:41  time: 0.6837  data_time: 0.0261  memory: 9516  loss: 1.1590  loss_rpn_cls: 0.0387  loss_rpn_bbox: 0.0300  s0.loss_cls: 0.1869  s0.acc: 88.6719  s0.loss_bbox: 0.2532  s0.loss_mask: 0.2166  s1.loss_cls: 0.0807  s1.acc: 89.4895  s1.loss_bbox: 0.1145  s1.loss_mask: 0.1058  s2.loss_cls: 0.0378  s2.acc: 91.7671  s2.loss_bbox: 0.0452  s2.loss_mask: 0.0496
2024/02/24 09:55:22 - mmengine - INFO - Epoch(train) [36][3300/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:46:07  time: 0.6880  data_time: 0.0294  memory: 9712  loss: 1.2908  loss_rpn_cls: 0.0435  loss_rpn_bbox: 0.0317  s0.loss_cls: 0.2083  s0.acc: 95.5078  s0.loss_bbox: 0.2764  s0.loss_mask: 0.2393  s1.loss_cls: 0.0968  s1.acc: 94.9799  s1.loss_bbox: 0.1227  s1.loss_mask: 0.1200  s2.loss_cls: 0.0465  s2.acc: 93.6556  s2.loss_bbox: 0.0489  s2.loss_mask: 0.0568
2024/02/24 09:55:56 - mmengine - INFO - Epoch(train) [36][3350/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:45:33  time: 0.6834  data_time: 0.0246  memory: 10823  loss: 1.1602  loss_rpn_cls: 0.0356  loss_rpn_bbox: 0.0230  s0.loss_cls: 0.1813  s0.acc: 93.1641  s0.loss_bbox: 0.2292  s0.loss_mask: 0.2470  s1.loss_cls: 0.0797  s1.acc: 93.1275  s1.loss_bbox: 0.1050  s1.loss_mask: 0.1221  s2.loss_cls: 0.0384  s2.acc: 92.7507  s2.loss_bbox: 0.0420  s2.loss_mask: 0.0571
2024/02/24 09:56:30 - mmengine - INFO - Epoch(train) [36][3400/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:44:58  time: 0.6830  data_time: 0.0253  memory: 10229  loss: 1.1618  loss_rpn_cls: 0.0344  loss_rpn_bbox: 0.0263  s0.loss_cls: 0.1879  s0.acc: 91.7969  s0.loss_bbox: 0.2450  s0.loss_mask: 0.2298  s1.loss_cls: 0.0824  s1.acc: 90.5584  s1.loss_bbox: 0.1116  s1.loss_mask: 0.1111  s2.loss_cls: 0.0381  s2.acc: 90.7351  s2.loss_bbox: 0.0444  s2.loss_mask: 0.0508
2024/02/24 09:57:04 - mmengine - INFO - Exp name: cascade_mask_rcnn_swin_tiny_patch4_window7_mstrain_480-800_giou_4conv1f_adamw_3x_coco_20240224_074830
2024/02/24 09:57:04 - mmengine - INFO - Epoch(train) [36][3450/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:44:24  time: 0.6828  data_time: 0.0241  memory: 9655  loss: 1.1010  loss_rpn_cls: 0.0396  loss_rpn_bbox: 0.0243  s0.loss_cls: 0.1676  s0.acc: 97.0703  s0.loss_bbox: 0.2197  s0.loss_mask: 0.2290  s1.loss_cls: 0.0738  s1.acc: 96.1914  s1.loss_bbox: 0.1015  s1.loss_mask: 0.1152  s2.loss_cls: 0.0332  s2.acc: 96.2891  s2.loss_bbox: 0.0418  s2.loss_mask: 0.0551
2024/02/24 09:57:39 - mmengine - INFO - Epoch(train) [36][3500/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:43:50  time: 0.6887  data_time: 0.0264  memory: 9549  loss: 1.1673  loss_rpn_cls: 0.0412  loss_rpn_bbox: 0.0329  s0.loss_cls: 0.1821  s0.acc: 91.7969  s0.loss_bbox: 0.2470  s0.loss_mask: 0.2249  s1.loss_cls: 0.0803  s1.acc: 92.6854  s1.loss_bbox: 0.1144  s1.loss_mask: 0.1099  s2.loss_cls: 0.0373  s2.acc: 94.3227  s2.loss_bbox: 0.0457  s2.loss_mask: 0.0515
2024/02/24 09:58:13 - mmengine - INFO - Epoch(train) [36][3550/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:43:15  time: 0.6806  data_time: 0.0254  memory: 10847  loss: 1.1643  loss_rpn_cls: 0.0382  loss_rpn_bbox: 0.0273  s0.loss_cls: 0.1886  s0.acc: 94.8242  s0.loss_bbox: 0.2364  s0.loss_mask: 0.2331  s1.loss_cls: 0.0838  s1.acc: 95.5078  s1.loss_bbox: 0.1066  s1.loss_mask: 0.1144  s2.loss_cls: 0.0398  s2.acc: 97.1680  s2.loss_bbox: 0.0422  s2.loss_mask: 0.0537
2024/02/24 09:58:47 - mmengine - INFO - Epoch(train) [36][3600/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:42:41  time: 0.6916  data_time: 0.0254  memory: 9454  loss: 1.2347  loss_rpn_cls: 0.0479  loss_rpn_bbox: 0.0312  s0.loss_cls: 0.1844  s0.acc: 94.0430  s0.loss_bbox: 0.2661  s0.loss_mask: 0.2419  s1.loss_cls: 0.0825  s1.acc: 94.3396  s1.loss_bbox: 0.1178  s1.loss_mask: 0.1183  s2.loss_cls: 0.0392  s2.acc: 94.1532  s2.loss_bbox: 0.0476  s2.loss_mask: 0.0576
2024/02/24 09:59:22 - mmengine - INFO - Epoch(train) [36][3650/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:42:07  time: 0.6886  data_time: 0.0238  memory: 9144  loss: 1.1413  loss_rpn_cls: 0.0360  loss_rpn_bbox: 0.0254  s0.loss_cls: 0.1732  s0.acc: 97.7539  s0.loss_bbox: 0.2360  s0.loss_mask: 0.2392  s1.loss_cls: 0.0796  s1.acc: 97.9492  s1.loss_bbox: 0.1061  s1.loss_mask: 0.1141  s2.loss_cls: 0.0367  s2.acc: 97.4609  s2.loss_bbox: 0.0423  s2.loss_mask: 0.0528
2024/02/24 09:59:56 - mmengine - INFO - Epoch(train) [36][3700/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:41:32  time: 0.6831  data_time: 0.0283  memory: 9417  loss: 1.2257  loss_rpn_cls: 0.0452  loss_rpn_bbox: 0.0313  s0.loss_cls: 0.1974  s0.acc: 93.1641  s0.loss_bbox: 0.2558  s0.loss_mask: 0.2402  s1.loss_cls: 0.0845  s1.acc: 94.7581  s1.loss_bbox: 0.1159  s1.loss_mask: 0.1167  s2.loss_cls: 0.0396  s2.acc: 93.9698  s2.loss_bbox: 0.0450  s2.loss_mask: 0.0541
2024/02/24 10:00:31 - mmengine - INFO - Epoch(train) [36][3750/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:40:58  time: 0.6912  data_time: 0.0258  memory: 9629  loss: 1.1417  loss_rpn_cls: 0.0379  loss_rpn_bbox: 0.0243  s0.loss_cls: 0.1757  s0.acc: 84.9609  s0.loss_bbox: 0.2315  s0.loss_mask: 0.2441  s1.loss_cls: 0.0753  s1.acc: 84.1535  s1.loss_bbox: 0.1032  s1.loss_mask: 0.1180  s2.loss_cls: 0.0363  s2.acc: 85.4207  s2.loss_bbox: 0.0412  s2.loss_mask: 0.0544
2024/02/24 10:01:05 - mmengine - INFO - Epoch(train) [36][3800/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:40:24  time: 0.6806  data_time: 0.0255  memory: 9381  loss: 1.2043  loss_rpn_cls: 0.0316  loss_rpn_bbox: 0.0247  s0.loss_cls: 0.1828  s0.acc: 92.5781  s0.loss_bbox: 0.2511  s0.loss_mask: 0.2510  s1.loss_cls: 0.0814  s1.acc: 92.9688  s1.loss_bbox: 0.1149  s1.loss_mask: 0.1226  s2.loss_cls: 0.0400  s2.acc: 94.4336  s2.loss_bbox: 0.0467  s2.loss_mask: 0.0575
2024/02/24 10:01:40 - mmengine - INFO - Epoch(train) [36][3850/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:39:50  time: 0.7086  data_time: 0.0275  memory: 10036  loss: 1.0840  loss_rpn_cls: 0.0318  loss_rpn_bbox: 0.0241  s0.loss_cls: 0.1697  s0.acc: 95.0195  s0.loss_bbox: 0.2159  s0.loss_mask: 0.2308  s1.loss_cls: 0.0753  s1.acc: 96.9428  s1.loss_bbox: 0.0983  s1.loss_mask: 0.1131  s2.loss_cls: 0.0344  s2.acc: 94.8718  s2.loss_bbox: 0.0388  s2.loss_mask: 0.0518
2024/02/24 10:02:14 - mmengine - INFO - Epoch(train) [36][3900/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:39:15  time: 0.6812  data_time: 0.0269  memory: 9747  loss: 1.1560  loss_rpn_cls: 0.0401  loss_rpn_bbox: 0.0305  s0.loss_cls: 0.1870  s0.acc: 98.5352  s0.loss_bbox: 0.2319  s0.loss_mask: 0.2329  s1.loss_cls: 0.0802  s1.acc: 99.6094  s1.loss_bbox: 0.1065  s1.loss_mask: 0.1139  s2.loss_cls: 0.0382  s2.acc: 99.3164  s2.loss_bbox: 0.0416  s2.loss_mask: 0.0532
2024/02/24 10:02:48 - mmengine - INFO - Epoch(train) [36][3950/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:38:41  time: 0.6815  data_time: 0.0265  memory: 9744  loss: 1.1595  loss_rpn_cls: 0.0383  loss_rpn_bbox: 0.0256  s0.loss_cls: 0.1854  s0.acc: 97.1680  s0.loss_bbox: 0.2370  s0.loss_mask: 0.2325  s1.loss_cls: 0.0832  s1.acc: 97.7539  s1.loss_bbox: 0.1083  s1.loss_mask: 0.1136  s2.loss_cls: 0.0380  s2.acc: 99.0234  s2.loss_bbox: 0.0442  s2.loss_mask: 0.0535
2024/02/24 10:03:22 - mmengine - INFO - Epoch(train) [36][4000/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:38:06  time: 0.6805  data_time: 0.0265  memory: 11054  loss: 1.1830  loss_rpn_cls: 0.0359  loss_rpn_bbox: 0.0262  s0.loss_cls: 0.1832  s0.acc: 87.5000  s0.loss_bbox: 0.2384  s0.loss_mask: 0.2476  s1.loss_cls: 0.0796  s1.acc: 88.9648  s1.loss_bbox: 0.1095  s1.loss_mask: 0.1234  s2.loss_cls: 0.0373  s2.acc: 91.4062  s2.loss_bbox: 0.0442  s2.loss_mask: 0.0577
2024/02/24 10:03:57 - mmengine - INFO - Epoch(train) [36][4050/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:37:32  time: 0.6871  data_time: 0.0252  memory: 9590  loss: 1.1441  loss_rpn_cls: 0.0328  loss_rpn_bbox: 0.0223  s0.loss_cls: 0.1761  s0.acc: 91.6016  s0.loss_bbox: 0.2419  s0.loss_mask: 0.2303  s1.loss_cls: 0.0805  s1.acc: 92.2528  s1.loss_bbox: 0.1113  s1.loss_mask: 0.1134  s2.loss_cls: 0.0372  s2.acc: 92.4797  s2.loss_bbox: 0.0449  s2.loss_mask: 0.0534
2024/02/24 10:04:32 - mmengine - INFO - Epoch(train) [36][4100/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:36:58  time: 0.6942  data_time: 0.0233  memory: 9741  loss: 1.1708  loss_rpn_cls: 0.0387  loss_rpn_bbox: 0.0313  s0.loss_cls: 0.1823  s0.acc: 94.0430  s0.loss_bbox: 0.2444  s0.loss_mask: 0.2350  s1.loss_cls: 0.0833  s1.acc: 91.3086  s1.loss_bbox: 0.1087  s1.loss_mask: 0.1134  s2.loss_cls: 0.0401  s2.acc: 92.8711  s2.loss_bbox: 0.0413  s2.loss_mask: 0.0522
2024/02/24 10:05:06 - mmengine - INFO - Epoch(train) [36][4150/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:36:23  time: 0.6859  data_time: 0.0256  memory: 10031  loss: 1.1575  loss_rpn_cls: 0.0335  loss_rpn_bbox: 0.0276  s0.loss_cls: 0.1810  s0.acc: 95.0195  s0.loss_bbox: 0.2502  s0.loss_mask: 0.2375  s1.loss_cls: 0.0788  s1.acc: 96.1727  s1.loss_bbox: 0.1058  s1.loss_mask: 0.1111  s2.loss_cls: 0.0379  s2.acc: 96.9277  s2.loss_bbox: 0.0419  s2.loss_mask: 0.0523
2024/02/24 10:05:40 - mmengine - INFO - Epoch(train) [36][4200/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:35:49  time: 0.6855  data_time: 0.0235  memory: 9721  loss: 1.1371  loss_rpn_cls: 0.0269  loss_rpn_bbox: 0.0222  s0.loss_cls: 0.1784  s0.acc: 96.4844  s0.loss_bbox: 0.2366  s0.loss_mask: 0.2376  s1.loss_cls: 0.0773  s1.acc: 99.2188  s1.loss_bbox: 0.1068  s1.loss_mask: 0.1168  s2.loss_cls: 0.0376  s2.acc: 99.5117  s2.loss_bbox: 0.0420  s2.loss_mask: 0.0549
2024/02/24 10:06:15 - mmengine - INFO - Epoch(train) [36][4250/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:35:15  time: 0.6870  data_time: 0.0256  memory: 9711  loss: 1.1453  loss_rpn_cls: 0.0438  loss_rpn_bbox: 0.0268  s0.loss_cls: 0.1748  s0.acc: 89.1602  s0.loss_bbox: 0.2357  s0.loss_mask: 0.2339  s1.loss_cls: 0.0801  s1.acc: 92.7022  s1.loss_bbox: 0.1059  s1.loss_mask: 0.1123  s2.loss_cls: 0.0369  s2.acc: 92.2321  s2.loss_bbox: 0.0424  s2.loss_mask: 0.0526
2024/02/24 10:06:49 - mmengine - INFO - Epoch(train) [36][4300/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:34:40  time: 0.6817  data_time: 0.0312  memory: 9988  loss: 1.2201  loss_rpn_cls: 0.0374  loss_rpn_bbox: 0.0256  s0.loss_cls: 0.1861  s0.acc: 93.3594  s0.loss_bbox: 0.2619  s0.loss_mask: 0.2439  s1.loss_cls: 0.0885  s1.acc: 93.0894  s1.loss_bbox: 0.1158  s1.loss_mask: 0.1175  s2.loss_cls: 0.0424  s2.acc: 92.3781  s2.loss_bbox: 0.0457  s2.loss_mask: 0.0552
2024/02/24 10:07:23 - mmengine - INFO - Epoch(train) [36][4350/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:34:06  time: 0.6811  data_time: 0.0242  memory: 9688  loss: 1.0488  loss_rpn_cls: 0.0293  loss_rpn_bbox: 0.0206  s0.loss_cls: 0.1589  s0.acc: 90.3320  s0.loss_bbox: 0.2125  s0.loss_mask: 0.2208  s1.loss_cls: 0.0734  s1.acc: 89.0342  s1.loss_bbox: 0.1005  s1.loss_mask: 0.1074  s2.loss_cls: 0.0354  s2.acc: 88.4576  s2.loss_bbox: 0.0405  s2.loss_mask: 0.0494
2024/02/24 10:07:57 - mmengine - INFO - Epoch(train) [36][4400/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:33:31  time: 0.6753  data_time: 0.0248  memory: 10054  loss: 1.1281  loss_rpn_cls: 0.0387  loss_rpn_bbox: 0.0252  s0.loss_cls: 0.1741  s0.acc: 97.5586  s0.loss_bbox: 0.2261  s0.loss_mask: 0.2427  s1.loss_cls: 0.0774  s1.acc: 98.8281  s1.loss_bbox: 0.1022  s1.loss_mask: 0.1145  s2.loss_cls: 0.0354  s2.acc: 99.3164  s2.loss_bbox: 0.0400  s2.loss_mask: 0.0518
2024/02/24 10:08:31 - mmengine - INFO - Exp name: cascade_mask_rcnn_swin_tiny_patch4_window7_mstrain_480-800_giou_4conv1f_adamw_3x_coco_20240224_074830
2024/02/24 10:08:31 - mmengine - INFO - Epoch(train) [36][4450/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:32:57  time: 0.6876  data_time: 0.0249  memory: 9680  loss: 1.1647  loss_rpn_cls: 0.0357  loss_rpn_bbox: 0.0223  s0.loss_cls: 0.1848  s0.acc: 93.2617  s0.loss_bbox: 0.2442  s0.loss_mask: 0.2305  s1.loss_cls: 0.0853  s1.acc: 92.7734  s1.loss_bbox: 0.1128  s1.loss_mask: 0.1119  s2.loss_cls: 0.0406  s2.acc: 94.7266  s2.loss_bbox: 0.0444  s2.loss_mask: 0.0521
2024/02/24 10:09:05 - mmengine - INFO - Epoch(train) [36][4500/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:32:23  time: 0.6780  data_time: 0.0265  memory: 9746  loss: 1.2650  loss_rpn_cls: 0.0383  loss_rpn_bbox: 0.0329  s0.loss_cls: 0.1959  s0.acc: 93.2617  s0.loss_bbox: 0.2735  s0.loss_mask: 0.2506  s1.loss_cls: 0.0890  s1.acc: 96.5820  s1.loss_bbox: 0.1194  s1.loss_mask: 0.1203  s2.loss_cls: 0.0424  s2.acc: 97.2656  s2.loss_bbox: 0.0464  s2.loss_mask: 0.0562
2024/02/24 10:09:39 - mmengine - INFO - Epoch(train) [36][4550/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:31:48  time: 0.6762  data_time: 0.0255  memory: 9308  loss: 1.0517  loss_rpn_cls: 0.0308  loss_rpn_bbox: 0.0257  s0.loss_cls: 0.1529  s0.acc: 89.2578  s0.loss_bbox: 0.2106  s0.loss_mask: 0.2285  s1.loss_cls: 0.0683  s1.acc: 90.8092  s1.loss_bbox: 0.0992  s1.loss_mask: 0.1114  s2.loss_cls: 0.0335  s2.acc: 88.5115  s2.loss_bbox: 0.0398  s2.loss_mask: 0.0511
2024/02/24 10:10:13 - mmengine - INFO - Epoch(train) [36][4600/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:31:14  time: 0.6853  data_time: 0.0320  memory: 9407  loss: 1.1891  loss_rpn_cls: 0.0479  loss_rpn_bbox: 0.0335  s0.loss_cls: 0.1794  s0.acc: 89.5508  s0.loss_bbox: 0.2549  s0.loss_mask: 0.2339  s1.loss_cls: 0.0784  s1.acc: 90.7692  s1.loss_bbox: 0.1137  s1.loss_mask: 0.1128  s2.loss_cls: 0.0369  s2.acc: 90.4908  s2.loss_bbox: 0.0449  s2.loss_mask: 0.0526
2024/02/24 10:10:47 - mmengine - INFO - Epoch(train) [36][4650/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:30:39  time: 0.6817  data_time: 0.0288  memory: 10082  loss: 1.1213  loss_rpn_cls: 0.0364  loss_rpn_bbox: 0.0290  s0.loss_cls: 0.1752  s0.acc: 92.3828  s0.loss_bbox: 0.2293  s0.loss_mask: 0.2276  s1.loss_cls: 0.0782  s1.acc: 91.1133  s1.loss_bbox: 0.1019  s1.loss_mask: 0.1138  s2.loss_cls: 0.0375  s2.acc: 92.4805  s2.loss_bbox: 0.0397  s2.loss_mask: 0.0529
2024/02/24 10:11:21 - mmengine - INFO - Epoch(train) [36][4700/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:30:05  time: 0.6734  data_time: 0.0252  memory: 9110  loss: 1.1050  loss_rpn_cls: 0.0431  loss_rpn_bbox: 0.0300  s0.loss_cls: 0.1709  s0.acc: 93.4570  s0.loss_bbox: 0.2223  s0.loss_mask: 0.2242  s1.loss_cls: 0.0761  s1.acc: 95.9606  s1.loss_bbox: 0.1006  s1.loss_mask: 0.1101  s2.loss_cls: 0.0350  s2.acc: 96.3547  s2.loss_bbox: 0.0409  s2.loss_mask: 0.0518
2024/02/24 10:11:55 - mmengine - INFO - Epoch(train) [36][4750/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:29:31  time: 0.6881  data_time: 0.0268  memory: 10632  loss: 1.2228  loss_rpn_cls: 0.0416  loss_rpn_bbox: 0.0286  s0.loss_cls: 0.1886  s0.acc: 96.3867  s0.loss_bbox: 0.2550  s0.loss_mask: 0.2566  s1.loss_cls: 0.0836  s1.acc: 98.0469  s1.loss_bbox: 0.1131  s1.loss_mask: 0.1204  s2.loss_cls: 0.0388  s2.acc: 98.4375  s2.loss_bbox: 0.0428  s2.loss_mask: 0.0539
2024/02/24 10:12:29 - mmengine - INFO - Epoch(train) [36][4800/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:28:56  time: 0.6801  data_time: 0.0227  memory: 9307  loss: 1.0757  loss_rpn_cls: 0.0389  loss_rpn_bbox: 0.0239  s0.loss_cls: 0.1532  s0.acc: 93.8477  s0.loss_bbox: 0.2181  s0.loss_mask: 0.2355  s1.loss_cls: 0.0681  s1.acc: 96.1771  s1.loss_bbox: 0.1010  s1.loss_mask: 0.1131  s2.loss_cls: 0.0305  s2.acc: 97.2810  s2.loss_bbox: 0.0406  s2.loss_mask: 0.0527
2024/02/24 10:13:04 - mmengine - INFO - Epoch(train) [36][4850/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:28:22  time: 0.6837  data_time: 0.0258  memory: 9578  loss: 1.1415  loss_rpn_cls: 0.0369  loss_rpn_bbox: 0.0262  s0.loss_cls: 0.1716  s0.acc: 93.3594  s0.loss_bbox: 0.2340  s0.loss_mask: 0.2427  s1.loss_cls: 0.0747  s1.acc: 94.6289  s1.loss_bbox: 0.1047  s1.loss_mask: 0.1189  s2.loss_cls: 0.0341  s2.acc: 97.2656  s2.loss_bbox: 0.0429  s2.loss_mask: 0.0548
2024/02/24 10:13:37 - mmengine - INFO - Epoch(train) [36][4900/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:27:48  time: 0.6785  data_time: 0.0268  memory: 9734  loss: 1.1099  loss_rpn_cls: 0.0302  loss_rpn_bbox: 0.0234  s0.loss_cls: 0.1648  s0.acc: 96.9727  s0.loss_bbox: 0.2249  s0.loss_mask: 0.2456  s1.loss_cls: 0.0689  s1.acc: 96.9727  s1.loss_bbox: 0.1032  s1.loss_mask: 0.1199  s2.loss_cls: 0.0325  s2.acc: 97.5586  s2.loss_bbox: 0.0412  s2.loss_mask: 0.0554
2024/02/24 10:14:11 - mmengine - INFO - Epoch(train) [36][4950/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:27:13  time: 0.6754  data_time: 0.0295  memory: 10003  loss: 1.1416  loss_rpn_cls: 0.0395  loss_rpn_bbox: 0.0246  s0.loss_cls: 0.1819  s0.acc: 98.7305  s0.loss_bbox: 0.2329  s0.loss_mask: 0.2306  s1.loss_cls: 0.0812  s1.acc: 98.0469  s1.loss_bbox: 0.1049  s1.loss_mask: 0.1129  s2.loss_cls: 0.0376  s2.acc: 98.8281  s2.loss_bbox: 0.0422  s2.loss_mask: 0.0533
2024/02/24 10:14:45 - mmengine - INFO - Epoch(train) [36][5000/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:26:39  time: 0.6824  data_time: 0.0279  memory: 9446  loss: 1.2477  loss_rpn_cls: 0.0492  loss_rpn_bbox: 0.0321  s0.loss_cls: 0.2036  s0.acc: 95.8984  s0.loss_bbox: 0.2693  s0.loss_mask: 0.2322  s1.loss_cls: 0.0877  s1.acc: 95.8008  s1.loss_bbox: 0.1214  s1.loss_mask: 0.1120  s2.loss_cls: 0.0417  s2.acc: 95.3125  s2.loss_bbox: 0.0470  s2.loss_mask: 0.0514
2024/02/24 10:15:20 - mmengine - INFO - Epoch(train) [36][5050/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:26:05  time: 0.7002  data_time: 0.0244  memory: 10027  loss: 1.1329  loss_rpn_cls: 0.0405  loss_rpn_bbox: 0.0266  s0.loss_cls: 0.1766  s0.acc: 92.6758  s0.loss_bbox: 0.2245  s0.loss_mask: 0.2405  s1.loss_cls: 0.0783  s1.acc: 93.8477  s1.loss_bbox: 0.1009  s1.loss_mask: 0.1145  s2.loss_cls: 0.0360  s2.acc: 96.4844  s2.loss_bbox: 0.0410  s2.loss_mask: 0.0533
2024/02/24 10:15:55 - mmengine - INFO - Epoch(train) [36][5100/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:25:30  time: 0.6969  data_time: 0.0259  memory: 9363  loss: 1.1204  loss_rpn_cls: 0.0331  loss_rpn_bbox: 0.0267  s0.loss_cls: 0.1612  s0.acc: 91.8945  s0.loss_bbox: 0.2316  s0.loss_mask: 0.2444  s1.loss_cls: 0.0724  s1.acc: 92.1891  s1.loss_bbox: 0.1045  s1.loss_mask: 0.1178  s2.loss_cls: 0.0332  s2.acc: 94.0083  s2.loss_bbox: 0.0410  s2.loss_mask: 0.0545
2024/02/24 10:16:29 - mmengine - INFO - Epoch(train) [36][5150/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:24:56  time: 0.6791  data_time: 0.0269  memory: 9759  loss: 1.2019  loss_rpn_cls: 0.0406  loss_rpn_bbox: 0.0291  s0.loss_cls: 0.1815  s0.acc: 90.2344  s0.loss_bbox: 0.2625  s0.loss_mask: 0.2336  s1.loss_cls: 0.0794  s1.acc: 92.1875  s1.loss_bbox: 0.1194  s1.loss_mask: 0.1150  s2.loss_cls: 0.0375  s2.acc: 94.2383  s2.loss_bbox: 0.0491  s2.loss_mask: 0.0541
2024/02/24 10:17:04 - mmengine - INFO - Epoch(train) [36][5200/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:24:22  time: 0.6860  data_time: 0.0264  memory: 9665  loss: 1.1891  loss_rpn_cls: 0.0462  loss_rpn_bbox: 0.0337  s0.loss_cls: 0.1881  s0.acc: 85.9375  s0.loss_bbox: 0.2470  s0.loss_mask: 0.2327  s1.loss_cls: 0.0821  s1.acc: 86.0352  s1.loss_bbox: 0.1107  s1.loss_mask: 0.1132  s2.loss_cls: 0.0374  s2.acc: 86.6211  s2.loss_bbox: 0.0440  s2.loss_mask: 0.0538
2024/02/24 10:17:38 - mmengine - INFO - Epoch(train) [36][5250/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:23:47  time: 0.6783  data_time: 0.0282  memory: 9664  loss: 1.1937  loss_rpn_cls: 0.0341  loss_rpn_bbox: 0.0310  s0.loss_cls: 0.1839  s0.acc: 90.4297  s0.loss_bbox: 0.2578  s0.loss_mask: 0.2367  s1.loss_cls: 0.0796  s1.acc: 89.1650  s1.loss_bbox: 0.1151  s1.loss_mask: 0.1179  s2.loss_cls: 0.0382  s2.acc: 90.4245  s2.loss_bbox: 0.0449  s2.loss_mask: 0.0544
2024/02/24 10:18:12 - mmengine - INFO - Epoch(train) [36][5300/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:23:13  time: 0.6829  data_time: 0.0264  memory: 9358  loss: 1.1863  loss_rpn_cls: 0.0393  loss_rpn_bbox: 0.0300  s0.loss_cls: 0.1881  s0.acc: 89.8438  s0.loss_bbox: 0.2437  s0.loss_mask: 0.2378  s1.loss_cls: 0.0881  s1.acc: 89.2713  s1.loss_bbox: 0.1083  s1.loss_mask: 0.1144  s2.loss_cls: 0.0412  s2.acc: 89.1393  s2.loss_bbox: 0.0424  s2.loss_mask: 0.0529
2024/02/24 10:18:46 - mmengine - INFO - Epoch(train) [36][5350/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:22:39  time: 0.6881  data_time: 0.0268  memory: 10607  loss: 1.2301  loss_rpn_cls: 0.0404  loss_rpn_bbox: 0.0272  s0.loss_cls: 0.1959  s0.acc: 98.2422  s0.loss_bbox: 0.2606  s0.loss_mask: 0.2350  s1.loss_cls: 0.0881  s1.acc: 97.9492  s1.loss_bbox: 0.1212  s1.loss_mask: 0.1177  s2.loss_cls: 0.0414  s2.acc: 97.6562  s2.loss_bbox: 0.0479  s2.loss_mask: 0.0547
2024/02/24 10:19:20 - mmengine - INFO - Epoch(train) [36][5400/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:22:04  time: 0.6768  data_time: 0.0269  memory: 10004  loss: 1.3608  loss_rpn_cls: 0.0618  loss_rpn_bbox: 0.0340  s0.loss_cls: 0.2275  s0.acc: 95.2148  s0.loss_bbox: 0.2792  s0.loss_mask: 0.2640  s1.loss_cls: 0.1016  s1.acc: 96.5820  s1.loss_bbox: 0.1186  s1.loss_mask: 0.1249  s2.loss_cls: 0.0469  s2.acc: 97.4609  s2.loss_bbox: 0.0449  s2.loss_mask: 0.0574
2024/02/24 10:19:54 - mmengine - INFO - Exp name: cascade_mask_rcnn_swin_tiny_patch4_window7_mstrain_480-800_giou_4conv1f_adamw_3x_coco_20240224_074830
2024/02/24 10:19:54 - mmengine - INFO - Epoch(train) [36][5450/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:21:30  time: 0.6725  data_time: 0.0252  memory: 9463  loss: 1.0893  loss_rpn_cls: 0.0333  loss_rpn_bbox: 0.0258  s0.loss_cls: 0.1660  s0.acc: 92.9688  s0.loss_bbox: 0.2215  s0.loss_mask: 0.2244  s1.loss_cls: 0.0741  s1.acc: 93.7070  s1.loss_bbox: 0.1031  s1.loss_mask: 0.1107  s2.loss_cls: 0.0359  s2.acc: 95.5752  s2.loss_bbox: 0.0424  s2.loss_mask: 0.0522
2024/02/24 10:20:28 - mmengine - INFO - Epoch(train) [36][5500/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:20:55  time: 0.6850  data_time: 0.0283  memory: 9568  loss: 1.1111  loss_rpn_cls: 0.0364  loss_rpn_bbox: 0.0250  s0.loss_cls: 0.1687  s0.acc: 93.2617  s0.loss_bbox: 0.2295  s0.loss_mask: 0.2307  s1.loss_cls: 0.0762  s1.acc: 95.7086  s1.loss_bbox: 0.1050  s1.loss_mask: 0.1130  s2.loss_cls: 0.0341  s2.acc: 95.6827  s2.loss_bbox: 0.0411  s2.loss_mask: 0.0513
2024/02/24 10:21:02 - mmengine - INFO - Epoch(train) [36][5550/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:20:21  time: 0.6871  data_time: 0.0296  memory: 9356  loss: 1.2771  loss_rpn_cls: 0.0409  loss_rpn_bbox: 0.0323  s0.loss_cls: 0.2011  s0.acc: 93.1641  s0.loss_bbox: 0.2789  s0.loss_mask: 0.2442  s1.loss_cls: 0.0913  s1.acc: 95.3125  s1.loss_bbox: 0.1218  s1.loss_mask: 0.1198  s2.loss_cls: 0.0437  s2.acc: 95.0195  s2.loss_bbox: 0.0470  s2.loss_mask: 0.0560
2024/02/24 10:21:37 - mmengine - INFO - Epoch(train) [36][5600/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:19:47  time: 0.6829  data_time: 0.0254  memory: 9895  loss: 1.1104  loss_rpn_cls: 0.0343  loss_rpn_bbox: 0.0251  s0.loss_cls: 0.1624  s0.acc: 90.5273  s0.loss_bbox: 0.2375  s0.loss_mask: 0.2273  s1.loss_cls: 0.0726  s1.acc: 89.6928  s1.loss_bbox: 0.1079  s1.loss_mask: 0.1122  s2.loss_cls: 0.0355  s2.acc: 91.7903  s2.loss_bbox: 0.0428  s2.loss_mask: 0.0528
2024/02/24 10:22:11 - mmengine - INFO - Epoch(train) [36][5650/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:19:12  time: 0.6801  data_time: 0.0260  memory: 8801  loss: 1.1458  loss_rpn_cls: 0.0405  loss_rpn_bbox: 0.0295  s0.loss_cls: 0.1822  s0.acc: 88.7695  s0.loss_bbox: 0.2388  s0.loss_mask: 0.2255  s1.loss_cls: 0.0817  s1.acc: 89.6158  s1.loss_bbox: 0.1060  s1.loss_mask: 0.1099  s2.loss_cls: 0.0386  s2.acc: 88.3333  s2.loss_bbox: 0.0412  s2.loss_mask: 0.0517
2024/02/24 10:22:45 - mmengine - INFO - Epoch(train) [36][5700/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:18:38  time: 0.6781  data_time: 0.0256  memory: 9589  loss: 1.2274  loss_rpn_cls: 0.0560  loss_rpn_bbox: 0.0313  s0.loss_cls: 0.1936  s0.acc: 88.8672  s0.loss_bbox: 0.2410  s0.loss_mask: 0.2498  s1.loss_cls: 0.0856  s1.acc: 90.3259  s1.loss_bbox: 0.1095  s1.loss_mask: 0.1207  s2.loss_cls: 0.0399  s2.acc: 89.9168  s2.loss_bbox: 0.0431  s2.loss_mask: 0.0569
2024/02/24 10:23:19 - mmengine - INFO - Epoch(train) [36][5750/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:18:04  time: 0.6791  data_time: 0.0278  memory: 10167  loss: 1.2314  loss_rpn_cls: 0.0351  loss_rpn_bbox: 0.0265  s0.loss_cls: 0.1947  s0.acc: 98.5352  s0.loss_bbox: 0.2600  s0.loss_mask: 0.2455  s1.loss_cls: 0.0875  s1.acc: 98.6328  s1.loss_bbox: 0.1175  s1.loss_mask: 0.1216  s2.loss_cls: 0.0418  s2.acc: 99.0234  s2.loss_bbox: 0.0446  s2.loss_mask: 0.0566
2024/02/24 10:23:52 - mmengine - INFO - Epoch(train) [36][5800/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:17:29  time: 0.6781  data_time: 0.0263  memory: 9193  loss: 1.2376  loss_rpn_cls: 0.0415  loss_rpn_bbox: 0.0304  s0.loss_cls: 0.2015  s0.acc: 92.6758  s0.loss_bbox: 0.2628  s0.loss_mask: 0.2419  s1.loss_cls: 0.0880  s1.acc: 93.8632  s1.loss_bbox: 0.1166  s1.loss_mask: 0.1148  s2.loss_cls: 0.0410  s2.acc: 94.5837  s2.loss_bbox: 0.0460  s2.loss_mask: 0.0531
2024/02/24 10:24:27 - mmengine - INFO - Epoch(train) [36][5850/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:16:55  time: 0.6856  data_time: 0.0271  memory: 10120  loss: 1.0879  loss_rpn_cls: 0.0333  loss_rpn_bbox: 0.0231  s0.loss_cls: 0.1675  s0.acc: 95.2148  s0.loss_bbox: 0.2210  s0.loss_mask: 0.2284  s1.loss_cls: 0.0717  s1.acc: 95.2148  s1.loss_bbox: 0.1030  s1.loss_mask: 0.1122  s2.loss_cls: 0.0337  s2.acc: 97.4609  s2.loss_bbox: 0.0415  s2.loss_mask: 0.0527
2024/02/24 10:25:01 - mmengine - INFO - Epoch(train) [36][5900/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:16:21  time: 0.6890  data_time: 0.0283  memory: 9274  loss: 1.2496  loss_rpn_cls: 0.0455  loss_rpn_bbox: 0.0333  s0.loss_cls: 0.2033  s0.acc: 92.1875  s0.loss_bbox: 0.2587  s0.loss_mask: 0.2412  s1.loss_cls: 0.0909  s1.acc: 92.2211  s1.loss_bbox: 0.1148  s1.loss_mask: 0.1182  s2.loss_cls: 0.0436  s2.acc: 93.2515  s2.loss_bbox: 0.0451  s2.loss_mask: 0.0551
2024/02/24 10:25:35 - mmengine - INFO - Epoch(train) [36][5950/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:15:46  time: 0.6794  data_time: 0.0270  memory: 9535  loss: 1.1609  loss_rpn_cls: 0.0457  loss_rpn_bbox: 0.0320  s0.loss_cls: 0.1802  s0.acc: 98.6328  s0.loss_bbox: 0.2370  s0.loss_mask: 0.2314  s1.loss_cls: 0.0811  s1.acc: 99.2188  s1.loss_bbox: 0.1076  s1.loss_mask: 0.1117  s2.loss_cls: 0.0384  s2.acc: 99.4141  s2.loss_bbox: 0.0432  s2.loss_mask: 0.0527
2024/02/24 10:26:09 - mmengine - INFO - Epoch(train) [36][6000/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:15:12  time: 0.6753  data_time: 0.0269  memory: 9307  loss: 1.1835  loss_rpn_cls: 0.0397  loss_rpn_bbox: 0.0286  s0.loss_cls: 0.1812  s0.acc: 97.1680  s0.loss_bbox: 0.2533  s0.loss_mask: 0.2378  s1.loss_cls: 0.0797  s1.acc: 97.3633  s1.loss_bbox: 0.1126  s1.loss_mask: 0.1155  s2.loss_cls: 0.0374  s2.acc: 98.1445  s2.loss_bbox: 0.0439  s2.loss_mask: 0.0537
2024/02/24 10:26:43 - mmengine - INFO - Epoch(train) [36][6050/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:14:38  time: 0.6874  data_time: 0.0246  memory: 9742  loss: 1.1539  loss_rpn_cls: 0.0391  loss_rpn_bbox: 0.0274  s0.loss_cls: 0.1722  s0.acc: 97.6562  s0.loss_bbox: 0.2385  s0.loss_mask: 0.2416  s1.loss_cls: 0.0762  s1.acc: 97.5309  s1.loss_bbox: 0.1085  s1.loss_mask: 0.1165  s2.loss_cls: 0.0355  s2.acc: 97.4948  s2.loss_bbox: 0.0444  s2.loss_mask: 0.0537
2024/02/24 10:27:18 - mmengine - INFO - Epoch(train) [36][6100/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:14:03  time: 0.6895  data_time: 0.0294  memory: 10002  loss: 1.1766  loss_rpn_cls: 0.0420  loss_rpn_bbox: 0.0306  s0.loss_cls: 0.1804  s0.acc: 97.6562  s0.loss_bbox: 0.2521  s0.loss_mask: 0.2308  s1.loss_cls: 0.0809  s1.acc: 98.6328  s1.loss_bbox: 0.1109  s1.loss_mask: 0.1135  s2.loss_cls: 0.0381  s2.acc: 99.2188  s2.loss_bbox: 0.0442  s2.loss_mask: 0.0531
2024/02/24 10:27:52 - mmengine - INFO - Epoch(train) [36][6150/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:13:29  time: 0.6863  data_time: 0.0276  memory: 9226  loss: 1.1600  loss_rpn_cls: 0.0463  loss_rpn_bbox: 0.0266  s0.loss_cls: 0.1876  s0.acc: 94.2383  s0.loss_bbox: 0.2406  s0.loss_mask: 0.2254  s1.loss_cls: 0.0826  s1.acc: 95.5401  s1.loss_bbox: 0.1090  s1.loss_mask: 0.1102  s2.loss_cls: 0.0386  s2.acc: 95.6479  s2.loss_bbox: 0.0421  s2.loss_mask: 0.0510
2024/02/24 10:28:26 - mmengine - INFO - Epoch(train) [36][6200/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:12:55  time: 0.6800  data_time: 0.0269  memory: 9576  loss: 1.1089  loss_rpn_cls: 0.0383  loss_rpn_bbox: 0.0275  s0.loss_cls: 0.1751  s0.acc: 95.0195  s0.loss_bbox: 0.2195  s0.loss_mask: 0.2315  s1.loss_cls: 0.0791  s1.acc: 96.8096  s1.loss_bbox: 0.0981  s1.loss_mask: 0.1118  s2.loss_cls: 0.0369  s2.acc: 96.2038  s2.loss_bbox: 0.0384  s2.loss_mask: 0.0527
2024/02/24 10:29:01 - mmengine - INFO - Epoch(train) [36][6250/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:12:21  time: 0.6864  data_time: 0.0248  memory: 9682  loss: 1.1796  loss_rpn_cls: 0.0410  loss_rpn_bbox: 0.0255  s0.loss_cls: 0.1852  s0.acc: 95.8984  s0.loss_bbox: 0.2531  s0.loss_mask: 0.2344  s1.loss_cls: 0.0832  s1.acc: 95.5078  s1.loss_bbox: 0.1129  s1.loss_mask: 0.1110  s2.loss_cls: 0.0392  s2.acc: 95.8984  s2.loss_bbox: 0.0441  s2.loss_mask: 0.0499
2024/02/24 10:29:35 - mmengine - INFO - Epoch(train) [36][6300/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:11:46  time: 0.6812  data_time: 0.0272  memory: 9039  loss: 1.1108  loss_rpn_cls: 0.0389  loss_rpn_bbox: 0.0231  s0.loss_cls: 0.1760  s0.acc: 99.3164  s0.loss_bbox: 0.2263  s0.loss_mask: 0.2263  s1.loss_cls: 0.0769  s1.acc: 99.0234  s1.loss_bbox: 0.1030  s1.loss_mask: 0.1102  s2.loss_cls: 0.0369  s2.acc: 99.5117  s2.loss_bbox: 0.0416  s2.loss_mask: 0.0516
2024/02/24 10:30:10 - mmengine - INFO - Epoch(train) [36][6350/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:11:12  time: 0.6969  data_time: 0.0320  memory: 9467  loss: 1.2874  loss_rpn_cls: 0.0487  loss_rpn_bbox: 0.0334  s0.loss_cls: 0.1862  s0.acc: 95.3125  s0.loss_bbox: 0.2810  s0.loss_mask: 0.2619  s1.loss_cls: 0.0829  s1.acc: 97.2973  s1.loss_bbox: 0.1248  s1.loss_mask: 0.1249  s2.loss_cls: 0.0380  s2.acc: 98.1982  s2.loss_bbox: 0.0490  s2.loss_mask: 0.0567
2024/02/24 10:30:43 - mmengine - INFO - Epoch(train) [36][6400/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:10:38  time: 0.6743  data_time: 0.0261  memory: 9527  loss: 1.1410  loss_rpn_cls: 0.0330  loss_rpn_bbox: 0.0230  s0.loss_cls: 0.1849  s0.acc: 91.3086  s0.loss_bbox: 0.2277  s0.loss_mask: 0.2326  s1.loss_cls: 0.0830  s1.acc: 90.9538  s1.loss_bbox: 0.1053  s1.loss_mask: 0.1139  s2.loss_cls: 0.0401  s2.acc: 93.0187  s2.loss_bbox: 0.0431  s2.loss_mask: 0.0546
2024/02/24 10:31:17 - mmengine - INFO - Exp name: cascade_mask_rcnn_swin_tiny_patch4_window7_mstrain_480-800_giou_4conv1f_adamw_3x_coco_20240224_074830
2024/02/24 10:31:17 - mmengine - INFO - Epoch(train) [36][6450/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:10:03  time: 0.6800  data_time: 0.0257  memory: 9528  loss: 1.1964  loss_rpn_cls: 0.0386  loss_rpn_bbox: 0.0315  s0.loss_cls: 0.1826  s0.acc: 94.0430  s0.loss_bbox: 0.2639  s0.loss_mask: 0.2367  s1.loss_cls: 0.0812  s1.acc: 95.6256  s1.loss_bbox: 0.1159  s1.loss_mask: 0.1115  s2.loss_cls: 0.0382  s2.acc: 94.9898  s2.loss_bbox: 0.0447  s2.loss_mask: 0.0516
2024/02/24 10:31:52 - mmengine - INFO - Epoch(train) [36][6500/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:09:29  time: 0.6833  data_time: 0.0260  memory: 11262  loss: 1.2128  loss_rpn_cls: 0.0390  loss_rpn_bbox: 0.0319  s0.loss_cls: 0.1949  s0.acc: 97.4609  s0.loss_bbox: 0.2506  s0.loss_mask: 0.2389  s1.loss_cls: 0.0903  s1.acc: 96.3867  s1.loss_bbox: 0.1133  s1.loss_mask: 0.1170  s2.loss_cls: 0.0397  s2.acc: 97.2656  s2.loss_bbox: 0.0431  s2.loss_mask: 0.0540
2024/02/24 10:32:25 - mmengine - INFO - Epoch(train) [36][6550/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:08:55  time: 0.6759  data_time: 0.0258  memory: 9134  loss: 1.0304  loss_rpn_cls: 0.0319  loss_rpn_bbox: 0.0240  s0.loss_cls: 0.1458  s0.acc: 98.6328  s0.loss_bbox: 0.2065  s0.loss_mask: 0.2296  s1.loss_cls: 0.0666  s1.acc: 98.0469  s1.loss_bbox: 0.0939  s1.loss_mask: 0.1129  s2.loss_cls: 0.0297  s2.acc: 97.6562  s2.loss_bbox: 0.0371  s2.loss_mask: 0.0523
2024/02/24 10:33:00 - mmengine - INFO - Epoch(train) [36][6600/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:08:20  time: 0.6866  data_time: 0.0259  memory: 9686  loss: 1.2055  loss_rpn_cls: 0.0475  loss_rpn_bbox: 0.0279  s0.loss_cls: 0.1874  s0.acc: 95.0195  s0.loss_bbox: 0.2570  s0.loss_mask: 0.2395  s1.loss_cls: 0.0823  s1.acc: 95.8984  s1.loss_bbox: 0.1139  s1.loss_mask: 0.1136  s2.loss_cls: 0.0382  s2.acc: 96.1914  s2.loss_bbox: 0.0448  s2.loss_mask: 0.0534
2024/02/24 10:33:34 - mmengine - INFO - Epoch(train) [36][6650/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:07:46  time: 0.6844  data_time: 0.0239  memory: 9784  loss: 1.0937  loss_rpn_cls: 0.0292  loss_rpn_bbox: 0.0203  s0.loss_cls: 0.1627  s0.acc: 93.5547  s0.loss_bbox: 0.2314  s0.loss_mask: 0.2271  s1.loss_cls: 0.0718  s1.acc: 94.8242  s1.loss_bbox: 0.1084  s1.loss_mask: 0.1133  s2.loss_cls: 0.0341  s2.acc: 97.2656  s2.loss_bbox: 0.0425  s2.loss_mask: 0.0530
2024/02/24 10:34:08 - mmengine - INFO - Epoch(train) [36][6700/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:07:12  time: 0.6823  data_time: 0.0250  memory: 10940  loss: 1.1482  loss_rpn_cls: 0.0353  loss_rpn_bbox: 0.0235  s0.loss_cls: 0.1909  s0.acc: 87.5000  s0.loss_bbox: 0.2394  s0.loss_mask: 0.2245  s1.loss_cls: 0.0845  s1.acc: 87.8486  s1.loss_bbox: 0.1081  s1.loss_mask: 0.1085  s2.loss_cls: 0.0392  s2.acc: 91.9323  s2.loss_bbox: 0.0433  s2.loss_mask: 0.0510
2024/02/24 10:34:43 - mmengine - INFO - Epoch(train) [36][6750/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:06:37  time: 0.7001  data_time: 0.0278  memory: 9715  loss: 1.2759  loss_rpn_cls: 0.0486  loss_rpn_bbox: 0.0298  s0.loss_cls: 0.2065  s0.acc: 95.4102  s0.loss_bbox: 0.2563  s0.loss_mask: 0.2583  s1.loss_cls: 0.0926  s1.acc: 95.4639  s1.loss_bbox: 0.1142  s1.loss_mask: 0.1247  s2.loss_cls: 0.0428  s2.acc: 95.4974  s2.loss_bbox: 0.0435  s2.loss_mask: 0.0587
2024/02/24 10:35:18 - mmengine - INFO - Epoch(train) [36][6800/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:06:03  time: 0.6851  data_time: 0.0261  memory: 9364  loss: 1.1730  loss_rpn_cls: 0.0348  loss_rpn_bbox: 0.0271  s0.loss_cls: 0.1741  s0.acc: 98.4375  s0.loss_bbox: 0.2446  s0.loss_mask: 0.2506  s1.loss_cls: 0.0794  s1.acc: 99.2188  s1.loss_bbox: 0.1084  s1.loss_mask: 0.1211  s2.loss_cls: 0.0367  s2.acc: 98.9258  s2.loss_bbox: 0.0417  s2.loss_mask: 0.0544
2024/02/24 10:35:52 - mmengine - INFO - Epoch(train) [36][6850/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:05:29  time: 0.6916  data_time: 0.0279  memory: 9703  loss: 1.1553  loss_rpn_cls: 0.0337  loss_rpn_bbox: 0.0272  s0.loss_cls: 0.1711  s0.acc: 95.8984  s0.loss_bbox: 0.2353  s0.loss_mask: 0.2443  s1.loss_cls: 0.0755  s1.acc: 94.4167  s1.loss_bbox: 0.1070  s1.loss_mask: 0.1218  s2.loss_cls: 0.0378  s2.acc: 95.2144  s2.loss_bbox: 0.0440  s2.loss_mask: 0.0576
2024/02/24 10:36:26 - mmengine - INFO - Epoch(train) [36][6900/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:04:55  time: 0.6855  data_time: 0.0263  memory: 9768  loss: 1.0974  loss_rpn_cls: 0.0348  loss_rpn_bbox: 0.0245  s0.loss_cls: 0.1703  s0.acc: 95.7031  s0.loss_bbox: 0.2221  s0.loss_mask: 0.2279  s1.loss_cls: 0.0755  s1.acc: 97.6096  s1.loss_bbox: 0.1003  s1.loss_mask: 0.1141  s2.loss_cls: 0.0363  s2.acc: 98.3968  s2.loss_bbox: 0.0388  s2.loss_mask: 0.0528
2024/02/24 10:37:01 - mmengine - INFO - Epoch(train) [36][6950/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:04:20  time: 0.6857  data_time: 0.0260  memory: 9664  loss: 1.1564  loss_rpn_cls: 0.0442  loss_rpn_bbox: 0.0331  s0.loss_cls: 0.1823  s0.acc: 94.8242  s0.loss_bbox: 0.2374  s0.loss_mask: 0.2316  s1.loss_cls: 0.0786  s1.acc: 96.1914  s1.loss_bbox: 0.1054  s1.loss_mask: 0.1127  s2.loss_cls: 0.0366  s2.acc: 96.0938  s2.loss_bbox: 0.0417  s2.loss_mask: 0.0527
2024/02/24 10:37:35 - mmengine - INFO - Epoch(train) [36][7000/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:03:46  time: 0.6833  data_time: 0.0304  memory: 9672  loss: 1.2572  loss_rpn_cls: 0.0388  loss_rpn_bbox: 0.0324  s0.loss_cls: 0.1969  s0.acc: 86.7188  s0.loss_bbox: 0.2758  s0.loss_mask: 0.2361  s1.loss_cls: 0.0877  s1.acc: 88.4692  s1.loss_bbox: 0.1266  s1.loss_mask: 0.1153  s2.loss_cls: 0.0431  s2.acc: 86.1966  s2.loss_bbox: 0.0502  s2.loss_mask: 0.0543
2024/02/24 10:38:09 - mmengine - INFO - Epoch(train) [36][7050/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:03:12  time: 0.6810  data_time: 0.0249  memory: 9591  loss: 1.1301  loss_rpn_cls: 0.0401  loss_rpn_bbox: 0.0319  s0.loss_cls: 0.1729  s0.acc: 95.5078  s0.loss_bbox: 0.2223  s0.loss_mask: 0.2374  s1.loss_cls: 0.0751  s1.acc: 95.8008  s1.loss_bbox: 0.1025  s1.loss_mask: 0.1169  s2.loss_cls: 0.0349  s2.acc: 92.2852  s2.loss_bbox: 0.0409  s2.loss_mask: 0.0550
2024/02/24 10:38:44 - mmengine - INFO - Epoch(train) [36][7100/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:02:37  time: 0.6913  data_time: 0.0245  memory: 10660  loss: 1.0663  loss_rpn_cls: 0.0319  loss_rpn_bbox: 0.0252  s0.loss_cls: 0.1660  s0.acc: 87.4023  s0.loss_bbox: 0.2164  s0.loss_mask: 0.2204  s1.loss_cls: 0.0719  s1.acc: 87.2984  s1.loss_bbox: 0.1005  s1.loss_mask: 0.1091  s2.loss_cls: 0.0334  s2.acc: 85.7143  s2.loss_bbox: 0.0410  s2.loss_mask: 0.0505
2024/02/24 10:39:17 - mmengine - INFO - Epoch(train) [36][7150/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:02:03  time: 0.6748  data_time: 0.0286  memory: 9595  loss: 1.2164  loss_rpn_cls: 0.0407  loss_rpn_bbox: 0.0311  s0.loss_cls: 0.1938  s0.acc: 96.7773  s0.loss_bbox: 0.2600  s0.loss_mask: 0.2380  s1.loss_cls: 0.0858  s1.acc: 97.1370  s1.loss_bbox: 0.1129  s1.loss_mask: 0.1161  s2.loss_cls: 0.0400  s2.acc: 97.9317  s2.loss_bbox: 0.0433  s2.loss_mask: 0.0546
2024/02/24 10:39:52 - mmengine - INFO - Epoch(train) [36][7200/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:01:29  time: 0.6845  data_time: 0.0269  memory: 9145  loss: 1.1945  loss_rpn_cls: 0.0385  loss_rpn_bbox: 0.0277  s0.loss_cls: 0.1940  s0.acc: 85.0586  s0.loss_bbox: 0.2439  s0.loss_mask: 0.2455  s1.loss_cls: 0.0870  s1.acc: 87.5977  s1.loss_bbox: 0.1036  s1.loss_mask: 0.1181  s2.loss_cls: 0.0406  s2.acc: 85.6445  s2.loss_bbox: 0.0405  s2.loss_mask: 0.0551
2024/02/24 10:40:26 - mmengine - INFO - Epoch(train) [36][7250/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:00:54  time: 0.6858  data_time: 0.0273  memory: 9395  loss: 1.0579  loss_rpn_cls: 0.0376  loss_rpn_bbox: 0.0257  s0.loss_cls: 0.1592  s0.acc: 98.7305  s0.loss_bbox: 0.2095  s0.loss_mask: 0.2268  s1.loss_cls: 0.0683  s1.acc: 99.0234  s1.loss_bbox: 0.0965  s1.loss_mask: 0.1112  s2.loss_cls: 0.0318  s2.acc: 99.2188  s2.loss_bbox: 0.0389  s2.loss_mask: 0.0524
2024/02/24 10:41:00 - mmengine - INFO - Epoch(train) [36][7300/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:00:20  time: 0.6776  data_time: 0.0274  memory: 9734  loss: 1.1755  loss_rpn_cls: 0.0405  loss_rpn_bbox: 0.0275  s0.loss_cls: 0.1877  s0.acc: 91.9922  s0.loss_bbox: 0.2468  s0.loss_mask: 0.2357  s1.loss_cls: 0.0807  s1.acc: 93.6041  s1.loss_bbox: 0.1096  s1.loss_mask: 0.1142  s2.loss_cls: 0.0386  s2.acc: 93.1702  s2.loss_bbox: 0.0428  s2.loss_mask: 0.0513
2024/02/24 10:41:20 - mmengine - INFO - Exp name: cascade_mask_rcnn_swin_tiny_patch4_window7_mstrain_480-800_giou_4conv1f_adamw_3x_coco_20240224_074830
2024/02/24 10:41:20 - mmengine - INFO - Saving checkpoint at 36 epochs
2024/02/24 10:41:35 - mmengine - INFO - Epoch(val) [36][ 50/625]    eta: 0:01:52  time: 0.1950  data_time: 0.0234  memory: 10303  
2024/02/24 10:41:45 - mmengine - INFO - Epoch(val) [36][100/625]    eta: 0:01:43  time: 0.1978  data_time: 0.0274  memory: 2669  
2024/02/24 10:41:55 - mmengine - INFO - Epoch(val) [36][150/625]    eta: 0:01:32  time: 0.1938  data_time: 0.0244  memory: 2665  
2024/02/24 10:42:04 - mmengine - INFO - Epoch(val) [36][200/625]    eta: 0:01:22  time: 0.1885  data_time: 0.0217  memory: 2664  
2024/02/24 10:42:14 - mmengine - INFO - Epoch(val) [36][250/625]    eta: 0:01:12  time: 0.1946  data_time: 0.0257  memory: 2669  
2024/02/24 10:42:24 - mmengine - INFO - Epoch(val) [36][300/625]    eta: 0:01:02  time: 0.1911  data_time: 0.0247  memory: 2665  
2024/02/24 10:42:33 - mmengine - INFO - Epoch(val) [36][350/625]    eta: 0:00:53  time: 0.1944  data_time: 0.0258  memory: 2665  
2024/02/24 10:42:43 - mmengine - INFO - Epoch(val) [36][400/625]    eta: 0:00:43  time: 0.1939  data_time: 0.0254  memory: 2669  
2024/02/24 10:42:53 - mmengine - INFO - Epoch(val) [36][450/625]    eta: 0:00:33  time: 0.1919  data_time: 0.0226  memory: 2669  
2024/02/24 10:43:02 - mmengine - INFO - Epoch(val) [36][500/625]    eta: 0:00:24  time: 0.1940  data_time: 0.0259  memory: 2665  
2024/02/24 10:43:12 - mmengine - INFO - Epoch(val) [36][550/625]    eta: 0:00:14  time: 0.2011  data_time: 0.0276  memory: 2669  
2024/02/24 10:43:22 - mmengine - INFO - Epoch(val) [36][600/625]    eta: 0:00:04  time: 0.1946  data_time: 0.0239  memory: 2665  
2024/02/24 10:43:39 - mmengine - INFO - Evaluating bbox...
2024/02/24 10:44:29 - mmengine - INFO - bbox_mAP_copypaste: 0.446 0.631 0.487 0.285 0.475 0.584
2024/02/24 10:44:29 - mmengine - INFO - Evaluating segm...
2024/02/24 10:45:25 - mmengine - INFO - segm_mAP_copypaste: 0.390 0.603 0.420 0.208 0.416 0.566
2024/02/24 10:45:26 - mmengine - INFO - Epoch(val) [36][625/625]    coco/bbox_mAP: 0.4460  coco/bbox_mAP_50: 0.6310  coco/bbox_mAP_75: 0.4870  coco/bbox_mAP_s: 0.2850  coco/bbox_mAP_m: 0.4750  coco/bbox_mAP_l: 0.5840  coco/segm_mAP: 0.3900  coco/segm_mAP_50: 0.6030  coco/segm_mAP_75: 0.4200  coco/segm_mAP_s: 0.2080  coco/segm_mAP_m: 0.4160  coco/segm_mAP_l: 0.5660  data_time: 0.0246  time: 0.1938
